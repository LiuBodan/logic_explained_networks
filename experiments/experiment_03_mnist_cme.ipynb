{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sympy import simplify_logic\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.tree import _tree, export_text\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from deep_logic.utils.base import validate_network, set_seed, tree_to_formula\n",
    "from deep_logic.utils.relu_nn import get_reduced_model, prune_features\n",
    "from deep_logic.utils.psi_nn import prune_equal_fanin\n",
    "from deep_logic import logic\n",
    "\n",
    "results_dir = 'results/mnist_h'\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "n_rep = 10\n",
    "tot_epochs = 4001\n",
    "prune_epochs = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST problem\n",
    "num_workers = 0\n",
    "batch_size = 128\n",
    "valid_size = 0.2\n",
    "# Data augmentation for train data + conversion to tensor\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "   \n",
    "])# Data augmentation for test data + conversion to tensor\n",
    "test_transforms= transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(0.5,))\n",
    "])\n",
    "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=train_transforms)\n",
    "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding indices for validation set\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "#Randomize indices\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(num_train*valid_size))\n",
    "train_index, test_index = indices[split:], indices[:split]# Making samplers for training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_index)\n",
    "valid_sampler = SubsetRandomSampler(test_index)# Creating data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # convolutional layers\n",
    "        self.conv1 = torch.nn.Conv2d(1, 8, 3, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(8, 16, 3, padding =1)\n",
    "        # linear layers\n",
    "        self.fc1 = torch.nn.Linear(784, 256)\n",
    "        self.fc2 = torch.nn.Linear(256, 128)\n",
    "        self.fc3 = torch.nn.Linear(128, 64)\n",
    "        self.fc4 = torch.nn.Linear(64, 2) \n",
    "        # dropout\n",
    "        self.dropout = torch.nn.Dropout(p=0.2)\n",
    "        # max pooling\n",
    "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # convolutional layers with ReLU and pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # flattening the image\n",
    "        x = x.view(-1, 7*7*16)\n",
    "        # linear layers\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = self.fc4(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "        \n",
    "model = Net()\n",
    "print(model)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Epoch: 1\n",
      "Training Loss: 0.388886\n",
      "Validation Loss: 0.3386\n",
      "Current Epoch: 2\n",
      "Training Loss: 0.336413\n",
      "Validation Loss: 0.334174\n",
      "Current Epoch: 3\n",
      "Training Loss: 0.330343\n",
      "Validation Loss: 0.329041\n",
      "Current Epoch: 4\n",
      "Training Loss: 0.327772\n",
      "Validation Loss: 0.328242\n",
      "Current Epoch: 5\n",
      "Training Loss: 0.326123\n",
      "Validation Loss: 0.331251\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7ef0e2f7f552>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# training steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[1;31m# moves tensors to GPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pietr\\anaconda3\\envs\\deep-logic\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pietr\\anaconda3\\envs\\deep-logic\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pietr\\anaconda3\\envs\\deep-logic\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pietr\\anaconda3\\envs\\deep-logic\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pietr\\anaconda3\\envs\\deep-logic\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pietr\\anaconda3\\envs\\deep-logic\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pietr\\anaconda3\\envs\\deep-logic\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \"\"\"\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pietr\\anaconda3\\envs\\deep-logic\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetbands\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;31m# put it from HWC to CHW format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "if os.path.isfile('./models/mnist_h/trained_model_h.pt'):\n",
    "    model.load_state_dict(torch.load('./models/mnist_h/trained_model_h.pt'))\n",
    "\n",
    "else:\n",
    "    # epochs to train for\n",
    "    epochs = 10\n",
    "    set_seed(0)\n",
    "\n",
    "    # tracks validation loss change after each epoch\n",
    "    minimum_validation_loss = np.inf \n",
    "\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr = 0.001)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(1, epochs+1):\n",
    "\n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "\n",
    "        # training steps\n",
    "        model.train()\n",
    "        for batch_index, (data, target) in enumerate(train_loader):\n",
    "            # moves tensors to GPU\n",
    "            data, target = data.cuda(), target.cuda() % 2\n",
    "            # clears gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass\n",
    "            output = model(data)\n",
    "            # loss in batch\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass for loss gradient\n",
    "            loss.backward()\n",
    "            # update paremeters\n",
    "            optimizer.step()\n",
    "            # update training loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "\n",
    "        # validation steps\n",
    "        model.eval()\n",
    "        for batch_index, (data, target) in enumerate(valid_loader):\n",
    "            # moves tensors to GPU\n",
    "            data, target = data.cuda(), target.cuda() % 2\n",
    "            # forward pass\n",
    "            output = model(data)\n",
    "            # loss in batch\n",
    "            loss = criterion(output, target)\n",
    "            # update validation loss\n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "\n",
    "        # average loss calculations\n",
    "        train_loss = train_loss/len(train_loader.sampler)\n",
    "        valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "\n",
    "        # Display loss statistics\n",
    "        print(f'Current Epoch: {epoch}\\nTraining Loss: {round(train_loss, 6)}\\nValidation Loss: {round(valid_loss, 6)}')\n",
    "\n",
    "        # Saving model every time validation loss decreases\n",
    "        if valid_loss <= minimum_validation_loss and epoch > 5:\n",
    "            print(f'Validation loss decreased from {round(minimum_validation_loss, 6)} to {round(valid_loss, 6)}')\n",
    "            torch.save(model.state_dict(), './models/mnist_h/trained_model_h.pt')\n",
    "            minimum_validation_loss = valid_loss\n",
    "            print('Saving New Model')\n",
    "    \n",
    "    model.load_state_dict(torch.load('./models/mnist_h/trained_model_h.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.320503\n",
      "Test Accuracy of 0: 100.0%\n",
      "Test Accuracy of 1: 97.4%\n",
      "Full Test Accuracy: 98.73% 156.0 out of 158.0\n"
     ]
    }
   ],
   "source": [
    "# tracking test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model.eval()\n",
    "classes = [0, 1]\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    # move tensors to GPU\n",
    "    data, target = data.cuda(), target.cuda() % 2\n",
    "    # forward pass\n",
    "    output = model(data)\n",
    "    # batch loss\n",
    "    loss = criterion(output, target)\n",
    "    # test loss update\n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(2):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print(f'Test Loss: {round(test_loss, 6)}')\n",
    "\n",
    "for i in range(2):\n",
    "    if class_total[i] > 0:\n",
    "        print(f'Test Accuracy of {classes[i]}: {round(100*class_correct[i]/class_total[i], 2)}%')\n",
    "    else:\n",
    "        print(f'Test Accuracy of {classes[i]}s: N/A (no training examples)')\n",
    "        \n",
    "        \n",
    "print(f'Full Test Accuracy: {round(100. * np.sum(class_correct) / np.sum(class_total), 2)}% {np.sum(class_correct)} out of {np.sum(class_total)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract concepts from hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48000, 128])\n",
      "torch.Size([48000])\n"
     ]
    }
   ],
   "source": [
    "pred_h_train = []\n",
    "true_y_train = []\n",
    "model.eval()\n",
    "model = model.cpu()\n",
    "for batch_index, (data, target) in enumerate(train_loader):\n",
    "    # moves tensors to GPU\n",
    "    data, target = data.cpu(), target.cpu() % 2\n",
    "    # forward pass\n",
    "    #output = model(data)\n",
    "    #pred = torch.argmax(output, 1)\n",
    "    \n",
    "    # get hidden layer's projection of the input\n",
    "    x = model.pool(F.relu(model.conv1(data)))\n",
    "    x = model.pool(F.relu(model.conv2(x)))\n",
    "    # flattening the image\n",
    "    x = x.view(-1, 7*7*16)\n",
    "    # linear layers\n",
    "    x = model.dropout(F.relu(model.fc1(x)))\n",
    "    x = model.dropout(F.relu(model.fc2(x)))\n",
    "    \n",
    "    pred_h_train.append(x.cpu())\n",
    "    true_y_train.append(target.cpu())\n",
    "\n",
    "pred_h_train = torch.cat(pred_h_train)\n",
    "true_y_train = torch.cat(true_y_train)\n",
    "print(pred_h_train.shape)\n",
    "print(true_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 128])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "pred_h_test = []\n",
    "true_y_test = []\n",
    "model.eval()\n",
    "model = model.cpu()\n",
    "for batch_index, (data, target) in enumerate(test_loader):\n",
    "    # moves tensors to GPU\n",
    "    data, target = data.cpu(), target.cpu() % 2\n",
    "    # forward pass\n",
    "    #output = model(data)\n",
    "    #pred = torch.argmax(output, 1)\n",
    "    \n",
    "    # get hidden layer's projection of the input\n",
    "    x = model.pool(F.relu(model.conv1(data)))\n",
    "    x = model.pool(F.relu(model.conv2(x)))\n",
    "    # flattening the image\n",
    "    x = x.view(-1, 7*7*16)\n",
    "    # linear layers\n",
    "    x = model.dropout(F.relu(model.fc1(x)))\n",
    "    x = model.dropout(F.relu(model.fc2(x)))\n",
    "    \n",
    "    pred_h_test.append(x.cpu())\n",
    "    true_y_test.append(target.cpu())\n",
    "\n",
    "pred_h_test = torch.cat(pred_h_test)\n",
    "true_y_test = torch.cat(true_y_test)\n",
    "print(pred_h_test.shape)\n",
    "print(true_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded = TSNE(n_components=2).fit_transform(pred_h_train.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(pred_h_train.detach().numpy())\n",
    "X_train = kmeans.predict(pred_h_train.detach().numpy())\n",
    "X_test = kmeans.predict(pred_h_test.detach().numpy())\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=X_train)\n",
    "plt.savefig('mnist_hidden.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48000, 10])\n",
      "torch.Size([10000, 10])\n"
     ]
    }
   ],
   "source": [
    "x_trainval = torch.FloatTensor(OneHotEncoder(sparse=False).fit_transform(X_train.reshape(-1, 1)))\n",
    "x_test = torch.FloatTensor(OneHotEncoder(sparse=False).fit_transform(X_test.reshape(-1, 1)))\n",
    "print(x_trainval.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48000])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "y_trainval = (true_y_train % 2 == 1).to(torch.long)\n",
    "y_test = (true_y_test % 2 == 1).to(torch.long)\n",
    "print(y_trainval.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47700, 10])\n",
      "torch.Size([300, 10])\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_trainval, y_trainval, test_size=300, random_state=42)\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h0', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'h7', 'h8', 'h9']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concepts = [f'h{i}' for i in range(x_train.shape[1])]\n",
    "concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(x_train, y_train, need_pruning, seed, device, relu=False, verbose=False):\n",
    "    set_seed(seed)\n",
    "    x_train = x_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    layers = [\n",
    "        torch.nn.Linear(x_train.size(1), 100),\n",
    "        torch.nn.ReLU() if relu else torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(100, 50),\n",
    "        torch.nn.ReLU() if relu else torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(50, 30),\n",
    "        torch.nn.ReLU() if relu else torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(30, 2),\n",
    "        torch.nn.Softmax(dim=1),\n",
    "    ]\n",
    "    model = torch.nn.Sequential(*layers).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "    loss_form = torch.nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    for epoch in range(tot_epochs):\n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_train)\n",
    "        # Compute Loss\n",
    "        loss = loss_form(y_pred, y_train)\n",
    "\n",
    "        for module in model.children():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                loss += 0.001 * torch.norm(module.weight, 1)\n",
    "                loss += 0.001 * torch.norm(module.bias, 1)\n",
    "                break\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch > prune_epochs and need_pruning:\n",
    "            prune_features(model, n_classes=1, device=device)\n",
    "            need_pruning = False\n",
    "            \n",
    "        # compute accuracy\n",
    "        if epoch % 500 == 0 and verbose:\n",
    "            y_pred_d = torch.argmax(y_pred, dim=1)\n",
    "            accuracy = y_pred_d.eq(y_train).sum().item() / y_train.size(0)\n",
    "            print(f'\\t Epoch {epoch}: train accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_psi_nn(x_train, y_train, need_pruning, seed, device, verbose=False):\n",
    "    set_seed(seed)\n",
    "    x_train = x_train.to(device)\n",
    "    y_train = y_train.to(device).to(torch.float)\n",
    "    layers = [\n",
    "        torch.nn.Linear(x_train.size(1), 10),\n",
    "        torch.nn.Sigmoid(),\n",
    "        torch.nn.Linear(10, 4),\n",
    "        torch.nn.Sigmoid(),\n",
    "        torch.nn.Linear(4, 1),\n",
    "        torch.nn.Sigmoid(),\n",
    "    ]\n",
    "    model = torch.nn.Sequential(*layers).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_form = torch.nn.BCELoss()\n",
    "    model.train()\n",
    "    for epoch in range(tot_epochs):\n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_train).squeeze()\n",
    "        # Compute Loss\n",
    "        loss = loss_form(y_pred, y_train)\n",
    "\n",
    "        for module in model.children():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                loss += 0.00001 * torch.norm(module.weight, 1)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch > prune_epochs and need_pruning:\n",
    "            model = prune_equal_fanin(model, 2, validate=True, device=device)\n",
    "            need_pruning = False\n",
    "            \n",
    "        # compute accuracy\n",
    "        if epoch % 500 == 0 and verbose:\n",
    "            y_pred_d = y_pred > 0.5\n",
    "            accuracy = y_pred_d.eq(y_train).sum().item() / y_train.size(0)\n",
    "            print(f'\\t Epoch {epoch}: train accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_to_y(method, need_pruning, relu, verbose=False):\n",
    "    methods = []\n",
    "    splits = []\n",
    "    explanations = []\n",
    "    explanations_inv = []\n",
    "    model_accuracies = []\n",
    "    explanation_accuracies = []\n",
    "    explanation_accuracies_inv = []\n",
    "    elapsed_times = []\n",
    "    elapsed_times_inv = []\n",
    "    for seed in range(n_rep):\n",
    "        explanation, explanation_inv = '', ''\n",
    "        explanation_accuracy, explanation_accuracy_inv = 0, 0\n",
    "        \n",
    "        print(f'Seed [{seed+1}/{n_rep}]')\n",
    "        \n",
    "        if method == 'tree':\n",
    "            classifier = DecisionTreeClassifier(random_state=seed)\n",
    "            classifier.fit(x_train.cpu().detach().numpy(), y_train.cpu().detach().numpy())\n",
    "            y_preds = classifier.predict(x_test.cpu().detach().numpy())\n",
    "            model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds)\n",
    "\n",
    "            target_class = 1\n",
    "            start = time.time()\n",
    "            explanation = tree_to_formula(classifier, concepts, target_class)\n",
    "            elapsed_time = time.time() - start\n",
    "            explanation_accuracy = model_accuracy\n",
    "\n",
    "            target_class_inv = 0\n",
    "            start = time.time()\n",
    "            explanation_inv = tree_to_formula(classifier, concepts, target_class_inv)\n",
    "            elapsed_time_inv = time.time() - start\n",
    "            explanation_accuracy_inv = model_accuracy\n",
    "        \n",
    "        else:\n",
    "            if method == 'psi':\n",
    "                # positive class\n",
    "                target_class = 1\n",
    "                model = train_psi_nn(x_train, y_train.eq(target_class), need_pruning, seed, device, verbose)\n",
    "                y_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "                model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds>0.5)\n",
    "                \n",
    "            else:\n",
    "                model = train_nn(x_train, y_train, need_pruning, seed, device, relu, verbose)\n",
    "                y_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "                model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds.argmax(axis=1))\n",
    "\n",
    "            # positive class\n",
    "            target_class = 1\n",
    "            start = time.time()\n",
    "            if method == 'psi':\n",
    "                global_explanation = logic.generate_fol_explanations(model, device)[0]\n",
    "            else:\n",
    "                global_explanation, _, _ = logic.relu_nn.combine_local_explanations(model, \n",
    "                                                                                   x_val.to(device), \n",
    "                                                                                   y_val.to(device), \n",
    "                                                                                   topk_explanations=5,\n",
    "                                                                                   target_class=target_class,\n",
    "                                                                                   method=method, device=device)\n",
    "            elapsed_time = time.time() - start\n",
    "            \n",
    "            if global_explanation:\n",
    "                explanation_accuracy, _ = logic.base.test_explanation(global_explanation, target_class, x_test, y_test)\n",
    "                explanation = logic.base.replace_names(global_explanation, concepts)\n",
    "\n",
    "            # negative class\n",
    "            target_class_inv = 0\n",
    "            if method == 'psi':\n",
    "                model = train_psi_nn(x_train, y_train.eq(target_class_inv), need_pruning, seed, device, verbose)\n",
    "            \n",
    "            start = time.time()\n",
    "            if method == 'psi':\n",
    "                global_explanation_inv = logic.generate_fol_explanations(model, device)[0]\n",
    "            else:\n",
    "                global_explanation_inv, _, _ = logic.relu_nn.combine_local_explanations(model, \n",
    "                                                                                       x_val.to(device), \n",
    "                                                                                       y_val.to(device), \n",
    "                                                                                       topk_explanations=5,\n",
    "                                                                                       target_class=target_class_inv,\n",
    "                                                                                       method=method, device=device)\n",
    "            elapsed_time_inv = time.time() - start\n",
    "            if global_explanation_inv:\n",
    "                explanation_accuracy_inv, _ = logic.base.test_explanation(global_explanation_inv, \n",
    "                                                                          target_class_inv, x_test, y_test)\n",
    "                explanation_inv = logic.base.replace_names(global_explanation_inv, concepts)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "            print(f'\\t Class {target_class} - Global explanation: \"{explanation}\" - Accuracy: {explanation_accuracy:.4f}')\n",
    "            print(f'\\t Elapsed time {elapsed_time}')\n",
    "            print(f'\\t Class {target_class_inv} - Global explanation: \"{explanation_inv}\" - Accuracy: {explanation_accuracy_inv:.4f}')\n",
    "            print(f'\\t Elapsed time {elapsed_time_inv}')\n",
    "\n",
    "        methods.append(method)\n",
    "        splits.append(seed)\n",
    "        explanations.append(explanation)\n",
    "        explanations_inv.append(explanation_inv)\n",
    "        model_accuracies.append(model_accuracy)\n",
    "        explanation_accuracies.append(explanation_accuracy)\n",
    "        explanation_accuracies_inv.append(explanation_accuracy_inv)\n",
    "        elapsed_times.append(elapsed_time)\n",
    "        elapsed_times_inv.append(elapsed_time_inv)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'method': methods,\n",
    "        'split': splits,\n",
    "        'explanation': explanations,\n",
    "        'explanation_inv': explanations_inv,\n",
    "        'model_accuracy': model_accuracies,\n",
    "        'explanation_accuracy': explanation_accuracies,\n",
    "        'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "        'elapsed_time': elapsed_times,\n",
    "        'elapsed_time_inv': elapsed_times_inv,\n",
    "    })\n",
    "    results.to_csv(os.path.join(results_dir, f'results_{method}.csv'))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed [1/10]\n",
      "Seed [2/10]\n",
      "Seed [3/10]\n",
      "Seed [4/10]\n",
      "Seed [5/10]\n",
      "Seed [6/10]\n",
      "Seed [7/10]\n",
      "Seed [8/10]\n",
      "Seed [9/10]\n",
      "Seed [10/10]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>explanation_inv</th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_accuracy_inv</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>elapsed_time_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pruning</td>\n",
       "      <td>0</td>\n",
       "      <td>~h0 &amp; ~h2 &amp; ~h5 &amp; ~h7</td>\n",
       "      <td>(h0 &amp; ~h2 &amp; ~h5 &amp; ~h7) | (h2 &amp; ~h0 &amp; ~h5 &amp; ~h7...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>99.24</td>\n",
       "      <td>99.24</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.037719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pruning</td>\n",
       "      <td>1</td>\n",
       "      <td>~h0 &amp; ~h2 &amp; ~h5 &amp; ~h7</td>\n",
       "      <td>(h0 &amp; ~h2 &amp; ~h5 &amp; ~h7) | (h2 &amp; ~h0 &amp; ~h5 &amp; ~h7...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>99.24</td>\n",
       "      <td>99.24</td>\n",
       "      <td>0.015608</td>\n",
       "      <td>0.031216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pruning</td>\n",
       "      <td>2</td>\n",
       "      <td>~h0 &amp; ~h2 &amp; ~h5 &amp; ~h7</td>\n",
       "      <td>(h0 &amp; ~h2 &amp; ~h5 &amp; ~h7) | (h2 &amp; ~h0 &amp; ~h5 &amp; ~h7...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>99.24</td>\n",
       "      <td>99.24</td>\n",
       "      <td>0.031234</td>\n",
       "      <td>0.038599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pruning</td>\n",
       "      <td>3</td>\n",
       "      <td>~h0 &amp; ~h2 &amp; ~h5 &amp; ~h7</td>\n",
       "      <td>(h0 &amp; ~h2 &amp; ~h5 &amp; ~h7) | (h2 &amp; ~h0 &amp; ~h5 &amp; ~h7...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>99.24</td>\n",
       "      <td>99.24</td>\n",
       "      <td>0.020086</td>\n",
       "      <td>0.040137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pruning</td>\n",
       "      <td>4</td>\n",
       "      <td>~h0 &amp; ~h2 &amp; ~h5 &amp; ~h7</td>\n",
       "      <td>(h0 &amp; ~h2 &amp; ~h5 &amp; ~h7) | (h2 &amp; ~h0 &amp; ~h5 &amp; ~h7...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>99.24</td>\n",
       "      <td>99.24</td>\n",
       "      <td>0.018133</td>\n",
       "      <td>0.050160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pruning</td>\n",
       "      <td>5</td>\n",
       "      <td>~h0 &amp; ~h2 &amp; ~h5 &amp; ~h7</td>\n",
       "      <td>(h0 &amp; ~h2 &amp; ~h5 &amp; ~h7) | (h2 &amp; ~h0 &amp; ~h5 &amp; ~h7...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>99.24</td>\n",
       "      <td>99.24</td>\n",
       "      <td>0.020123</td>\n",
       "      <td>0.040112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pruning</td>\n",
       "      <td>6</td>\n",
       "      <td>~h0 &amp; ~h2 &amp; ~h5 &amp; ~h7</td>\n",
       "      <td>(h0 &amp; ~h2 &amp; ~h5 &amp; ~h7) | (h2 &amp; ~h0 &amp; ~h5 &amp; ~h7...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>99.24</td>\n",
       "      <td>99.24</td>\n",
       "      <td>0.030130</td>\n",
       "      <td>0.048194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pruning</td>\n",
       "      <td>7</td>\n",
       "      <td>~h0 &amp; ~h2 &amp; ~h5 &amp; ~h7</td>\n",
       "      <td>(h0 &amp; ~h2 &amp; ~h5 &amp; ~h7) | (h2 &amp; ~h0 &amp; ~h5 &amp; ~h7...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>99.24</td>\n",
       "      <td>99.24</td>\n",
       "      <td>0.020223</td>\n",
       "      <td>0.030110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pruning</td>\n",
       "      <td>8</td>\n",
       "      <td>~h0 &amp; ~h2 &amp; ~h5 &amp; ~h7</td>\n",
       "      <td>(h0 &amp; ~h2 &amp; ~h5 &amp; ~h7) | (h2 &amp; ~h0 &amp; ~h5 &amp; ~h7...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>99.24</td>\n",
       "      <td>99.24</td>\n",
       "      <td>0.012039</td>\n",
       "      <td>0.038094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pruning</td>\n",
       "      <td>9</td>\n",
       "      <td>~h0 &amp; ~h2 &amp; ~h5 &amp; ~h7</td>\n",
       "      <td>(h0 &amp; ~h2 &amp; ~h5 &amp; ~h7) | (h2 &amp; ~h0 &amp; ~h5 &amp; ~h7...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>99.24</td>\n",
       "      <td>99.24</td>\n",
       "      <td>0.020166</td>\n",
       "      <td>0.040193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    method  split            explanation  \\\n",
       "0  pruning      0  ~h0 & ~h2 & ~h5 & ~h7   \n",
       "1  pruning      1  ~h0 & ~h2 & ~h5 & ~h7   \n",
       "2  pruning      2  ~h0 & ~h2 & ~h5 & ~h7   \n",
       "3  pruning      3  ~h0 & ~h2 & ~h5 & ~h7   \n",
       "4  pruning      4  ~h0 & ~h2 & ~h5 & ~h7   \n",
       "5  pruning      5  ~h0 & ~h2 & ~h5 & ~h7   \n",
       "6  pruning      6  ~h0 & ~h2 & ~h5 & ~h7   \n",
       "7  pruning      7  ~h0 & ~h2 & ~h5 & ~h7   \n",
       "8  pruning      8  ~h0 & ~h2 & ~h5 & ~h7   \n",
       "9  pruning      9  ~h0 & ~h2 & ~h5 & ~h7   \n",
       "\n",
       "                                     explanation_inv  model_accuracy  \\\n",
       "0  (h0 & ~h2 & ~h5 & ~h7) | (h2 & ~h0 & ~h5 & ~h7...          0.9924   \n",
       "1  (h0 & ~h2 & ~h5 & ~h7) | (h2 & ~h0 & ~h5 & ~h7...          0.9924   \n",
       "2  (h0 & ~h2 & ~h5 & ~h7) | (h2 & ~h0 & ~h5 & ~h7...          0.9924   \n",
       "3  (h0 & ~h2 & ~h5 & ~h7) | (h2 & ~h0 & ~h5 & ~h7...          0.9924   \n",
       "4  (h0 & ~h2 & ~h5 & ~h7) | (h2 & ~h0 & ~h5 & ~h7...          0.9924   \n",
       "5  (h0 & ~h2 & ~h5 & ~h7) | (h2 & ~h0 & ~h5 & ~h7...          0.9924   \n",
       "6  (h0 & ~h2 & ~h5 & ~h7) | (h2 & ~h0 & ~h5 & ~h7...          0.9924   \n",
       "7  (h0 & ~h2 & ~h5 & ~h7) | (h2 & ~h0 & ~h5 & ~h7...          0.9924   \n",
       "8  (h0 & ~h2 & ~h5 & ~h7) | (h2 & ~h0 & ~h5 & ~h7...          0.9924   \n",
       "9  (h0 & ~h2 & ~h5 & ~h7) | (h2 & ~h0 & ~h5 & ~h7...          0.9924   \n",
       "\n",
       "   explanation_accuracy  explanation_accuracy_inv  elapsed_time  \\\n",
       "0                 99.24                     99.24      0.015625   \n",
       "1                 99.24                     99.24      0.015608   \n",
       "2                 99.24                     99.24      0.031234   \n",
       "3                 99.24                     99.24      0.020086   \n",
       "4                 99.24                     99.24      0.018133   \n",
       "5                 99.24                     99.24      0.020123   \n",
       "6                 99.24                     99.24      0.030130   \n",
       "7                 99.24                     99.24      0.020223   \n",
       "8                 99.24                     99.24      0.012039   \n",
       "9                 99.24                     99.24      0.020166   \n",
       "\n",
       "   elapsed_time_inv  \n",
       "0          0.037719  \n",
       "1          0.031216  \n",
       "2          0.038599  \n",
       "3          0.040137  \n",
       "4          0.050160  \n",
       "5          0.040112  \n",
       "6          0.048194  \n",
       "7          0.030110  \n",
       "8          0.038094  \n",
       "9          0.040193  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = 'pruning'\n",
    "need_pruning = True\n",
    "relu = False\n",
    "results_pruning = c_to_y(method, need_pruning, relu)\n",
    "results_pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed [1/10]\n",
      "Seed [2/10]\n",
      "Seed [3/10]\n",
      "Seed [4/10]\n",
      "Seed [5/10]\n",
      "Seed [6/10]\n",
      "Seed [7/10]\n",
      "Seed [8/10]\n",
      "Seed [9/10]\n",
      "Seed [10/10]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>explanation_inv</th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_accuracy_inv</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>elapsed_time_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weights</td>\n",
       "      <td>0</td>\n",
       "      <td>~h0 &amp; ~h2 &amp; ~h5 &amp; ~h7</td>\n",
       "      <td>(h0 &amp; ~h2 &amp; ~h5 &amp; ~h7) | (h2 &amp; ~h0 &amp; ~h5 &amp; ~h7...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>99.24</td>\n",
       "      <td>99.24</td>\n",
       "      <td>0.031232</td>\n",
       "      <td>0.031213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weights</td>\n",
       "      <td>1</td>\n",
       "      <td>~h0 &amp; ~h2 &amp; ~h5 &amp; ~h7</td>\n",
       "      <td>(h0 &amp; ~h2 &amp; ~h5 &amp; ~h7) | (h2 &amp; ~h0 &amp; ~h5 &amp; ~h7...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>99.24</td>\n",
       "      <td>99.24</td>\n",
       "      <td>0.031243</td>\n",
       "      <td>0.046839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weights</td>\n",
       "      <td>2</td>\n",
       "      <td>~h0 &amp; ~h2 &amp; ~h5 &amp; ~h7</td>\n",
       "      <td>(h0 &amp; ~h2 &amp; ~h5 &amp; ~h7) | (h2 &amp; ~h0 &amp; ~h5 &amp; ~h7...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>99.24</td>\n",
       "      <td>99.24</td>\n",
       "      <td>0.015622</td>\n",
       "      <td>0.031242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weights</td>\n",
       "      <td>3</td>\n",
       "      <td>(~h0 &amp; ~h2 &amp; ~h5 &amp; ~h7) | (h8 &amp; ~h0 &amp; ~h1 &amp; ~h...</td>\n",
       "      <td>(h0 &amp; ~h2 &amp; ~h5 &amp; ~h7) | (h2 &amp; ~h0 &amp; ~h5 &amp; ~h7...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>99.24</td>\n",
       "      <td>99.24</td>\n",
       "      <td>0.046857</td>\n",
       "      <td>0.038647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weights</td>\n",
       "      <td>4</td>\n",
       "      <td>~h0 &amp; ~h2 &amp; ~h5 &amp; ~h7</td>\n",
       "      <td>(h0 &amp; ~h2 &amp; ~h5 &amp; ~h7) | (h2 &amp; ~h0 &amp; ~h5 &amp; ~h7...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>99.24</td>\n",
       "      <td>99.24</td>\n",
       "      <td>0.086716</td>\n",
       "      <td>0.040088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weights</td>\n",
       "      <td>5</td>\n",
       "      <td>(h3 &amp; ~h0 &amp; ~h2 &amp; ~h4) | (~h0 &amp; ~h2 &amp; ~h5 &amp; ~h...</td>\n",
       "      <td>(h0 &amp; ~h2 &amp; ~h5 &amp; ~h7) | (h2 &amp; ~h0 &amp; ~h5 &amp; ~h7...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>71.70</td>\n",
       "      <td>99.24</td>\n",
       "      <td>0.806288</td>\n",
       "      <td>0.040141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weights</td>\n",
       "      <td>6</td>\n",
       "      <td>(~h0 &amp; ~h4 &amp; ~h7) | (~h0 &amp; ~h2 &amp; ~h5 &amp; ~h7)</td>\n",
       "      <td>(h0 &amp; ~h2 &amp; ~h5 &amp; ~h7) | (h2 &amp; ~h0 &amp; ~h5 &amp; ~h7...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>78.80</td>\n",
       "      <td>99.24</td>\n",
       "      <td>0.044370</td>\n",
       "      <td>0.030097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weights</td>\n",
       "      <td>7</td>\n",
       "      <td>(~h0 &amp; ~h2 &amp; ~h5 &amp; ~h7) | (~h0 &amp; ~h2 &amp; ~h3 &amp; ~...</td>\n",
       "      <td>(h0 &amp; ~h2 &amp; ~h5 &amp; ~h7) | (h2 &amp; ~h0 &amp; ~h5 &amp; ~h7...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>92.40</td>\n",
       "      <td>99.24</td>\n",
       "      <td>0.091287</td>\n",
       "      <td>0.040213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weights</td>\n",
       "      <td>8</td>\n",
       "      <td>(~h0 &amp; ~h9) | (~h0 &amp; ~h2 &amp; ~h5 &amp; ~h7)</td>\n",
       "      <td>(h0 &amp; ~h2 &amp; ~h5 &amp; ~h7) | (h2 &amp; ~h0 &amp; ~h5 &amp; ~h7...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>58.10</td>\n",
       "      <td>99.24</td>\n",
       "      <td>0.030088</td>\n",
       "      <td>0.040270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>weights</td>\n",
       "      <td>9</td>\n",
       "      <td>(~h7 &amp; ~h8) | (~h0 &amp; ~h2 &amp; ~h5 &amp; ~h7)</td>\n",
       "      <td>(h0 &amp; ~h2 &amp; ~h5 &amp; ~h7) | (h2 &amp; ~h0 &amp; ~h5 &amp; ~h7...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>71.44</td>\n",
       "      <td>99.24</td>\n",
       "      <td>0.078100</td>\n",
       "      <td>0.038725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    method  split                                        explanation  \\\n",
       "0  weights      0                              ~h0 & ~h2 & ~h5 & ~h7   \n",
       "1  weights      1                              ~h0 & ~h2 & ~h5 & ~h7   \n",
       "2  weights      2                              ~h0 & ~h2 & ~h5 & ~h7   \n",
       "3  weights      3  (~h0 & ~h2 & ~h5 & ~h7) | (h8 & ~h0 & ~h1 & ~h...   \n",
       "4  weights      4                              ~h0 & ~h2 & ~h5 & ~h7   \n",
       "5  weights      5  (h3 & ~h0 & ~h2 & ~h4) | (~h0 & ~h2 & ~h5 & ~h...   \n",
       "6  weights      6        (~h0 & ~h4 & ~h7) | (~h0 & ~h2 & ~h5 & ~h7)   \n",
       "7  weights      7  (~h0 & ~h2 & ~h5 & ~h7) | (~h0 & ~h2 & ~h3 & ~...   \n",
       "8  weights      8              (~h0 & ~h9) | (~h0 & ~h2 & ~h5 & ~h7)   \n",
       "9  weights      9              (~h7 & ~h8) | (~h0 & ~h2 & ~h5 & ~h7)   \n",
       "\n",
       "                                     explanation_inv  model_accuracy  \\\n",
       "0  (h0 & ~h2 & ~h5 & ~h7) | (h2 & ~h0 & ~h5 & ~h7...          0.9924   \n",
       "1  (h0 & ~h2 & ~h5 & ~h7) | (h2 & ~h0 & ~h5 & ~h7...          0.9924   \n",
       "2  (h0 & ~h2 & ~h5 & ~h7) | (h2 & ~h0 & ~h5 & ~h7...          0.9924   \n",
       "3  (h0 & ~h2 & ~h5 & ~h7) | (h2 & ~h0 & ~h5 & ~h7...          0.9924   \n",
       "4  (h0 & ~h2 & ~h5 & ~h7) | (h2 & ~h0 & ~h5 & ~h7...          0.9924   \n",
       "5  (h0 & ~h2 & ~h5 & ~h7) | (h2 & ~h0 & ~h5 & ~h7...          0.9924   \n",
       "6  (h0 & ~h2 & ~h5 & ~h7) | (h2 & ~h0 & ~h5 & ~h7...          0.9924   \n",
       "7  (h0 & ~h2 & ~h5 & ~h7) | (h2 & ~h0 & ~h5 & ~h7...          0.9924   \n",
       "8  (h0 & ~h2 & ~h5 & ~h7) | (h2 & ~h0 & ~h5 & ~h7...          0.9924   \n",
       "9  (h0 & ~h2 & ~h5 & ~h7) | (h2 & ~h0 & ~h5 & ~h7...          0.9924   \n",
       "\n",
       "   explanation_accuracy  explanation_accuracy_inv  elapsed_time  \\\n",
       "0                 99.24                     99.24      0.031232   \n",
       "1                 99.24                     99.24      0.031243   \n",
       "2                 99.24                     99.24      0.015622   \n",
       "3                 99.24                     99.24      0.046857   \n",
       "4                 99.24                     99.24      0.086716   \n",
       "5                 71.70                     99.24      0.806288   \n",
       "6                 78.80                     99.24      0.044370   \n",
       "7                 92.40                     99.24      0.091287   \n",
       "8                 58.10                     99.24      0.030088   \n",
       "9                 71.44                     99.24      0.078100   \n",
       "\n",
       "   elapsed_time_inv  \n",
       "0          0.031213  \n",
       "1          0.046839  \n",
       "2          0.031242  \n",
       "3          0.038647  \n",
       "4          0.040088  \n",
       "5          0.040141  \n",
       "6          0.030097  \n",
       "7          0.040213  \n",
       "8          0.040270  \n",
       "9          0.038725  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = 'weights'\n",
    "need_pruning = False\n",
    "relu = True\n",
    "results_weights = c_to_y(method, need_pruning, relu)\n",
    "results_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Psi network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed [1/10]\n",
      "\t Epoch 0: train accuracy: 0.4912\n",
      "\t Epoch 500: train accuracy: 0.9938\n",
      "\t Epoch 1000: train accuracy: 0.9938\n",
      "\t Epoch 1500: train accuracy: 0.9938\n",
      "\t Epoch 2000: train accuracy: 0.9938\n",
      "\t Epoch 2500: train accuracy: 0.8351\n",
      "\t Epoch 3000: train accuracy: 0.8351\n",
      "\t Epoch 3500: train accuracy: 0.8351\n",
      "\t Epoch 4000: train accuracy: 0.8351\n",
      "\t Epoch 0: train accuracy: 0.5088\n",
      "\t Epoch 500: train accuracy: 0.9938\n",
      "\t Epoch 1000: train accuracy: 0.9938\n",
      "\t Epoch 1500: train accuracy: 0.9938\n",
      "\t Epoch 2000: train accuracy: 0.9938\n",
      "\t Epoch 2500: train accuracy: 0.9264\n",
      "\t Epoch 3000: train accuracy: 0.9264\n",
      "\t Epoch 3500: train accuracy: 0.9264\n",
      "\t Epoch 4000: train accuracy: 0.9264\n",
      "\t Model's accuracy: 0.8366\n",
      "\t Class 1 - Global explanation: \"(~h5 & (h3 | h8 | h9 | ~h7))\" - Accuracy: 71.4400\n",
      "\t Elapsed time 0.04689669609069824\n",
      "\t Class 0 - Global explanation: \"(h5 | (h2 & ~h1) | (h7 & ~h1 & ~h3 & ~h6))\" - Accuracy: 91.8800\n",
      "\t Elapsed time 0.07810521125793457\n",
      "Seed [2/10]\n",
      "\t Epoch 0: train accuracy: 0.4912\n",
      "\t Epoch 500: train accuracy: 0.9938\n",
      "\t Epoch 1000: train accuracy: 0.9938\n",
      "\t Epoch 1500: train accuracy: 0.9938\n",
      "\t Epoch 2000: train accuracy: 0.9938\n",
      "\t Epoch 2500: train accuracy: 0.8329\n",
      "\t Epoch 3000: train accuracy: 0.8329\n",
      "\t Epoch 3500: train accuracy: 0.8329\n",
      "\t Epoch 4000: train accuracy: 0.8329\n",
      "\t Epoch 0: train accuracy: 0.5088\n",
      "\t Epoch 500: train accuracy: 0.9938\n",
      "\t Epoch 1000: train accuracy: 0.9938\n",
      "\t Epoch 1500: train accuracy: 0.9938\n",
      "\t Epoch 2000: train accuracy: 0.9938\n",
      "\t Epoch 2500: train accuracy: 0.7157\n",
      "\t Epoch 3000: train accuracy: 0.7157\n",
      "\t Epoch 3500: train accuracy: 0.7157\n",
      "\t Epoch 4000: train accuracy: 0.7157\n",
      "\t Model's accuracy: 0.8286\n",
      "\t Class 1 - Global explanation: \"(~h5 & (h6 | ~h0) & (h1 | h3 | h6 | h8))\" - Accuracy: 82.8600\n",
      "\t Elapsed time 0.046897172927856445\n",
      "\t Class 0 - Global explanation: \"((h2 | h5) & (h2 | ~h1) & (h2 | ~h6) & (h5 | ~h3) & (~h1 | ~h3) & (~h3 | ~h6))\" - Accuracy: 49.2600\n",
      "\t Elapsed time 0.05336952209472656\n",
      "Seed [3/10]\n",
      "\t Epoch 0: train accuracy: 0.5088\n",
      "\t Epoch 500: train accuracy: 0.9938\n",
      "\t Epoch 1000: train accuracy: 0.9938\n",
      "\t Epoch 1500: train accuracy: 0.9938\n",
      "\t Epoch 2000: train accuracy: 0.9938\n",
      "\t Epoch 2500: train accuracy: 0.8747\n",
      "\t Epoch 3000: train accuracy: 0.8747\n",
      "\t Epoch 3500: train accuracy: 0.8747\n",
      "\t Epoch 4000: train accuracy: 0.8747\n",
      "\t Epoch 0: train accuracy: 0.4912\n",
      "\t Epoch 500: train accuracy: 0.9938\n",
      "\t Epoch 1000: train accuracy: 0.9938\n",
      "\t Epoch 1500: train accuracy: 0.9938\n",
      "\t Epoch 2000: train accuracy: 0.9938\n",
      "\t Epoch 2500: train accuracy: 0.8351\n",
      "\t Epoch 3000: train accuracy: 0.8351\n",
      "\t Epoch 3500: train accuracy: 0.8351\n",
      "\t Epoch 4000: train accuracy: 0.8351\n",
      "\t Model's accuracy: 0.8752\n",
      "\t Class 1 - Global explanation: \"(h1 | h3 | ~h0 | (h9 & ~h5))\" - Accuracy: 58.1000\n",
      "\t Elapsed time 0.04686856269836426\n",
      "\t Class 0 - Global explanation: \"(~h3 & ~h6 & ~h8 & (h0 | ~h9))\" - Accuracy: 57.7500\n",
      "\t Elapsed time 0.046869516372680664\n",
      "Seed [4/10]\n",
      "\t Epoch 0: train accuracy: 0.5088\n",
      "\t Epoch 500: train accuracy: 0.9938\n",
      "\t Epoch 1000: train accuracy: 0.9938\n",
      "\t Epoch 1500: train accuracy: 0.9938\n",
      "\t Epoch 2000: train accuracy: 0.9938\n",
      "\t Epoch 2500: train accuracy: 0.8747\n",
      "\t Epoch 3000: train accuracy: 0.8747\n",
      "\t Epoch 3500: train accuracy: 0.8747\n",
      "\t Epoch 4000: train accuracy: 0.8747\n",
      "\t Epoch 0: train accuracy: 0.4912\n",
      "\t Epoch 500: train accuracy: 0.9938\n",
      "\t Epoch 1000: train accuracy: 0.9938\n",
      "\t Epoch 1500: train accuracy: 0.9938\n",
      "\t Epoch 2000: train accuracy: 0.9938\n",
      "\t Epoch 2500: train accuracy: 0.7195\n",
      "\t Epoch 3000: train accuracy: 0.8351\n",
      "\t Epoch 3500: train accuracy: 0.8351\n",
      "\t Epoch 4000: train accuracy: 0.8351\n",
      "\t Model's accuracy: 0.8752\n",
      "\t Class 1 - Global explanation: \"(h1 | h8 | h9 | (h3 & ~h0 & ~h7))\" - Accuracy: 87.5200\n",
      "\t Elapsed time 0.08465433120727539\n",
      "\t Class 0 - Global explanation: \"(h7 & ~h3 & ~h6 & ~h8)\" - Accuracy: 71.4400\n",
      "\t Elapsed time 0.05335044860839844\n",
      "Seed [5/10]\n",
      "\t Epoch 0: train accuracy: 0.4912\n",
      "\t Epoch 500: train accuracy: 0.9938\n",
      "\t Epoch 1000: train accuracy: 0.9938\n",
      "\t Epoch 1500: train accuracy: 0.9938\n",
      "\t Epoch 2000: train accuracy: 0.9938\n",
      "\t Epoch 2500: train accuracy: 0.8607\n",
      "\t Epoch 3000: train accuracy: 0.8607\n",
      "\t Epoch 3500: train accuracy: 0.8607\n",
      "\t Epoch 4000: train accuracy: 0.8607\n",
      "\t Epoch 0: train accuracy: 0.5088\n",
      "\t Epoch 500: train accuracy: 0.9938\n",
      "\t Epoch 1000: train accuracy: 0.9938\n",
      "\t Epoch 1500: train accuracy: 0.9938\n",
      "\t Epoch 2000: train accuracy: 0.9938\n",
      "\t Epoch 2500: train accuracy: 0.7173\n",
      "\t Epoch 3000: train accuracy: 0.7173\n",
      "\t Epoch 3500: train accuracy: 0.7173\n",
      "\t Epoch 4000: train accuracy: 0.7173\n",
      "\t Model's accuracy: 0.8504\n",
      "\t Class 1 - Global explanation: \"(h9 | (h3 & ~h2 & ~h7))\" - Accuracy: 64.0300\n",
      "\t Elapsed time 0.046862125396728516\n",
      "\t Class 0 - Global explanation: \"(~h6 & ~h8 & (h0 | h2))\" - Accuracy: 71.7000\n",
      "\t Elapsed time 0.05343508720397949\n",
      "Seed [6/10]\n",
      "\t Epoch 0: train accuracy: 0.4912\n",
      "\t Epoch 500: train accuracy: 0.8725\n",
      "\t Epoch 1000: train accuracy: 0.9938\n",
      "\t Epoch 1500: train accuracy: 0.9938\n",
      "\t Epoch 2000: train accuracy: 0.9938\n",
      "\t Epoch 2500: train accuracy: 0.8526\n",
      "\t Epoch 3000: train accuracy: 0.8526\n",
      "\t Epoch 3500: train accuracy: 0.8526\n",
      "\t Epoch 4000: train accuracy: 0.8526\n",
      "\t Epoch 0: train accuracy: 0.5088\n",
      "\t Epoch 500: train accuracy: 0.5088\n",
      "\t Epoch 1000: train accuracy: 0.9938\n",
      "\t Epoch 1500: train accuracy: 0.9938\n",
      "\t Epoch 2000: train accuracy: 0.9938\n",
      "\t Epoch 2500: train accuracy: 0.6148\n",
      "\t Epoch 3000: train accuracy: 0.6148\n",
      "\t Epoch 3500: train accuracy: 0.6148\n",
      "\t Epoch 4000: train accuracy: 0.6148\n",
      "\t Model's accuracy: 0.8564\n",
      "\t Class 1 - Global explanation: \"(~h0 & ~h5 & ~h7)\" - Accuracy: 85.6400\n",
      "\t Elapsed time 0.05337023735046387\n",
      "\t Class 0 - Global explanation: \"(~h6 & ~h9)\" - Accuracy: 61.5800\n",
      "\t Elapsed time 0.02692866325378418\n",
      "Seed [7/10]\n",
      "\t Epoch 0: train accuracy: 0.5088\n",
      "\t Epoch 500: train accuracy: 0.9938\n",
      "\t Epoch 1000: train accuracy: 0.9938\n",
      "\t Epoch 1500: train accuracy: 0.9938\n",
      "\t Epoch 2000: train accuracy: 0.9938\n",
      "\t Epoch 2500: train accuracy: 0.7852\n",
      "\t Epoch 3000: train accuracy: 0.7852\n",
      "\t Epoch 3500: train accuracy: 0.7852\n",
      "\t Epoch 4000: train accuracy: 0.7852\n",
      "\t Epoch 0: train accuracy: 0.4912\n",
      "\t Epoch 500: train accuracy: 0.9938\n",
      "\t Epoch 1000: train accuracy: 0.9938\n",
      "\t Epoch 1500: train accuracy: 0.9938\n",
      "\t Epoch 2000: train accuracy: 0.9938\n",
      "\t Epoch 2500: train accuracy: 0.7830\n",
      "\t Epoch 3000: train accuracy: 0.7830\n",
      "\t Epoch 3500: train accuracy: 0.7830\n",
      "\t Epoch 4000: train accuracy: 0.7830\n",
      "\t Model's accuracy: 0.7828\n",
      "\t Class 1 - Global explanation: \"((h3 & h6) | (h3 & ~h7) | (h6 & ~h5) | (~h5 & ~h7))\" - Accuracy: 78.2800\n",
      "\t Elapsed time 0.03780484199523926\n",
      "\t Class 0 - Global explanation: \"(h0 | h2 | (h5 & ~h9))\" - Accuracy: 78.5400\n",
      "\t Elapsed time 0.04686570167541504\n",
      "Seed [8/10]\n",
      "\t Epoch 0: train accuracy: 0.5088\n",
      "\t Epoch 500: train accuracy: 0.9938\n",
      "\t Epoch 1000: train accuracy: 0.9938\n",
      "\t Epoch 1500: train accuracy: 0.9938\n",
      "\t Epoch 2000: train accuracy: 0.9938\n",
      "\t Epoch 2500: train accuracy: 0.9280\n",
      "\t Epoch 3000: train accuracy: 0.9280\n",
      "\t Epoch 3500: train accuracy: 0.9280\n",
      "\t Epoch 4000: train accuracy: 0.9280\n",
      "\t Epoch 0: train accuracy: 0.4912\n",
      "\t Epoch 500: train accuracy: 0.9938\n",
      "\t Epoch 1000: train accuracy: 0.9938\n",
      "\t Epoch 1500: train accuracy: 0.9938\n",
      "\t Epoch 2000: train accuracy: 0.9938\n",
      "\t Epoch 2500: train accuracy: 0.6148\n",
      "\t Epoch 3000: train accuracy: 0.6148\n",
      "\t Epoch 3500: train accuracy: 0.6148\n",
      "\t Epoch 4000: train accuracy: 0.6148\n",
      "\t Model's accuracy: 0.9240\n",
      "\t Class 1 - Global explanation: \"((h6 & h8) | (h6 & ~h7) | (h8 & ~h2) | (h9 & ~h2 & ~h7) | (~h0 & ~h2 & ~h7))\" - Accuracy: 92.4000\n",
      "\t Elapsed time 0.06897997856140137\n",
      "\t Class 0 - Global explanation: \"(h0 & ~h6 & ~h9)\" - Accuracy: 58.1000\n",
      "\t Elapsed time 0.05337882041931152\n",
      "Seed [9/10]\n",
      "\t Epoch 0: train accuracy: 0.4912\n",
      "\t Epoch 500: train accuracy: 0.9938\n",
      "\t Epoch 1000: train accuracy: 0.9938\n",
      "\t Epoch 1500: train accuracy: 0.9938\n",
      "\t Epoch 2000: train accuracy: 0.9938\n",
      "\t Epoch 2500: train accuracy: 0.8747\n",
      "\t Epoch 3000: train accuracy: 0.8747\n",
      "\t Epoch 3500: train accuracy: 0.8747\n",
      "\t Epoch 4000: train accuracy: 0.8747\n",
      "\t Epoch 0: train accuracy: 0.5088\n",
      "\t Epoch 500: train accuracy: 0.9938\n",
      "\t Epoch 1000: train accuracy: 0.9938\n",
      "\t Epoch 1500: train accuracy: 0.9938\n",
      "\t Epoch 2000: train accuracy: 0.9938\n",
      "\t Epoch 2500: train accuracy: 0.8526\n",
      "\t Epoch 3000: train accuracy: 0.7852\n",
      "\t Epoch 3500: train accuracy: 0.8526\n",
      "\t Epoch 4000: train accuracy: 0.8526\n",
      "\t Model's accuracy: 0.8752\n",
      "\t Class 1 - Global explanation: \"(h1 | h3 | h8 | h9)\" - Accuracy: 87.5200\n",
      "\t Elapsed time 0.049805402755737305\n",
      "\t Class 0 - Global explanation: \"(h5 | ~h8 | (h0 & h7 & ~h6))\" - Accuracy: 65.0600\n",
      "\t Elapsed time 0.060192108154296875\n",
      "Seed [10/10]\n",
      "\t Epoch 0: train accuracy: 0.4912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 500: train accuracy: 0.9938\n",
      "\t Epoch 1000: train accuracy: 0.9938\n",
      "\t Epoch 1500: train accuracy: 0.9938\n",
      "\t Epoch 2000: train accuracy: 0.9938\n",
      "\t Epoch 2500: train accuracy: 0.5508\n",
      "\t Epoch 3000: train accuracy: 0.7116\n",
      "\t Epoch 3500: train accuracy: 0.7116\n",
      "\t Epoch 4000: train accuracy: 0.7116\n",
      "\t Epoch 0: train accuracy: 0.5088\n",
      "\t Epoch 500: train accuracy: 0.9938\n",
      "\t Epoch 1000: train accuracy: 0.9938\n",
      "\t Epoch 1500: train accuracy: 0.9938\n",
      "\t Epoch 2000: train accuracy: 0.9938\n",
      "\t Epoch 2500: train accuracy: 0.8607\n",
      "\t Epoch 3000: train accuracy: 0.8607\n",
      "\t Epoch 3500: train accuracy: 0.8607\n",
      "\t Epoch 4000: train accuracy: 0.8607\n",
      "\t Model's accuracy: 0.7134\n",
      "\t Class 1 - Global explanation: \"(h3 | h8)\" - Accuracy: 71.3400\n",
      "\t Elapsed time 0.029570341110229492\n",
      "\t Class 0 - Global explanation: \"((h2 | h7) & (h0 | ~h1) & (h0 | ~h8) & (~h1 | ~h9) & (~h8 | ~h9))\" - Accuracy: 49.2600\n",
      "\t Elapsed time 0.07990479469299316\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>explanation_inv</th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_accuracy_inv</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>elapsed_time_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>psi</td>\n",
       "      <td>0</td>\n",
       "      <td>(~h5 &amp; (h3 | h8 | h9 | ~h7))</td>\n",
       "      <td>(h5 | (h2 &amp; ~h1) | (h7 &amp; ~h1 &amp; ~h3 &amp; ~h6))</td>\n",
       "      <td>0.8366</td>\n",
       "      <td>71.44</td>\n",
       "      <td>91.88</td>\n",
       "      <td>0.046897</td>\n",
       "      <td>0.078105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>psi</td>\n",
       "      <td>1</td>\n",
       "      <td>(~h5 &amp; (h6 | ~h0) &amp; (h1 | h3 | h6 | h8))</td>\n",
       "      <td>((h2 | h5) &amp; (h2 | ~h1) &amp; (h2 | ~h6) &amp; (h5 | ~...</td>\n",
       "      <td>0.8286</td>\n",
       "      <td>82.86</td>\n",
       "      <td>49.26</td>\n",
       "      <td>0.046897</td>\n",
       "      <td>0.053370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>psi</td>\n",
       "      <td>2</td>\n",
       "      <td>(h1 | h3 | ~h0 | (h9 &amp; ~h5))</td>\n",
       "      <td>(~h3 &amp; ~h6 &amp; ~h8 &amp; (h0 | ~h9))</td>\n",
       "      <td>0.8752</td>\n",
       "      <td>58.10</td>\n",
       "      <td>57.75</td>\n",
       "      <td>0.046869</td>\n",
       "      <td>0.046870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>psi</td>\n",
       "      <td>3</td>\n",
       "      <td>(h1 | h8 | h9 | (h3 &amp; ~h0 &amp; ~h7))</td>\n",
       "      <td>(h7 &amp; ~h3 &amp; ~h6 &amp; ~h8)</td>\n",
       "      <td>0.8752</td>\n",
       "      <td>87.52</td>\n",
       "      <td>71.44</td>\n",
       "      <td>0.084654</td>\n",
       "      <td>0.053350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>psi</td>\n",
       "      <td>4</td>\n",
       "      <td>(h9 | (h3 &amp; ~h2 &amp; ~h7))</td>\n",
       "      <td>(~h6 &amp; ~h8 &amp; (h0 | h2))</td>\n",
       "      <td>0.8504</td>\n",
       "      <td>64.03</td>\n",
       "      <td>71.70</td>\n",
       "      <td>0.046862</td>\n",
       "      <td>0.053435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>psi</td>\n",
       "      <td>5</td>\n",
       "      <td>(~h0 &amp; ~h5 &amp; ~h7)</td>\n",
       "      <td>(~h6 &amp; ~h9)</td>\n",
       "      <td>0.8564</td>\n",
       "      <td>85.64</td>\n",
       "      <td>61.58</td>\n",
       "      <td>0.053370</td>\n",
       "      <td>0.026929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>psi</td>\n",
       "      <td>6</td>\n",
       "      <td>((h3 &amp; h6) | (h3 &amp; ~h7) | (h6 &amp; ~h5) | (~h5 &amp; ...</td>\n",
       "      <td>(h0 | h2 | (h5 &amp; ~h9))</td>\n",
       "      <td>0.7828</td>\n",
       "      <td>78.28</td>\n",
       "      <td>78.54</td>\n",
       "      <td>0.037805</td>\n",
       "      <td>0.046866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>psi</td>\n",
       "      <td>7</td>\n",
       "      <td>((h6 &amp; h8) | (h6 &amp; ~h7) | (h8 &amp; ~h2) | (h9 &amp; ~...</td>\n",
       "      <td>(h0 &amp; ~h6 &amp; ~h9)</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>92.40</td>\n",
       "      <td>58.10</td>\n",
       "      <td>0.068980</td>\n",
       "      <td>0.053379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>psi</td>\n",
       "      <td>8</td>\n",
       "      <td>(h1 | h3 | h8 | h9)</td>\n",
       "      <td>(h5 | ~h8 | (h0 &amp; h7 &amp; ~h6))</td>\n",
       "      <td>0.8752</td>\n",
       "      <td>87.52</td>\n",
       "      <td>65.06</td>\n",
       "      <td>0.049805</td>\n",
       "      <td>0.060192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>psi</td>\n",
       "      <td>9</td>\n",
       "      <td>(h3 | h8)</td>\n",
       "      <td>((h2 | h7) &amp; (h0 | ~h1) &amp; (h0 | ~h8) &amp; (~h1 | ...</td>\n",
       "      <td>0.7134</td>\n",
       "      <td>71.34</td>\n",
       "      <td>49.26</td>\n",
       "      <td>0.029570</td>\n",
       "      <td>0.079905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  split                                        explanation  \\\n",
       "0    psi      0                       (~h5 & (h3 | h8 | h9 | ~h7))   \n",
       "1    psi      1           (~h5 & (h6 | ~h0) & (h1 | h3 | h6 | h8))   \n",
       "2    psi      2                       (h1 | h3 | ~h0 | (h9 & ~h5))   \n",
       "3    psi      3                  (h1 | h8 | h9 | (h3 & ~h0 & ~h7))   \n",
       "4    psi      4                            (h9 | (h3 & ~h2 & ~h7))   \n",
       "5    psi      5                                  (~h0 & ~h5 & ~h7)   \n",
       "6    psi      6  ((h3 & h6) | (h3 & ~h7) | (h6 & ~h5) | (~h5 & ...   \n",
       "7    psi      7  ((h6 & h8) | (h6 & ~h7) | (h8 & ~h2) | (h9 & ~...   \n",
       "8    psi      8                                (h1 | h3 | h8 | h9)   \n",
       "9    psi      9                                          (h3 | h8)   \n",
       "\n",
       "                                     explanation_inv  model_accuracy  \\\n",
       "0         (h5 | (h2 & ~h1) | (h7 & ~h1 & ~h3 & ~h6))          0.8366   \n",
       "1  ((h2 | h5) & (h2 | ~h1) & (h2 | ~h6) & (h5 | ~...          0.8286   \n",
       "2                     (~h3 & ~h6 & ~h8 & (h0 | ~h9))          0.8752   \n",
       "3                             (h7 & ~h3 & ~h6 & ~h8)          0.8752   \n",
       "4                            (~h6 & ~h8 & (h0 | h2))          0.8504   \n",
       "5                                        (~h6 & ~h9)          0.8564   \n",
       "6                             (h0 | h2 | (h5 & ~h9))          0.7828   \n",
       "7                                   (h0 & ~h6 & ~h9)          0.9240   \n",
       "8                       (h5 | ~h8 | (h0 & h7 & ~h6))          0.8752   \n",
       "9  ((h2 | h7) & (h0 | ~h1) & (h0 | ~h8) & (~h1 | ...          0.7134   \n",
       "\n",
       "   explanation_accuracy  explanation_accuracy_inv  elapsed_time  \\\n",
       "0                 71.44                     91.88      0.046897   \n",
       "1                 82.86                     49.26      0.046897   \n",
       "2                 58.10                     57.75      0.046869   \n",
       "3                 87.52                     71.44      0.084654   \n",
       "4                 64.03                     71.70      0.046862   \n",
       "5                 85.64                     61.58      0.053370   \n",
       "6                 78.28                     78.54      0.037805   \n",
       "7                 92.40                     58.10      0.068980   \n",
       "8                 87.52                     65.06      0.049805   \n",
       "9                 71.34                     49.26      0.029570   \n",
       "\n",
       "   elapsed_time_inv  \n",
       "0          0.078105  \n",
       "1          0.053370  \n",
       "2          0.046870  \n",
       "3          0.053350  \n",
       "4          0.053435  \n",
       "5          0.026929  \n",
       "6          0.046866  \n",
       "7          0.053379  \n",
       "8          0.060192  \n",
       "9          0.079905  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = 'psi'\n",
    "need_pruning = True\n",
    "relu = False\n",
    "results_psi = c_to_y(method, need_pruning, relu, verbose=True)\n",
    "results_psi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed [1/10]\n",
      "Seed [2/10]\n",
      "Seed [3/10]\n",
      "Seed [4/10]\n",
      "Seed [5/10]\n",
      "Seed [6/10]\n",
      "Seed [7/10]\n",
      "Seed [8/10]\n",
      "Seed [9/10]\n",
      "Seed [10/10]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>explanation_inv</th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_accuracy_inv</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>elapsed_time_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tree</td>\n",
       "      <td>0</td>\n",
       "      <td>(h7 &lt;= 0.50 &amp; h2 &lt;= 0.50 &amp; h0 &lt;= 0.50 &amp; h5 &lt;= ...</td>\n",
       "      <td>(h7 &lt;= 0.50 &amp; h2 &lt;= 0.50 &amp; h0 &lt;= 0.50 &amp; h5 &gt; 0...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>(h7 &lt;= 0.50 &amp; h2 &lt;= 0.50 &amp; h0 &lt;= 0.50 &amp; h5 &lt;= ...</td>\n",
       "      <td>(h7 &lt;= 0.50 &amp; h2 &lt;= 0.50 &amp; h0 &lt;= 0.50 &amp; h5 &gt; 0...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>(h7 &lt;= 0.50 &amp; h2 &lt;= 0.50 &amp; h0 &lt;= 0.50 &amp; h5 &lt;= ...</td>\n",
       "      <td>(h7 &lt;= 0.50 &amp; h2 &lt;= 0.50 &amp; h0 &lt;= 0.50 &amp; h5 &gt; 0...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>(h7 &lt;= 0.50 &amp; h2 &lt;= 0.50 &amp; h0 &lt;= 0.50 &amp; h5 &lt;= ...</td>\n",
       "      <td>(h7 &lt;= 0.50 &amp; h2 &lt;= 0.50 &amp; h0 &lt;= 0.50 &amp; h5 &gt; 0...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>(h7 &lt;= 0.50 &amp; h2 &lt;= 0.50 &amp; h0 &lt;= 0.50 &amp; h5 &lt;= ...</td>\n",
       "      <td>(h7 &lt;= 0.50 &amp; h2 &lt;= 0.50 &amp; h0 &lt;= 0.50 &amp; h5 &gt; 0...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>(h7 &lt;= 0.50 &amp; h2 &lt;= 0.50 &amp; h0 &lt;= 0.50 &amp; h5 &lt;= ...</td>\n",
       "      <td>(h7 &lt;= 0.50 &amp; h2 &lt;= 0.50 &amp; h0 &lt;= 0.50 &amp; h5 &gt; 0...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tree</td>\n",
       "      <td>6</td>\n",
       "      <td>(h7 &lt;= 0.50 &amp; h2 &lt;= 0.50 &amp; h0 &lt;= 0.50 &amp; h5 &lt;= ...</td>\n",
       "      <td>(h7 &lt;= 0.50 &amp; h2 &lt;= 0.50 &amp; h0 &lt;= 0.50 &amp; h5 &gt; 0...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tree</td>\n",
       "      <td>7</td>\n",
       "      <td>(h7 &lt;= 0.50 &amp; h2 &lt;= 0.50 &amp; h0 &lt;= 0.50 &amp; h5 &lt;= ...</td>\n",
       "      <td>(h7 &lt;= 0.50 &amp; h2 &lt;= 0.50 &amp; h0 &lt;= 0.50 &amp; h5 &gt; 0...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tree</td>\n",
       "      <td>8</td>\n",
       "      <td>(h7 &lt;= 0.50 &amp; h2 &lt;= 0.50 &amp; h0 &lt;= 0.50 &amp; h5 &lt;= ...</td>\n",
       "      <td>(h7 &lt;= 0.50 &amp; h2 &lt;= 0.50 &amp; h0 &lt;= 0.50 &amp; h5 &gt; 0...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tree</td>\n",
       "      <td>9</td>\n",
       "      <td>(h7 &lt;= 0.50 &amp; h2 &lt;= 0.50 &amp; h0 &lt;= 0.50 &amp; h5 &lt;= ...</td>\n",
       "      <td>(h7 &lt;= 0.50 &amp; h2 &lt;= 0.50 &amp; h0 &lt;= 0.50 &amp; h5 &gt; 0...</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  split                                        explanation  \\\n",
       "0   tree      0  (h7 <= 0.50 & h2 <= 0.50 & h0 <= 0.50 & h5 <= ...   \n",
       "1   tree      1  (h7 <= 0.50 & h2 <= 0.50 & h0 <= 0.50 & h5 <= ...   \n",
       "2   tree      2  (h7 <= 0.50 & h2 <= 0.50 & h0 <= 0.50 & h5 <= ...   \n",
       "3   tree      3  (h7 <= 0.50 & h2 <= 0.50 & h0 <= 0.50 & h5 <= ...   \n",
       "4   tree      4  (h7 <= 0.50 & h2 <= 0.50 & h0 <= 0.50 & h5 <= ...   \n",
       "5   tree      5  (h7 <= 0.50 & h2 <= 0.50 & h0 <= 0.50 & h5 <= ...   \n",
       "6   tree      6  (h7 <= 0.50 & h2 <= 0.50 & h0 <= 0.50 & h5 <= ...   \n",
       "7   tree      7  (h7 <= 0.50 & h2 <= 0.50 & h0 <= 0.50 & h5 <= ...   \n",
       "8   tree      8  (h7 <= 0.50 & h2 <= 0.50 & h0 <= 0.50 & h5 <= ...   \n",
       "9   tree      9  (h7 <= 0.50 & h2 <= 0.50 & h0 <= 0.50 & h5 <= ...   \n",
       "\n",
       "                                     explanation_inv  model_accuracy  \\\n",
       "0  (h7 <= 0.50 & h2 <= 0.50 & h0 <= 0.50 & h5 > 0...          0.9924   \n",
       "1  (h7 <= 0.50 & h2 <= 0.50 & h0 <= 0.50 & h5 > 0...          0.9924   \n",
       "2  (h7 <= 0.50 & h2 <= 0.50 & h0 <= 0.50 & h5 > 0...          0.9924   \n",
       "3  (h7 <= 0.50 & h2 <= 0.50 & h0 <= 0.50 & h5 > 0...          0.9924   \n",
       "4  (h7 <= 0.50 & h2 <= 0.50 & h0 <= 0.50 & h5 > 0...          0.9924   \n",
       "5  (h7 <= 0.50 & h2 <= 0.50 & h0 <= 0.50 & h5 > 0...          0.9924   \n",
       "6  (h7 <= 0.50 & h2 <= 0.50 & h0 <= 0.50 & h5 > 0...          0.9924   \n",
       "7  (h7 <= 0.50 & h2 <= 0.50 & h0 <= 0.50 & h5 > 0...          0.9924   \n",
       "8  (h7 <= 0.50 & h2 <= 0.50 & h0 <= 0.50 & h5 > 0...          0.9924   \n",
       "9  (h7 <= 0.50 & h2 <= 0.50 & h0 <= 0.50 & h5 > 0...          0.9924   \n",
       "\n",
       "   explanation_accuracy  explanation_accuracy_inv  elapsed_time  \\\n",
       "0                0.9924                    0.9924           0.0   \n",
       "1                0.9924                    0.9924           0.0   \n",
       "2                0.9924                    0.9924           0.0   \n",
       "3                0.9924                    0.9924           0.0   \n",
       "4                0.9924                    0.9924           0.0   \n",
       "5                0.9924                    0.9924           0.0   \n",
       "6                0.9924                    0.9924           0.0   \n",
       "7                0.9924                    0.9924           0.0   \n",
       "8                0.9924                    0.9924           0.0   \n",
       "9                0.9924                    0.9924           0.0   \n",
       "\n",
       "   elapsed_time_inv  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  \n",
       "5               0.0  \n",
       "6               0.0  \n",
       "7               0.0  \n",
       "8               0.0  \n",
       "9               0.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = 'tree'\n",
    "need_pruning = False\n",
    "relu = False\n",
    "results_tree = c_to_y(method, need_pruning, relu)\n",
    "results_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_accuracy_mean</th>\n",
       "      <th>explanation_accuracy_mean</th>\n",
       "      <th>explanation_accuracy_inv_mean</th>\n",
       "      <th>elapsed_time_mean</th>\n",
       "      <th>elapsed_time_inv_mean</th>\n",
       "      <th>model_accuracy_sem</th>\n",
       "      <th>explanation_accuracy_sem</th>\n",
       "      <th>explanation_accuracy_inv_sem</th>\n",
       "      <th>elapsed_time_sem</th>\n",
       "      <th>elapsed_time_inv_sem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pruning</th>\n",
       "      <td>0.99240</td>\n",
       "      <td>99.2400</td>\n",
       "      <td>99.2400</td>\n",
       "      <td>0.020337</td>\n",
       "      <td>0.039453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.001981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weights</th>\n",
       "      <td>0.99240</td>\n",
       "      <td>86.8640</td>\n",
       "      <td>99.2400</td>\n",
       "      <td>0.126180</td>\n",
       "      <td>0.037748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.895255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076019</td>\n",
       "      <td>0.001672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psi</th>\n",
       "      <td>0.84178</td>\n",
       "      <td>77.9130</td>\n",
       "      <td>65.4570</td>\n",
       "      <td>0.051171</td>\n",
       "      <td>0.055240</td>\n",
       "      <td>0.018427</td>\n",
       "      <td>3.573316</td>\n",
       "      <td>4.213087</td>\n",
       "      <td>0.004903</td>\n",
       "      <td>0.004843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>0.99240</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model_accuracy_mean  explanation_accuracy_mean  \\\n",
       "pruning              0.99240                    99.2400   \n",
       "weights              0.99240                    86.8640   \n",
       "psi                  0.84178                    77.9130   \n",
       "tree                 0.99240                     0.9924   \n",
       "\n",
       "         explanation_accuracy_inv_mean  elapsed_time_mean  \\\n",
       "pruning                        99.2400           0.020337   \n",
       "weights                        99.2400           0.126180   \n",
       "psi                            65.4570           0.051171   \n",
       "tree                            0.9924           0.000000   \n",
       "\n",
       "         elapsed_time_inv_mean  model_accuracy_sem  explanation_accuracy_sem  \\\n",
       "pruning               0.039453            0.000000                  0.000000   \n",
       "weights               0.037748            0.000000                  4.895255   \n",
       "psi                   0.055240            0.018427                  3.573316   \n",
       "tree                  0.000000            0.000000                  0.000000   \n",
       "\n",
       "         explanation_accuracy_inv_sem  elapsed_time_sem  elapsed_time_inv_sem  \n",
       "pruning                      0.000000          0.001924              0.001981  \n",
       "weights                      0.000000          0.076019              0.001672  \n",
       "psi                          4.213087          0.004903              0.004843  \n",
       "tree                         0.000000          0.000000              0.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['model_accuracy', 'explanation_accuracy', 'explanation_accuracy_inv', 'elapsed_time', 'elapsed_time_inv']\n",
    "mean_cols = [f'{c}_mean' for c in cols]\n",
    "sem_cols = [f'{c}_sem' for c in cols]\n",
    "\n",
    "# pruning\n",
    "df_mean = results_pruning[cols].mean()\n",
    "df_sem = results_pruning[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_pruning = pd.concat([df_mean, df_sem])\n",
    "summary_pruning.name = 'pruning'\n",
    "\n",
    "# # lime\n",
    "# df_mean = results_lime[cols].mean()\n",
    "# df_sem = results_lime[cols].sem()\n",
    "# df_mean.columns = mean_cols\n",
    "# df_sem.columns = sem_cols\n",
    "# summary_lime = pd.concat([df_mean, df_sem])\n",
    "# summary_lime.name = 'lime'\n",
    "\n",
    "# weights\n",
    "df_mean = results_weights[cols].mean()\n",
    "df_sem = results_weights[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_weights = pd.concat([df_mean, df_sem])\n",
    "summary_weights.name = 'weights'\n",
    "\n",
    "# psi\n",
    "df_mean = results_psi[cols].mean()\n",
    "df_sem = results_psi[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_psi = pd.concat([df_mean, df_sem])\n",
    "summary_psi.name = 'psi'\n",
    "\n",
    "# tree\n",
    "df_mean = results_tree[cols].mean()\n",
    "df_sem = results_tree[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_tree = pd.concat([df_mean, df_sem])\n",
    "summary_tree.name = 'tree'\n",
    "\n",
    "summary = pd.concat([summary_pruning, \n",
    "#                      summary_lime, \n",
    "                     summary_weights, summary_psi, summary_tree], axis=1).T\n",
    "summary.columns = mean_cols + sem_cols\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_csv(os.path.join(results_dir, 'summary.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
