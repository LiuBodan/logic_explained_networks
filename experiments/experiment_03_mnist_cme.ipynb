{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sympy import simplify_logic\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.tree import _tree, export_text\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from deep_logic.utils.base import validate_network, set_seed, tree_to_formula\n",
    "from deep_logic.utils.relunn import get_reduced_model, prune_features\n",
    "from deep_logic.utils.sigmoidnn import prune_equal_fanin\n",
    "from deep_logic import logic\n",
    "\n",
    "results_dir = 'results/mnist_h'\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "n_rep = 10\n",
    "tot_epochs = 4001\n",
    "prune_epochs = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST problem\n",
    "num_workers = 0\n",
    "batch_size = 128\n",
    "valid_size = 0.2\n",
    "# Data augmentation for train data + conversion to tensor\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "   \n",
    "])# Data augmentation for test data + conversion to tensor\n",
    "test_transforms= transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(0.5,))\n",
    "])\n",
    "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=train_transforms)\n",
    "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding indices for validation set\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "#Randomize indices\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(num_train*valid_size))\n",
    "train_index, test_index = indices[split:], indices[:split]# Making samplers for training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_index)\n",
    "valid_sampler = SubsetRandomSampler(test_index)# Creating data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # convolutional layers\n",
    "        self.conv1 = torch.nn.Conv2d(1, 8, 3, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(8, 16, 3, padding =1)\n",
    "        # linear layers\n",
    "        self.fc1 = torch.nn.Linear(784, 256)\n",
    "        self.fc2 = torch.nn.Linear(256, 128)\n",
    "        self.fc3 = torch.nn.Linear(128, 64)\n",
    "        self.fc4 = torch.nn.Linear(64, 2) \n",
    "        # dropout\n",
    "        self.dropout = torch.nn.Dropout(p=0.2)\n",
    "        # max pooling\n",
    "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # convolutional layers with ReLU and pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # flattening the image\n",
    "        x = x.view(-1, 7*7*16)\n",
    "        # linear layers\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = self.fc4(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "        \n",
    "model = Net()\n",
    "print(model)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "if os.path.isfile('trained_model_h.pt'):\n",
    "    model.load_state_dict(torch.load('trained_model_h.pt'))\n",
    "\n",
    "else:\n",
    "    # epochs to train for\n",
    "    epochs = 10\n",
    "    set_seed(0)\n",
    "\n",
    "    # tracks validation loss change after each epoch\n",
    "    minimum_validation_loss = np.inf \n",
    "\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr = 0.001)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(1, epochs+1):\n",
    "\n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "\n",
    "        # training steps\n",
    "        model.train()\n",
    "        for batch_index, (data, target) in enumerate(train_loader):\n",
    "            # moves tensors to GPU\n",
    "            data, target = data.cuda(), target.cuda() % 2\n",
    "            # clears gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass\n",
    "            output = model(data)\n",
    "            # loss in batch\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass for loss gradient\n",
    "            loss.backward()\n",
    "            # update paremeters\n",
    "            optimizer.step()\n",
    "            # update training loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "\n",
    "        # validation steps\n",
    "        model.eval()\n",
    "        for batch_index, (data, target) in enumerate(valid_loader):\n",
    "            # moves tensors to GPU\n",
    "            data, target = data.cuda(), target.cuda() % 2\n",
    "            # forward pass\n",
    "            output = model(data)\n",
    "            # loss in batch\n",
    "            loss = criterion(output, target)\n",
    "            # update validation loss\n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "\n",
    "        # average loss calculations\n",
    "        train_loss = train_loss/len(train_loader.sampler)\n",
    "        valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "\n",
    "        # Display loss statistics\n",
    "        print(f'Current Epoch: {epoch}\\nTraining Loss: {round(train_loss, 6)}\\nValidation Loss: {round(valid_loss, 6)}')\n",
    "\n",
    "        # Saving model every time validation loss decreases\n",
    "        if valid_loss <= minimum_validation_loss and epoch > 5:\n",
    "            print(f'Validation loss decreased from {round(minimum_validation_loss, 6)} to {round(valid_loss, 6)}')\n",
    "            torch.save(model.state_dict(), 'trained_model_h.pt')\n",
    "            minimum_validation_loss = valid_loss\n",
    "            print('Saving New Model')\n",
    "    \n",
    "    model.load_state_dict(torch.load('trained_model_h.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.320503\n",
      "Test Accuracy of 0: 100.0%\n",
      "Test Accuracy of 1: 97.4%\n",
      "Full Test Accuracy: 98.73% 156.0 out of 158.0\n"
     ]
    }
   ],
   "source": [
    "# tracking test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model.eval()\n",
    "classes = [0, 1]\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    # move tensors to GPU\n",
    "    data, target = data.cuda(), target.cuda() % 2\n",
    "    # forward pass\n",
    "    output = model(data)\n",
    "    # batch loss\n",
    "    loss = criterion(output, target)\n",
    "    # test loss update\n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(2):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print(f'Test Loss: {round(test_loss, 6)}')\n",
    "\n",
    "for i in range(2):\n",
    "    if class_total[i] > 0:\n",
    "        print(f'Test Accuracy of {classes[i]}: {round(100*class_correct[i]/class_total[i], 2)}%')\n",
    "    else:\n",
    "        print(f'Test Accuracy of {classes[i]}s: N/A (no training examples)')\n",
    "        \n",
    "        \n",
    "print(f'Full Test Accuracy: {round(100. * np.sum(class_correct) / np.sum(class_total), 2)}% {np.sum(class_correct)} out of {np.sum(class_total)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract concepts from hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48000, 128])\n",
      "torch.Size([48000])\n"
     ]
    }
   ],
   "source": [
    "pred_h_train = []\n",
    "true_y_train = []\n",
    "model.eval()\n",
    "model = model.cpu()\n",
    "for batch_index, (data, target) in enumerate(train_loader):\n",
    "    # moves tensors to GPU\n",
    "    data, target = data.cpu(), target.cpu() % 2\n",
    "    # forward pass\n",
    "    #output = model(data)\n",
    "    #pred = torch.argmax(output, 1)\n",
    "    \n",
    "    # get hidden layer's projection of the input\n",
    "    x = model.pool(F.relu(model.conv1(data)))\n",
    "    x = model.pool(F.relu(model.conv2(x)))\n",
    "    # flattening the image\n",
    "    x = x.view(-1, 7*7*16)\n",
    "    # linear layers\n",
    "    x = model.dropout(F.relu(model.fc1(x)))\n",
    "    x = model.dropout(F.relu(model.fc2(x)))\n",
    "    \n",
    "    pred_h_train.append(x.cpu())\n",
    "    true_y_train.append(target.cpu())\n",
    "\n",
    "pred_h_train = torch.cat(pred_h_train)\n",
    "true_y_train = torch.cat(true_y_train)\n",
    "print(pred_h_train.shape)\n",
    "print(true_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 128])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "pred_h_test = []\n",
    "true_y_test = []\n",
    "model.eval()\n",
    "model = model.cpu()\n",
    "for batch_index, (data, target) in enumerate(test_loader):\n",
    "    # moves tensors to GPU\n",
    "    data, target = data.cpu(), target.cpu() % 2\n",
    "    # forward pass\n",
    "    #output = model(data)\n",
    "    #pred = torch.argmax(output, 1)\n",
    "    \n",
    "    # get hidden layer's projection of the input\n",
    "    x = model.pool(F.relu(model.conv1(data)))\n",
    "    x = model.pool(F.relu(model.conv2(x)))\n",
    "    # flattening the image\n",
    "    x = x.view(-1, 7*7*16)\n",
    "    # linear layers\n",
    "    x = model.dropout(F.relu(model.fc1(x)))\n",
    "    x = model.dropout(F.relu(model.fc2(x)))\n",
    "    \n",
    "    pred_h_test.append(x.cpu())\n",
    "    true_y_test.append(target.cpu())\n",
    "\n",
    "pred_h_test = torch.cat(pred_h_test)\n",
    "true_y_test = torch.cat(true_y_test)\n",
    "print(pred_h_test.shape)\n",
    "print(true_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded = TSNE(n_components=2).fit_transform(pred_h_train.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(pred_h_train.detach().numpy())\n",
    "X_train = kmeans.predict(pred_h_train.detach().numpy())\n",
    "X_test = kmeans.predict(pred_h_test.detach().numpy())\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=X_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48000, 10])\n",
      "torch.Size([10000, 10])\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.FloatTensor(OneHotEncoder(sparse=False).fit_transform(X_train.reshape(-1, 1)))\n",
    "x_test = torch.FloatTensor(OneHotEncoder(sparse=False).fit_transform(X_test.reshape(-1, 1)))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48000])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "y_train = (true_y_train % 2 == 1).to(torch.long)\n",
    "y_test = (true_y_test % 2 == 1).to(torch.long)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h0', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'h7', 'h8', 'h9']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concepts = [f'h{i}' for i in range(x_train.shape[1])]\n",
    "concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(x_train, y_train, need_pruning, seed, device):\n",
    "    set_seed(seed)\n",
    "    x_train = x_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    layers = [\n",
    "        torch.nn.Linear(x_train.size(1), 100),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(100, 50),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(50, 30),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(30, 2),\n",
    "        torch.nn.Softmax(dim=1),\n",
    "    ]\n",
    "    model = torch.nn.Sequential(*layers).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "    loss_form = torch.nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    for epoch in range(tot_epochs):\n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_train)\n",
    "        # Compute Loss\n",
    "        loss = loss_form(y_pred, y_train)\n",
    "\n",
    "        for module in model.children():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                loss += 0.01 * torch.norm(module.weight, 1)\n",
    "                loss += 0.01 * torch.norm(module.bias, 1)\n",
    "                break\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch > prune_epochs and need_pruning:\n",
    "            prune_features(model, n_classes=1, device=device)\n",
    "            need_pruning = False\n",
    "            \n",
    "        # compute accuracy\n",
    "        if epoch % 500 == 0:\n",
    "            y_pred_d = torch.argmax(y_pred, dim=1)\n",
    "            accuracy = y_pred_d.eq(y_train).sum().item() / y_train.size(0)\n",
    "            print(f'\\t Epoch {epoch}: train accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed [1/10]\n",
      "\t Epoch 0: train accuracy: 0.4910\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.9939\n",
      "\t Epoch 3000: train accuracy: 0.9939\n",
      "\t Epoch 3500: train accuracy: 0.9939\n",
      "\t Epoch 4000: train accuracy: 0.9939\n",
      "\t Model's accuracy: 0.9928\n",
      "~feature0000000001 & ~feature0000000003 & ~feature0000000006 & ~feature0000000009\n",
      "\t Class 1 - Global explanation: \"~h1 & ~h3 & ~h6 & ~h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 65.44997954368591\n",
      "feature0000000001 | feature0000000003 | feature0000000006 | feature0000000009\n",
      "\t Class 0 - Global explanation: \"h1 | h3 | h6 | h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 51.40061378479004\n",
      "Seed [2/10]\n",
      "\t Epoch 0: train accuracy: 0.4910\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.9939\n",
      "\t Epoch 3000: train accuracy: 0.9939\n",
      "\t Epoch 3500: train accuracy: 0.9939\n",
      "\t Epoch 4000: train accuracy: 0.9939\n",
      "\t Model's accuracy: 0.9928\n",
      "~feature0000000001 & ~feature0000000003 & ~feature0000000006 & ~feature0000000009\n",
      "\t Class 1 - Global explanation: \"~h1 & ~h3 & ~h6 & ~h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 50.679115295410156\n",
      "feature0000000001 | feature0000000003 | feature0000000006 | feature0000000009\n",
      "\t Class 0 - Global explanation: \"h1 | h3 | h6 | h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 58.62730050086975\n",
      "Seed [3/10]\n",
      "\t Epoch 0: train accuracy: 0.5090\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.9939\n",
      "\t Epoch 3000: train accuracy: 0.9939\n",
      "\t Epoch 3500: train accuracy: 0.9939\n",
      "\t Epoch 4000: train accuracy: 0.9939\n",
      "\t Model's accuracy: 0.9928\n",
      "~feature0000000001 & ~feature0000000003 & ~feature0000000006 & ~feature0000000009\n",
      "\t Class 1 - Global explanation: \"~h1 & ~h3 & ~h6 & ~h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 57.36271095275879\n",
      "feature0000000001 | feature0000000003 | feature0000000006 | feature0000000009\n",
      "\t Class 0 - Global explanation: \"h1 | h3 | h6 | h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 58.14558672904968\n",
      "Seed [4/10]\n",
      "\t Epoch 0: train accuracy: 0.5090\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.9939\n",
      "\t Epoch 3000: train accuracy: 0.9939\n",
      "\t Epoch 3500: train accuracy: 0.9939\n",
      "\t Epoch 4000: train accuracy: 0.9939\n",
      "\t Model's accuracy: 0.9928\n",
      "~feature0000000001 & ~feature0000000003 & ~feature0000000006 & ~feature0000000009\n",
      "\t Class 1 - Global explanation: \"~h1 & ~h3 & ~h6 & ~h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 61.27322554588318\n",
      "feature0000000001 | feature0000000003 | feature0000000006 | feature0000000009\n",
      "\t Class 0 - Global explanation: \"h1 | h3 | h6 | h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 49.23344659805298\n",
      "Seed [5/10]\n",
      "\t Epoch 0: train accuracy: 0.5090\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.9939\n",
      "\t Epoch 3000: train accuracy: 0.9939\n",
      "\t Epoch 3500: train accuracy: 0.9939\n",
      "\t Epoch 4000: train accuracy: 0.9939\n",
      "\t Model's accuracy: 0.9928\n",
      "~feature0000000001 & ~feature0000000003 & ~feature0000000006 & ~feature0000000009\n",
      "\t Class 1 - Global explanation: \"~h1 & ~h3 & ~h6 & ~h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 58.92633509635925\n",
      "feature0000000001 | feature0000000003 | feature0000000006 | feature0000000009\n",
      "\t Class 0 - Global explanation: \"h1 | h3 | h6 | h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 58.84974932670593\n",
      "Seed [6/10]\n",
      "\t Epoch 0: train accuracy: 0.5090\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.9939\n",
      "\t Epoch 3000: train accuracy: 0.9939\n",
      "\t Epoch 3500: train accuracy: 0.9939\n",
      "\t Epoch 4000: train accuracy: 0.9939\n",
      "\t Model's accuracy: 0.9928\n",
      "~feature0000000001 & ~feature0000000003 & ~feature0000000006 & ~feature0000000009\n",
      "\t Class 1 - Global explanation: \"~h1 & ~h3 & ~h6 & ~h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 57.387614250183105\n",
      "feature0000000001 | feature0000000003 | feature0000000006 | feature0000000009\n",
      "\t Class 0 - Global explanation: \"h1 | h3 | h6 | h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 56.04120969772339\n",
      "Seed [7/10]\n",
      "\t Epoch 0: train accuracy: 0.5090\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.9939\n",
      "\t Epoch 3000: train accuracy: 0.9939\n",
      "\t Epoch 3500: train accuracy: 0.9939\n",
      "\t Epoch 4000: train accuracy: 0.9939\n",
      "\t Model's accuracy: 0.9928\n",
      "~feature0000000001 & ~feature0000000003 & ~feature0000000006 & ~feature0000000009\n",
      "\t Class 1 - Global explanation: \"~h1 & ~h3 & ~h6 & ~h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 55.66836619377136\n",
      "feature0000000001 | feature0000000003 | feature0000000006 | feature0000000009\n",
      "\t Class 0 - Global explanation: \"h1 | h3 | h6 | h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 61.18748879432678\n",
      "Seed [8/10]\n",
      "\t Epoch 0: train accuracy: 0.4910\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.9939\n",
      "\t Epoch 3000: train accuracy: 0.9939\n",
      "\t Epoch 3500: train accuracy: 0.9939\n",
      "\t Epoch 4000: train accuracy: 0.9939\n",
      "\t Model's accuracy: 0.9928\n",
      "~feature0000000001 & ~feature0000000003 & ~feature0000000006 & ~feature0000000009\n",
      "\t Class 1 - Global explanation: \"~h1 & ~h3 & ~h6 & ~h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 60.25893712043762\n",
      "feature0000000001 | feature0000000003 | feature0000000006 | feature0000000009\n",
      "\t Class 0 - Global explanation: \"h1 | h3 | h6 | h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 53.01643109321594\n",
      "Seed [9/10]\n",
      "\t Epoch 0: train accuracy: 0.4910\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.9939\n",
      "\t Epoch 3000: train accuracy: 0.9939\n",
      "\t Epoch 3500: train accuracy: 0.9939\n",
      "\t Epoch 4000: train accuracy: 0.9939\n",
      "\t Model's accuracy: 0.9928\n",
      "~feature0000000001 & ~feature0000000003 & ~feature0000000006 & ~feature0000000009\n",
      "\t Class 1 - Global explanation: \"~h1 & ~h3 & ~h6 & ~h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 58.359018087387085\n",
      "feature0000000001 | feature0000000003 | feature0000000006 | feature0000000009\n",
      "\t Class 0 - Global explanation: \"h1 | h3 | h6 | h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 59.10502624511719\n",
      "Seed [10/10]\n",
      "\t Epoch 0: train accuracy: 0.5090\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.9939\n",
      "\t Epoch 3000: train accuracy: 0.9939\n",
      "\t Epoch 3500: train accuracy: 0.9939\n",
      "\t Epoch 4000: train accuracy: 0.9939\n",
      "\t Model's accuracy: 0.9928\n",
      "~feature0000000001 & ~feature0000000003 & ~feature0000000006 & ~feature0000000009\n",
      "\t Class 1 - Global explanation: \"~h1 & ~h3 & ~h6 & ~h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 62.157901763916016\n",
      "feature0000000001 | feature0000000003 | feature0000000006 | feature0000000009\n",
      "\t Class 0 - Global explanation: \"h1 | h3 | h6 | h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 58.62530565261841\n"
     ]
    }
   ],
   "source": [
    "need_pruning = True\n",
    "method = 'pruning'\n",
    "methods = []\n",
    "splits = []\n",
    "explanations = []\n",
    "explanations_inv = []\n",
    "model_accuracies = []\n",
    "explanation_accuracies = []\n",
    "explanation_accuracies_inv = []\n",
    "elapsed_times = []\n",
    "elapsed_times_inv = []\n",
    "for seed in range(n_rep):\n",
    "    print(f'Seed [{seed+1}/{n_rep}]')\n",
    "    \n",
    "    model = train_nn(x_train, y_train, need_pruning, seed, device)\n",
    "    \n",
    "    y_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "    model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds.argmax(axis=1))\n",
    "    print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "    \n",
    "    # positive class\n",
    "    target_class = 1\n",
    "    start = time.time()\n",
    "    global_explanation, _, _ = logic.relunn.combine_local_explanations(model, \n",
    "                                                                       x_train.to(device), y_train.to(device), \n",
    "                                                                       target_class=target_class,\n",
    "                                                                       topk_explanations=10,\n",
    "                                                                       method=method, device=device)\n",
    "    elapsed_time = time.time() - start\n",
    "    if global_explanation:\n",
    "        explanation_accuracy, _ = logic.base.test_explanation(global_explanation, target_class, x_test, y_test)\n",
    "        explanation = logic.base.replace_names(global_explanation, concepts)\n",
    "    print(f'\\t Class {target_class} - Global explanation: \"{explanation}\" - Accuracy: {explanation_accuracy:.4f}')\n",
    "    print(f'\\t Elapsed time {elapsed_time}')\n",
    "        \n",
    "    # negative class\n",
    "    target_class = 0\n",
    "    start = time.time()\n",
    "    global_explanation_inv, _, _ = logic.relunn.combine_local_explanations(model, \n",
    "                                                                           x_train.to(device), y_train.to(device), \n",
    "                                                                           target_class=target_class,\n",
    "                                                                           topk_explanations=10,\n",
    "                                                                           method=method, device=device)\n",
    "    elapsed_time_inv = time.time() - start\n",
    "    if global_explanation_inv:\n",
    "        explanation_accuracy_inv, _ = logic.base.test_explanation(global_explanation_inv, target_class, x_test, y_test)\n",
    "        explanation_inv = logic.base.replace_names(global_explanation_inv, concepts)\n",
    "    print(f'\\t Class {target_class} - Global explanation: \"{explanation_inv}\" - Accuracy: {explanation_accuracy_inv:.4f}')\n",
    "    print(f'\\t Elapsed time {elapsed_time_inv}')\n",
    "    \n",
    "    methods.append(method)\n",
    "    splits.append(seed)\n",
    "    explanations.append(explanation)\n",
    "    explanations_inv.append(explanation_inv)\n",
    "    model_accuracies.append(model_accuracy)\n",
    "    explanation_accuracies.append(explanation_accuracy)\n",
    "    explanation_accuracies_inv.append(explanation_accuracy_inv)\n",
    "    elapsed_times.append(elapsed_time)\n",
    "    elapsed_times_inv.append(elapsed_time_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>explanation_inv</th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_accuracy_inv</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>elapsed_time_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pruning</td>\n",
       "      <td>0</td>\n",
       "      <td>~h1 &amp; ~h3 &amp; ~h6 &amp; ~h9</td>\n",
       "      <td>h1 | h3 | h6 | h9</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>65.449980</td>\n",
       "      <td>51.400614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pruning</td>\n",
       "      <td>1</td>\n",
       "      <td>~h1 &amp; ~h3 &amp; ~h6 &amp; ~h9</td>\n",
       "      <td>h1 | h3 | h6 | h9</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>50.679115</td>\n",
       "      <td>58.627301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pruning</td>\n",
       "      <td>2</td>\n",
       "      <td>~h1 &amp; ~h3 &amp; ~h6 &amp; ~h9</td>\n",
       "      <td>h1 | h3 | h6 | h9</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>57.362711</td>\n",
       "      <td>58.145587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pruning</td>\n",
       "      <td>3</td>\n",
       "      <td>~h1 &amp; ~h3 &amp; ~h6 &amp; ~h9</td>\n",
       "      <td>h1 | h3 | h6 | h9</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>61.273226</td>\n",
       "      <td>49.233447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pruning</td>\n",
       "      <td>4</td>\n",
       "      <td>~h1 &amp; ~h3 &amp; ~h6 &amp; ~h9</td>\n",
       "      <td>h1 | h3 | h6 | h9</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>58.926335</td>\n",
       "      <td>58.849749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pruning</td>\n",
       "      <td>5</td>\n",
       "      <td>~h1 &amp; ~h3 &amp; ~h6 &amp; ~h9</td>\n",
       "      <td>h1 | h3 | h6 | h9</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>57.387614</td>\n",
       "      <td>56.041210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pruning</td>\n",
       "      <td>6</td>\n",
       "      <td>~h1 &amp; ~h3 &amp; ~h6 &amp; ~h9</td>\n",
       "      <td>h1 | h3 | h6 | h9</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>55.668366</td>\n",
       "      <td>61.187489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pruning</td>\n",
       "      <td>7</td>\n",
       "      <td>~h1 &amp; ~h3 &amp; ~h6 &amp; ~h9</td>\n",
       "      <td>h1 | h3 | h6 | h9</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>60.258937</td>\n",
       "      <td>53.016431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pruning</td>\n",
       "      <td>8</td>\n",
       "      <td>~h1 &amp; ~h3 &amp; ~h6 &amp; ~h9</td>\n",
       "      <td>h1 | h3 | h6 | h9</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>58.359018</td>\n",
       "      <td>59.105026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pruning</td>\n",
       "      <td>9</td>\n",
       "      <td>~h1 &amp; ~h3 &amp; ~h6 &amp; ~h9</td>\n",
       "      <td>h1 | h3 | h6 | h9</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>62.157902</td>\n",
       "      <td>58.625306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    method  split            explanation    explanation_inv  model_accuracy  \\\n",
       "0  pruning      0  ~h1 & ~h3 & ~h6 & ~h9  h1 | h3 | h6 | h9          0.9928   \n",
       "1  pruning      1  ~h1 & ~h3 & ~h6 & ~h9  h1 | h3 | h6 | h9          0.9928   \n",
       "2  pruning      2  ~h1 & ~h3 & ~h6 & ~h9  h1 | h3 | h6 | h9          0.9928   \n",
       "3  pruning      3  ~h1 & ~h3 & ~h6 & ~h9  h1 | h3 | h6 | h9          0.9928   \n",
       "4  pruning      4  ~h1 & ~h3 & ~h6 & ~h9  h1 | h3 | h6 | h9          0.9928   \n",
       "5  pruning      5  ~h1 & ~h3 & ~h6 & ~h9  h1 | h3 | h6 | h9          0.9928   \n",
       "6  pruning      6  ~h1 & ~h3 & ~h6 & ~h9  h1 | h3 | h6 | h9          0.9928   \n",
       "7  pruning      7  ~h1 & ~h3 & ~h6 & ~h9  h1 | h3 | h6 | h9          0.9928   \n",
       "8  pruning      8  ~h1 & ~h3 & ~h6 & ~h9  h1 | h3 | h6 | h9          0.9928   \n",
       "9  pruning      9  ~h1 & ~h3 & ~h6 & ~h9  h1 | h3 | h6 | h9          0.9928   \n",
       "\n",
       "   explanation_accuracy  explanation_accuracy_inv  elapsed_time  \\\n",
       "0                0.9928                    0.9928     65.449980   \n",
       "1                0.9928                    0.9928     50.679115   \n",
       "2                0.9928                    0.9928     57.362711   \n",
       "3                0.9928                    0.9928     61.273226   \n",
       "4                0.9928                    0.9928     58.926335   \n",
       "5                0.9928                    0.9928     57.387614   \n",
       "6                0.9928                    0.9928     55.668366   \n",
       "7                0.9928                    0.9928     60.258937   \n",
       "8                0.9928                    0.9928     58.359018   \n",
       "9                0.9928                    0.9928     62.157902   \n",
       "\n",
       "   elapsed_time_inv  \n",
       "0         51.400614  \n",
       "1         58.627301  \n",
       "2         58.145587  \n",
       "3         49.233447  \n",
       "4         58.849749  \n",
       "5         56.041210  \n",
       "6         61.187489  \n",
       "7         53.016431  \n",
       "8         59.105026  \n",
       "9         58.625306  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_pruning = pd.DataFrame({\n",
    "    'method': methods,\n",
    "    'split': splits,\n",
    "    'explanation': explanations,\n",
    "    'explanation_inv': explanations_inv,\n",
    "    'model_accuracy': model_accuracies,\n",
    "    'explanation_accuracy': explanation_accuracies,\n",
    "    'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "    'elapsed_time': elapsed_times,\n",
    "    'elapsed_time_inv': elapsed_times_inv,\n",
    "})\n",
    "results_pruning.to_csv(os.path.join(results_dir, 'results_pruning.csv'))\n",
    "results_pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need_pruning = False\n",
    "# method = 'lime'\n",
    "# methods = []\n",
    "# splits = []\n",
    "# explanations = []\n",
    "# explanations_inv = []\n",
    "# model_accuracies = []\n",
    "# explanation_accuracies = []\n",
    "# explanation_accuracies_inv = []\n",
    "# elapsed_times = []\n",
    "# elapsed_times_inv = []\n",
    "# for seed in range(n_rep):\n",
    "#     print(f'Seed [{seed+1}/{n_rep}]')\n",
    "    \n",
    "#     model = train_nn(x_train, y_train, need_pruning, seed, device)\n",
    "    \n",
    "#     y_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "#     model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds.argmax(axis=1))\n",
    "#     print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "    \n",
    "#     # positive class\n",
    "#     target_class = 1\n",
    "#     start = time.time()\n",
    "#     global_explanation, _, _ = logic.relunn.combine_local_explanations(model, \n",
    "#                                                                        x_train.to(device), y_train.to(device), \n",
    "#                                                                        target_class=target_class,\n",
    "#                                                                        method=method, device=device)\n",
    "#     elapsed_time = time.time() - start\n",
    "#     if global_explanation:\n",
    "#         explanation_accuracy, _ = logic.base.test_explanation(global_explanation, target_class, x_test, y_test)\n",
    "#         explanation = logic.base.replace_names(global_explanation, concepts)\n",
    "#     print(f'\\t Class {target_class} - Global explanation: \"{explanation}\" - Accuracy: {explanation_accuracy:.4f}')\n",
    "#     print(f'\\t Elapsed time {elapsed_time}')\n",
    "        \n",
    "#     # negative class\n",
    "#     target_class = 0\n",
    "#     start = time.time()\n",
    "#     global_explanation_inv, _, _ = logic.relunn.combine_local_explanations(model, \n",
    "#                                                                            x_train.to(device), y_train.to(device), \n",
    "#                                                                            target_class=target_class,\n",
    "#                                                                            method=method, device=device)\n",
    "#     elapsed_time_inv = time.time() - start\n",
    "#     if global_explanation_inv:\n",
    "#         explanation_accuracy_inv, _ = logic.base.test_explanation(global_explanation_inv, target_class, x_test, y_test)\n",
    "#         explanation_inv = logic.base.replace_names(global_explanation_inv, concepts)\n",
    "#     print(f'\\t Class {target_class} - Global explanation: \"{explanation_inv}\" - Accuracy: {explanation_accuracy_inv:.4f}')\n",
    "#     print(f'\\t Elapsed time {elapsed_time_inv}')\n",
    "    \n",
    "#     methods.append(method)\n",
    "#     splits.append(seed)\n",
    "#     explanations.append(explanation)\n",
    "#     explanations_inv.append(explanation_inv)\n",
    "#     model_accuracies.append(model_accuracy)\n",
    "#     explanation_accuracies.append(explanation_accuracy)\n",
    "#     explanation_accuracies_inv.append(explanation_accuracy_inv)\n",
    "#     elapsed_times.append(elapsed_time)\n",
    "#     elapsed_times_inv.append(elapsed_time_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_lime = pd.DataFrame({\n",
    "#     'method': methods,\n",
    "#     'split': splits,\n",
    "#     'explanation': explanations,\n",
    "#     'explanation_inv': explanations_inv,\n",
    "#     'model_accuracy': model_accuracies,\n",
    "#     'explanation_accuracy': explanation_accuracies,\n",
    "#     'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "#     'elapsed_time': elapsed_times,\n",
    "#     'elapsed_time_inv': elapsed_times_inv,\n",
    "# })\n",
    "# results_lime.to_csv(os.path.join(results_dir, 'results_lime.csv'))\n",
    "# results_lime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed [1/10]\n",
      "\t Epoch 0: train accuracy: 0.4910\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.9939\n",
      "\t Epoch 3000: train accuracy: 0.9939\n",
      "\t Epoch 3500: train accuracy: 0.9939\n",
      "\t Epoch 4000: train accuracy: 0.9939\n",
      "\t Model's accuracy: 0.9928\n",
      "~feature0000000001 & ~feature0000000003 & ~feature0000000006 & ~feature0000000009\n",
      "\t Class 1 - Global explanation: \"~h1 & ~h3 & ~h6 & ~h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 112.44951820373535\n",
      "feature0000000001 | feature0000000003 | feature0000000006 | (~feature0000000000 & ~feature0000000002 & ~feature0000000004 & ~feature0000000007 & ~feature0000000008)\n",
      "\t Class 0 - Global explanation: \"h1 | h3 | h6 | (~h0 & ~h2 & ~h4 & ~h7 & ~h8)\" - Accuracy: 0.9085\n",
      "\t Elapsed time 114.9409294128418\n",
      "Seed [2/10]\n",
      "\t Epoch 0: train accuracy: 0.4910\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.9939\n",
      "\t Epoch 3000: train accuracy: 0.9939\n",
      "\t Epoch 3500: train accuracy: 0.9939\n",
      "\t Epoch 4000: train accuracy: 0.9939\n",
      "\t Model's accuracy: 0.9928\n",
      "feature0000000002 | ~feature0000000006\n",
      "\t Class 1 - Global explanation: \"h2 | ~h6\" - Accuracy: 0.4179\n",
      "\t Elapsed time 111.5159375667572\n",
      "feature0000000001 | feature0000000003 | feature0000000006 | feature0000000009\n",
      "\t Class 0 - Global explanation: \"h1 | h3 | h6 | h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 104.96747303009033\n",
      "Seed [3/10]\n",
      "\t Epoch 0: train accuracy: 0.5090\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.9939\n",
      "\t Epoch 3000: train accuracy: 0.9939\n",
      "\t Epoch 3500: train accuracy: 0.9939\n",
      "\t Epoch 4000: train accuracy: 0.9939\n",
      "\t Model's accuracy: 0.9928\n",
      "feature0000000002 | feature0000000007 | feature0000000008 | (~feature0000000001 & ~feature0000000003 & ~feature0000000006 & ~feature0000000009)\n",
      "\t Class 1 - Global explanation: \"h2 | h7 | h8 | (~h1 & ~h3 & ~h6 & ~h9)\" - Accuracy: 0.6776\n",
      "\t Elapsed time 112.24299263954163\n",
      "feature0000000001 | feature0000000003 | feature0000000006 | feature0000000009\n",
      "\t Class 0 - Global explanation: \"h1 | h3 | h6 | h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 106.87138652801514\n",
      "Seed [4/10]\n",
      "\t Epoch 0: train accuracy: 0.5090\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.9939\n",
      "\t Epoch 3000: train accuracy: 0.9939\n",
      "\t Epoch 3500: train accuracy: 0.9939\n",
      "\t Epoch 4000: train accuracy: 0.9939\n",
      "\t Model's accuracy: 0.9928\n",
      "~feature0000000001 & ~feature0000000003 & ~feature0000000006 & ~feature0000000009\n",
      "\t Class 1 - Global explanation: \"~h1 & ~h3 & ~h6 & ~h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 115.07260489463806\n",
      "feature0000000001 | feature0000000003 | feature0000000006 | feature0000000009\n",
      "\t Class 0 - Global explanation: \"h1 | h3 | h6 | h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 108.20275402069092\n",
      "Seed [5/10]\n",
      "\t Epoch 0: train accuracy: 0.5090\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.9939\n",
      "\t Epoch 3000: train accuracy: 0.9939\n",
      "\t Epoch 3500: train accuracy: 0.9939\n",
      "\t Epoch 4000: train accuracy: 0.9939\n",
      "\t Model's accuracy: 0.9928\n",
      "(~feature0000000003 & ~feature0000000007) | (~feature0000000001 & ~feature0000000003 & ~feature0000000006 & ~feature0000000009)\n",
      "\t Class 1 - Global explanation: \"(~h3 & ~h7) | (~h1 & ~h3 & ~h6 & ~h9)\" - Accuracy: 0.1530\n",
      "\t Elapsed time 107.58219003677368\n",
      "feature0000000001 | feature0000000003 | feature0000000006 | feature0000000009\n",
      "\t Class 0 - Global explanation: \"h1 | h3 | h6 | h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 107.0119776725769\n",
      "Seed [6/10]\n",
      "\t Epoch 0: train accuracy: 0.5090\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.9939\n",
      "\t Epoch 3000: train accuracy: 0.9939\n",
      "\t Epoch 3500: train accuracy: 0.9939\n",
      "\t Epoch 4000: train accuracy: 0.9939\n",
      "\t Model's accuracy: 0.9928\n",
      "~feature0000000001 & ~feature0000000003 & ~feature0000000006 & ~feature0000000009\n",
      "\t Class 1 - Global explanation: \"~h1 & ~h3 & ~h6 & ~h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 116.75691318511963\n",
      "feature0000000001 | feature0000000003 | feature0000000006 | feature0000000009\n",
      "\t Class 0 - Global explanation: \"h1 | h3 | h6 | h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 119.55345821380615\n",
      "Seed [7/10]\n",
      "\t Epoch 0: train accuracy: 0.5090\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.9939\n",
      "\t Epoch 3000: train accuracy: 0.9939\n",
      "\t Epoch 3500: train accuracy: 0.9939\n",
      "\t Epoch 4000: train accuracy: 0.9939\n",
      "\t Model's accuracy: 0.9928\n",
      "feature0000000002 | (~feature0000000001 & ~feature0000000003 & ~feature0000000006 & ~feature0000000009)\n",
      "\t Class 1 - Global explanation: \"h2 | (~h1 & ~h3 & ~h6 & ~h9)\" - Accuracy: 0.8347\n",
      "\t Elapsed time 117.11197876930237\n",
      "feature0000000001 | feature0000000003 | feature0000000006 | feature0000000009\n",
      "\t Class 0 - Global explanation: \"h1 | h3 | h6 | h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 106.37371492385864\n",
      "Seed [8/10]\n",
      "\t Epoch 0: train accuracy: 0.4910\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.9939\n",
      "\t Epoch 3000: train accuracy: 0.9939\n",
      "\t Epoch 3500: train accuracy: 0.9939\n",
      "\t Epoch 4000: train accuracy: 0.9939\n",
      "\t Model's accuracy: 0.9928\n",
      "~feature0000000001 & ~feature0000000003 & ~feature0000000006 & ~feature0000000009\n",
      "\t Class 1 - Global explanation: \"~h1 & ~h3 & ~h6 & ~h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 125.10850358009338\n",
      "feature0000000001 | feature0000000003 | feature0000000006 | feature0000000009\n",
      "\t Class 0 - Global explanation: \"h1 | h3 | h6 | h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 114.83217906951904\n",
      "Seed [9/10]\n",
      "\t Epoch 0: train accuracy: 0.4910\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.9939\n",
      "\t Epoch 3000: train accuracy: 0.9939\n",
      "\t Epoch 3500: train accuracy: 0.9939\n",
      "\t Epoch 4000: train accuracy: 0.9939\n",
      "\t Model's accuracy: 0.9928\n",
      "(~feature0000000000 & ~feature0000000001 & ~feature0000000002) | (~feature0000000001 & ~feature0000000003 & ~feature0000000006 & ~feature0000000009)\n",
      "\t Class 1 - Global explanation: \"(~h0 & ~h1 & ~h2) | (~h1 & ~h3 & ~h6 & ~h9)\" - Accuracy: 0.4102\n",
      "\t Elapsed time 119.23829984664917\n",
      "feature0000000001 | feature0000000003 | feature0000000006 | feature0000000009\n",
      "\t Class 0 - Global explanation: \"h1 | h3 | h6 | h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 114.38427257537842\n",
      "Seed [10/10]\n",
      "\t Epoch 0: train accuracy: 0.5090\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.9939\n",
      "\t Epoch 3000: train accuracy: 0.9939\n",
      "\t Epoch 3500: train accuracy: 0.9939\n",
      "\t Epoch 4000: train accuracy: 0.9939\n",
      "\t Model's accuracy: 0.9928\n",
      "~feature0000000001 & ~feature0000000003 & ~feature0000000006 & ~feature0000000009\n",
      "\t Class 1 - Global explanation: \"~h1 & ~h3 & ~h6 & ~h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 112.36267757415771\n",
      "feature0000000001 | feature0000000003 | feature0000000006 | feature0000000009\n",
      "\t Class 0 - Global explanation: \"h1 | h3 | h6 | h9\" - Accuracy: 0.9928\n",
      "\t Elapsed time 111.74395179748535\n"
     ]
    }
   ],
   "source": [
    "need_pruning = False\n",
    "method = 'weights'\n",
    "methods = []\n",
    "splits = []\n",
    "explanations = []\n",
    "explanations_inv = []\n",
    "model_accuracies = []\n",
    "explanation_accuracies = []\n",
    "explanation_accuracies_inv = []\n",
    "elapsed_times = []\n",
    "elapsed_times_inv = []\n",
    "for seed in range(n_rep):\n",
    "    print(f'Seed [{seed+1}/{n_rep}]')\n",
    "    \n",
    "    model = train_nn(x_train, y_train, need_pruning, seed, device)\n",
    "    \n",
    "    y_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "    model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds.argmax(axis=1))\n",
    "    print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "    \n",
    "    # positive class\n",
    "    target_class = 1\n",
    "    start = time.time()\n",
    "    global_explanation, _, _ = logic.relunn.combine_local_explanations(model, \n",
    "                                                                       x_train.to(device), y_train.to(device),\n",
    "                                                                       topk_explanations=10, \n",
    "                                                                       target_class=target_class,\n",
    "                                                                       method=method, device=device)\n",
    "    elapsed_time = time.time() - start\n",
    "    if global_explanation:\n",
    "        explanation_accuracy, _ = logic.base.test_explanation(global_explanation, target_class, x_test, y_test)\n",
    "        explanation = logic.base.replace_names(global_explanation, concepts)\n",
    "    print(f'\\t Class {target_class} - Global explanation: \"{explanation}\" - Accuracy: {explanation_accuracy:.4f}')\n",
    "    print(f'\\t Elapsed time {elapsed_time}')\n",
    "        \n",
    "    # negative class\n",
    "    target_class = 0\n",
    "    start = time.time()\n",
    "    global_explanation_inv, _, _ = logic.relunn.combine_local_explanations(model, \n",
    "                                                                           x_train.to(device), y_train.to(device), \n",
    "                                                                           topk_explanations=10, \n",
    "                                                                           target_class=target_class,\n",
    "                                                                           method=method, device=device)\n",
    "    elapsed_time_inv = time.time() - start\n",
    "    if global_explanation_inv:\n",
    "        explanation_accuracy_inv, _ = logic.base.test_explanation(global_explanation_inv, target_class, x_test, y_test)\n",
    "        explanation_inv = logic.base.replace_names(global_explanation_inv, concepts)\n",
    "    print(f'\\t Class {target_class} - Global explanation: \"{explanation_inv}\" - Accuracy: {explanation_accuracy_inv:.4f}')\n",
    "    print(f'\\t Elapsed time {elapsed_time_inv}')\n",
    "    \n",
    "    methods.append(method)\n",
    "    splits.append(seed)\n",
    "    explanations.append(explanation)\n",
    "    explanations_inv.append(explanation_inv)\n",
    "    model_accuracies.append(model_accuracy)\n",
    "    explanation_accuracies.append(explanation_accuracy)\n",
    "    explanation_accuracies_inv.append(explanation_accuracy_inv)\n",
    "    elapsed_times.append(elapsed_time)\n",
    "    elapsed_times_inv.append(elapsed_time_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>explanation_inv</th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_accuracy_inv</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>elapsed_time_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weights</td>\n",
       "      <td>0</td>\n",
       "      <td>~h1 &amp; ~h3 &amp; ~h6 &amp; ~h9</td>\n",
       "      <td>h1 | h3 | h6 | (~h0 &amp; ~h2 &amp; ~h4 &amp; ~h7 &amp; ~h8)</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>112.449518</td>\n",
       "      <td>114.940929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weights</td>\n",
       "      <td>1</td>\n",
       "      <td>h2 | ~h6</td>\n",
       "      <td>h1 | h3 | h6 | h9</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.4179</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>111.515938</td>\n",
       "      <td>104.967473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weights</td>\n",
       "      <td>2</td>\n",
       "      <td>h2 | h7 | h8 | (~h1 &amp; ~h3 &amp; ~h6 &amp; ~h9)</td>\n",
       "      <td>h1 | h3 | h6 | h9</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.6776</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>112.242993</td>\n",
       "      <td>106.871387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weights</td>\n",
       "      <td>3</td>\n",
       "      <td>~h1 &amp; ~h3 &amp; ~h6 &amp; ~h9</td>\n",
       "      <td>h1 | h3 | h6 | h9</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>115.072605</td>\n",
       "      <td>108.202754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weights</td>\n",
       "      <td>4</td>\n",
       "      <td>(~h3 &amp; ~h7) | (~h1 &amp; ~h3 &amp; ~h6 &amp; ~h9)</td>\n",
       "      <td>h1 | h3 | h6 | h9</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>107.582190</td>\n",
       "      <td>107.011978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weights</td>\n",
       "      <td>5</td>\n",
       "      <td>~h1 &amp; ~h3 &amp; ~h6 &amp; ~h9</td>\n",
       "      <td>h1 | h3 | h6 | h9</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>116.756913</td>\n",
       "      <td>119.553458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weights</td>\n",
       "      <td>6</td>\n",
       "      <td>h2 | (~h1 &amp; ~h3 &amp; ~h6 &amp; ~h9)</td>\n",
       "      <td>h1 | h3 | h6 | h9</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.8347</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>117.111979</td>\n",
       "      <td>106.373715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weights</td>\n",
       "      <td>7</td>\n",
       "      <td>~h1 &amp; ~h3 &amp; ~h6 &amp; ~h9</td>\n",
       "      <td>h1 | h3 | h6 | h9</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>125.108504</td>\n",
       "      <td>114.832179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weights</td>\n",
       "      <td>8</td>\n",
       "      <td>(~h0 &amp; ~h1 &amp; ~h2) | (~h1 &amp; ~h3 &amp; ~h6 &amp; ~h9)</td>\n",
       "      <td>h1 | h3 | h6 | h9</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.4102</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>119.238300</td>\n",
       "      <td>114.384273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>weights</td>\n",
       "      <td>9</td>\n",
       "      <td>~h1 &amp; ~h3 &amp; ~h6 &amp; ~h9</td>\n",
       "      <td>h1 | h3 | h6 | h9</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>112.362678</td>\n",
       "      <td>111.743952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    method  split                                  explanation  \\\n",
       "0  weights      0                        ~h1 & ~h3 & ~h6 & ~h9   \n",
       "1  weights      1                                     h2 | ~h6   \n",
       "2  weights      2       h2 | h7 | h8 | (~h1 & ~h3 & ~h6 & ~h9)   \n",
       "3  weights      3                        ~h1 & ~h3 & ~h6 & ~h9   \n",
       "4  weights      4        (~h3 & ~h7) | (~h1 & ~h3 & ~h6 & ~h9)   \n",
       "5  weights      5                        ~h1 & ~h3 & ~h6 & ~h9   \n",
       "6  weights      6                 h2 | (~h1 & ~h3 & ~h6 & ~h9)   \n",
       "7  weights      7                        ~h1 & ~h3 & ~h6 & ~h9   \n",
       "8  weights      8  (~h0 & ~h1 & ~h2) | (~h1 & ~h3 & ~h6 & ~h9)   \n",
       "9  weights      9                        ~h1 & ~h3 & ~h6 & ~h9   \n",
       "\n",
       "                                explanation_inv  model_accuracy  \\\n",
       "0  h1 | h3 | h6 | (~h0 & ~h2 & ~h4 & ~h7 & ~h8)          0.9928   \n",
       "1                             h1 | h3 | h6 | h9          0.9928   \n",
       "2                             h1 | h3 | h6 | h9          0.9928   \n",
       "3                             h1 | h3 | h6 | h9          0.9928   \n",
       "4                             h1 | h3 | h6 | h9          0.9928   \n",
       "5                             h1 | h3 | h6 | h9          0.9928   \n",
       "6                             h1 | h3 | h6 | h9          0.9928   \n",
       "7                             h1 | h3 | h6 | h9          0.9928   \n",
       "8                             h1 | h3 | h6 | h9          0.9928   \n",
       "9                             h1 | h3 | h6 | h9          0.9928   \n",
       "\n",
       "   explanation_accuracy  explanation_accuracy_inv  elapsed_time  \\\n",
       "0                0.9928                    0.9085    112.449518   \n",
       "1                0.4179                    0.9928    111.515938   \n",
       "2                0.6776                    0.9928    112.242993   \n",
       "3                0.9928                    0.9928    115.072605   \n",
       "4                0.1530                    0.9928    107.582190   \n",
       "5                0.9928                    0.9928    116.756913   \n",
       "6                0.8347                    0.9928    117.111979   \n",
       "7                0.9928                    0.9928    125.108504   \n",
       "8                0.4102                    0.9928    119.238300   \n",
       "9                0.9928                    0.9928    112.362678   \n",
       "\n",
       "   elapsed_time_inv  \n",
       "0        114.940929  \n",
       "1        104.967473  \n",
       "2        106.871387  \n",
       "3        108.202754  \n",
       "4        107.011978  \n",
       "5        119.553458  \n",
       "6        106.373715  \n",
       "7        114.832179  \n",
       "8        114.384273  \n",
       "9        111.743952  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_weights = pd.DataFrame({\n",
    "    'method': methods,\n",
    "    'split': splits,\n",
    "    'explanation': explanations,\n",
    "    'explanation_inv': explanations_inv,\n",
    "    'model_accuracy': model_accuracies,\n",
    "    'explanation_accuracy': explanation_accuracies,\n",
    "    'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "    'elapsed_time': elapsed_times,\n",
    "    'elapsed_time_inv': elapsed_times_inv,\n",
    "})\n",
    "results_weights.to_csv(os.path.join(results_dir, 'results_weights.csv'))\n",
    "results_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Psi network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_psi_nn(x_train, y_train, need_pruning, seed, device):\n",
    "    set_seed(seed)\n",
    "    x_train = x_train.to(device)\n",
    "    y_train = y_train.to(device).to(torch.float)\n",
    "    layers = [\n",
    "        torch.nn.Linear(x_train.size(1), 10),\n",
    "        torch.nn.Sigmoid(),\n",
    "        torch.nn.Linear(10, 4),\n",
    "        torch.nn.Sigmoid(),\n",
    "        torch.nn.Linear(4, 1),\n",
    "        torch.nn.Sigmoid(),\n",
    "    ]\n",
    "    model = torch.nn.Sequential(*layers).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_form = torch.nn.BCELoss()\n",
    "    model.train()\n",
    "    for epoch in range(tot_epochs):\n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_train).squeeze()\n",
    "        # Compute Loss\n",
    "        loss = loss_form(y_pred, y_train)\n",
    "\n",
    "        for module in model.children():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                loss += 0.00001 * torch.norm(module.weight, 1)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch > prune_epochs and need_pruning:\n",
    "            model = prune_equal_fanin(model, 2, validate=True, device=device)\n",
    "            need_pruning = False\n",
    "            \n",
    "        # compute accuracy\n",
    "        if epoch % 500 == 0:\n",
    "            y_pred_d = y_pred > 0.5\n",
    "            accuracy = y_pred_d.eq(y_train).sum().item() / y_train.size(0)\n",
    "            print(f'\\t Epoch {epoch}: train accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed [1/10]\n",
      "\t Epoch 0: train accuracy: 0.4910\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.7683\n",
      "\t Epoch 3000: train accuracy: 0.7683\n",
      "\t Epoch 3500: train accuracy: 0.7683\n",
      "\t Epoch 4000: train accuracy: 0.7683\n",
      "\t Model's accuracy: 0.7614\n",
      "\t Class 1 - Global explanation: \"(h0 | h2 | ~h1)\" - Accuracy: 0.5202\n",
      "\t Elapsed time 0.0747995376586914\n",
      "\t Epoch 0: train accuracy: 0.5090\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.7107\n",
      "\t Epoch 3000: train accuracy: 0.7107\n",
      "\t Epoch 3500: train accuracy: 0.7107\n",
      "\t Epoch 4000: train accuracy: 0.7107\n",
      "\t Model's accuracy: 0.7143\n",
      "\t Class 0 - Global explanation: \"(~h4 & ~h5 & (h6 | ~h7))\" - Accuracy: 0.5663\n",
      "\t Elapsed time 0.08178138732910156\n",
      "Seed [2/10]\n",
      "\t Epoch 0: train accuracy: 0.4910\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.7860\n",
      "\t Epoch 3000: train accuracy: 0.7860\n",
      "\t Epoch 3500: train accuracy: 0.7860\n",
      "\t Epoch 4000: train accuracy: 0.7860\n",
      "\t Model's accuracy: 0.7874\n",
      "\t Class 1 - Global explanation: \"((h2 | h5) & (h2 | ~h1) & (h5 | ~h3) & (~h1 | ~h3))\" - Accuracy: 0.2847\n",
      "\t Elapsed time 0.07579851150512695\n",
      "\t Epoch 0: train accuracy: 0.5090\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.7860\n",
      "\t Epoch 3000: train accuracy: 0.7860\n",
      "\t Epoch 3500: train accuracy: 0.7860\n",
      "\t Epoch 4000: train accuracy: 0.7860\n",
      "\t Model's accuracy: 0.7874\n",
      "\t Class 0 - Global explanation: \"(~h4 & ~h5 & (h1 | h3))\" - Accuracy: 0.7874\n",
      "\t Elapsed time 0.05485272407531738\n",
      "Seed [3/10]\n",
      "\t Epoch 0: train accuracy: 0.5090\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.9273\n",
      "\t Epoch 3000: train accuracy: 0.9273\n",
      "\t Epoch 3500: train accuracy: 0.9273\n",
      "\t Epoch 4000: train accuracy: 0.9273\n",
      "\t Model's accuracy: 0.9207\n",
      "\t Class 1 - Global explanation: \"(~h1 & (h2 | ~h9) & (h0 | h7 | ~h6))\" - Accuracy: 0.3072\n",
      "\t Elapsed time 0.08979368209838867\n",
      "\t Epoch 0: train accuracy: 0.4910\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.8511\n",
      "\t Epoch 3000: train accuracy: 0.8511\n",
      "\t Epoch 3500: train accuracy: 0.8511\n",
      "\t Epoch 4000: train accuracy: 0.8511\n",
      "\t Model's accuracy: 0.8457\n",
      "\t Class 0 - Global explanation: \"(~h0 & ~h2 & ~h5 & ~h7)\" - Accuracy: 0.8457\n",
      "\t Elapsed time 0.05485177040100098\n",
      "Seed [4/10]\n",
      "\t Epoch 0: train accuracy: 0.5090\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.8122\n",
      "\t Epoch 3000: train accuracy: 0.8122\n",
      "\t Epoch 3500: train accuracy: 0.8122\n",
      "\t Epoch 4000: train accuracy: 0.8122\n",
      "\t Model's accuracy: 0.8087\n",
      "\t Class 1 - Global explanation: \"((h2 & h5) | (h2 & ~h3) | (h2 & ~h9) | (h5 & ~h3) | (h7 & ~h6) | (~h3 & ~h9))\" - Accuracy: 0.4002\n",
      "\t Elapsed time 0.23037505149841309\n",
      "\t Epoch 0: train accuracy: 0.4910\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.9939\n",
      "\t Epoch 3000: train accuracy: 0.9939\n",
      "\t Epoch 3500: train accuracy: 0.9939\n",
      "\t Epoch 4000: train accuracy: 0.9939\n",
      "\t Model's accuracy: 0.9928\n",
      "\t Class 0 - Global explanation: \"(h1 | h3 | h6 | h9)\" - Accuracy: 0.9928\n",
      "\t Elapsed time 0.07881999015808105\n",
      "Seed [5/10]\n",
      "\t Epoch 0: train accuracy: 0.4910\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.8122\n",
      "\t Epoch 3000: train accuracy: 0.8524\n",
      "\t Epoch 3500: train accuracy: 0.8524\n",
      "\t Epoch 4000: train accuracy: 0.8524\n",
      "\t Model's accuracy: 0.8560\n",
      "\t Class 1 - Global explanation: \"(~h1 & ~h6 & (h2 | h7))\" - Accuracy: 0.7244\n",
      "\t Elapsed time 0.19647431373596191\n",
      "\t Epoch 0: train accuracy: 0.5090\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.9275\n",
      "\t Epoch 3000: train accuracy: 0.9275\n",
      "\t Epoch 3500: train accuracy: 0.9275\n",
      "\t Epoch 4000: train accuracy: 0.9275\n",
      "\t Model's accuracy: 0.9242\n",
      "\t Class 0 - Global explanation: \"(h1 | h9 | (h3 & ~h2 & ~h5))\" - Accuracy: 0.9242\n",
      "\t Elapsed time 0.13068342208862305\n",
      "Seed [6/10]\n",
      "\t Epoch 0: train accuracy: 0.4910\n",
      "\t Epoch 500: train accuracy: 0.7106\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.7169\n",
      "\t Epoch 3000: train accuracy: 0.7169\n",
      "\t Epoch 3500: train accuracy: 0.7169\n",
      "\t Epoch 4000: train accuracy: 0.7169\n",
      "\t Model's accuracy: 0.7128\n",
      "\t Class 1 - Global explanation: \"(h2 & ~h6 & ~h9)\" - Accuracy: 0.6507\n",
      "\t Elapsed time 0.08577156066894531\n",
      "\t Epoch 0: train accuracy: 0.5090\n",
      "\t Epoch 500: train accuracy: 0.5090\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.7496\n",
      "\t Epoch 3000: train accuracy: 0.7496\n",
      "\t Epoch 3500: train accuracy: 0.7496\n",
      "\t Epoch 4000: train accuracy: 0.7496\n",
      "\t Model's accuracy: 0.7513\n",
      "\t Class 0 - Global explanation: \"(h9 & ~h5 & ~h7)\" - Accuracy: 0.6442\n",
      "\t Elapsed time 0.046874046325683594\n",
      "Seed [7/10]\n",
      "\t Epoch 0: train accuracy: 0.5090\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.7743\n",
      "\t Epoch 3000: train accuracy: 0.7743\n",
      "\t Epoch 3500: train accuracy: 0.7743\n",
      "\t Epoch 4000: train accuracy: 0.7743\n",
      "\t Model's accuracy: 0.7720\n",
      "\t Class 1 - Global explanation: \"(h0 | h2 | h5)\" - Accuracy: 0.7720\n",
      "\t Elapsed time 0.0388638973236084\n",
      "\t Epoch 0: train accuracy: 0.4910\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.7127\n",
      "\t Epoch 3000: train accuracy: 0.7127\n",
      "\t Epoch 3500: train accuracy: 0.7127\n",
      "\t Epoch 4000: train accuracy: 0.7127\n",
      "\t Model's accuracy: 0.7144\n",
      "\t Class 0 - Global explanation: \"(h6 | (h3 & ~h2 & ~h4))\" - Accuracy: 0.6481\n",
      "\t Elapsed time 0.14461278915405273\n",
      "Seed [8/10]\n",
      "\t Epoch 0: train accuracy: 0.5090\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.6915\n",
      "\t Epoch 3000: train accuracy: 0.6915\n",
      "\t Epoch 3500: train accuracy: 0.6915\n",
      "\t Epoch 4000: train accuracy: 0.6915\n",
      "\t Model's accuracy: 0.6877\n",
      "\t Class 1 - Global explanation: \"(h2 & ~h3)\" - Accuracy: 0.6507\n",
      "\t Elapsed time 0.10470438003540039\n",
      "\t Epoch 0: train accuracy: 0.4910\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.6420\n",
      "\t Epoch 3000: train accuracy: 0.6420\n",
      "\t Epoch 3500: train accuracy: 0.6420\n",
      "\t Epoch 4000: train accuracy: 0.6420\n",
      "\t Model's accuracy: 0.6481\n",
      "\t Class 0 - Global explanation: \"(h3 | h6)\" - Accuracy: 0.6481\n",
      "\t Elapsed time 0.05485391616821289\n",
      "Seed [9/10]\n",
      "\t Epoch 0: train accuracy: 0.4910\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.9273\n",
      "\t Epoch 3000: train accuracy: 0.9273\n",
      "\t Epoch 3500: train accuracy: 0.9273\n",
      "\t Epoch 4000: train accuracy: 0.9273\n",
      "\t Model's accuracy: 0.9207\n",
      "\t Class 1 - Global explanation: \"((h2 | ~h9) & (h4 | ~h6) & (h5 | ~h1))\" - Accuracy: 0.4092\n",
      "\t Elapsed time 0.12267255783081055\n",
      "\t Epoch 0: train accuracy: 0.5090\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.7836\n",
      "\t Epoch 3000: train accuracy: 0.7836\n",
      "\t Epoch 3500: train accuracy: 0.7836\n",
      "\t Epoch 4000: train accuracy: 0.7836\n",
      "\t Model's accuracy: 0.7849\n",
      "\t Class 0 - Global explanation: \"((h9 | ~h0) & (h9 | ~h5) & (h3 | h6 | h9) & (~h0 | ~h7) & (~h5 | ~h7) & (h3 | h6 | ~h7))\" - Accuracy: 0.5663\n",
      "\t Elapsed time 0.15259170532226562\n",
      "Seed [10/10]\n",
      "\t Epoch 0: train accuracy: 0.4910\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.4910\n",
      "\t Epoch 3000: train accuracy: 0.6526\n",
      "\t Epoch 3500: train accuracy: 0.9275\n",
      "\t Epoch 4000: train accuracy: 0.9275\n",
      "\t Model's accuracy: 0.9242\n",
      "\t Class 1 - Global explanation: \"(~h1 & ~h3 & (h2 | ~h9))\" - Accuracy: 0.4861\n",
      "\t Elapsed time 0.07875370979309082\n",
      "\t Epoch 0: train accuracy: 0.5090\n",
      "\t Epoch 500: train accuracy: 0.9939\n",
      "\t Epoch 1000: train accuracy: 0.9939\n",
      "\t Epoch 1500: train accuracy: 0.9939\n",
      "\t Epoch 2000: train accuracy: 0.9939\n",
      "\t Epoch 2500: train accuracy: 0.5756\n",
      "\t Epoch 3000: train accuracy: 0.5756\n",
      "\t Epoch 3500: train accuracy: 0.7516\n",
      "\t Epoch 4000: train accuracy: 0.7516\n",
      "\t Model's accuracy: 0.7514\n",
      "\t Class 0 - Global explanation: \"(~h4)\" - Accuracy: 0.5563\n",
      "\t Elapsed time 0.03493762016296387\n"
     ]
    }
   ],
   "source": [
    "need_pruning = True\n",
    "method = 'psi'\n",
    "methods = []\n",
    "splits = []\n",
    "explanations = []\n",
    "explanations_inv = []\n",
    "model_accuracies = []\n",
    "explanation_accuracies = []\n",
    "explanation_accuracies_inv = []\n",
    "elapsed_times = []\n",
    "elapsed_times_inv = []\n",
    "for seed in range(n_rep):\n",
    "    print(f'Seed [{seed+1}/{n_rep}]')\n",
    "    \n",
    "    # positive class\n",
    "    target_class = 1\n",
    "    model = train_psi_nn(x_train, y_train, need_pruning, seed, device)\n",
    "    \n",
    "    y_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "    model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds > 0.5)\n",
    "    print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "    \n",
    "    start = time.time()\n",
    "    global_explanation = logic.generate_fol_explanations(model, device)[0]\n",
    "    elapsed_time = time.time() - start\n",
    "    explanation_accuracy, _ = logic.base.test_explanation(global_explanation, target_class, x_test, y_test)\n",
    "    explanation = logic.base.replace_names(global_explanation, concepts)\n",
    "    print(f'\\t Class {target_class} - Global explanation: \"{explanation}\" - Accuracy: {explanation_accuracy:.4f}')\n",
    "    print(f'\\t Elapsed time {elapsed_time}')\n",
    "        \n",
    "    # negative class\n",
    "    target_class = 0\n",
    "    model = train_psi_nn(x_train, y_train.eq(target_class), need_pruning, seed, device)\n",
    "    \n",
    "    y_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "    model_accuracy = accuracy_score(y_test.eq(target_class).cpu().detach().numpy(), y_preds > 0.5)\n",
    "    print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "    \n",
    "    start = time.time()\n",
    "    global_explanation_inv = logic.generate_fol_explanations(model, device)[0]\n",
    "    elapsed_time_inv = time.time() - start\n",
    "    explanation_accuracy_inv, _ = logic.base.test_explanation(global_explanation_inv, \n",
    "                                                              target_class, x_test, y_test)\n",
    "    explanation_inv = logic.base.replace_names(global_explanation_inv, concepts)\n",
    "    print(f'\\t Class {target_class} - Global explanation: \"{explanation_inv}\" - Accuracy: {explanation_accuracy_inv:.4f}')\n",
    "    print(f'\\t Elapsed time {elapsed_time_inv}')\n",
    "    \n",
    "    methods.append(method)\n",
    "    splits.append(seed)\n",
    "    explanations.append(explanation)\n",
    "    explanations_inv.append(explanation_inv)\n",
    "    model_accuracies.append(model_accuracy)\n",
    "    explanation_accuracies.append(explanation_accuracy)\n",
    "    explanation_accuracies_inv.append(explanation_accuracy_inv)\n",
    "    elapsed_times.append(elapsed_time)\n",
    "    elapsed_times_inv.append(elapsed_time_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>explanation_inv</th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_accuracy_inv</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>elapsed_time_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>psi</td>\n",
       "      <td>0</td>\n",
       "      <td>(h0 | h2 | ~h1)</td>\n",
       "      <td>(~h4 &amp; ~h5 &amp; (h6 | ~h7))</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.5202</td>\n",
       "      <td>0.5663</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>0.081781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>psi</td>\n",
       "      <td>1</td>\n",
       "      <td>((h2 | h5) &amp; (h2 | ~h1) &amp; (h5 | ~h3) &amp; (~h1 | ...</td>\n",
       "      <td>(~h4 &amp; ~h5 &amp; (h1 | h3))</td>\n",
       "      <td>0.7874</td>\n",
       "      <td>0.2847</td>\n",
       "      <td>0.7874</td>\n",
       "      <td>0.075799</td>\n",
       "      <td>0.054853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>psi</td>\n",
       "      <td>2</td>\n",
       "      <td>(~h1 &amp; (h2 | ~h9) &amp; (h0 | h7 | ~h6))</td>\n",
       "      <td>(~h0 &amp; ~h2 &amp; ~h5 &amp; ~h7)</td>\n",
       "      <td>0.8457</td>\n",
       "      <td>0.3072</td>\n",
       "      <td>0.8457</td>\n",
       "      <td>0.089794</td>\n",
       "      <td>0.054852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>psi</td>\n",
       "      <td>3</td>\n",
       "      <td>((h2 &amp; h5) | (h2 &amp; ~h3) | (h2 &amp; ~h9) | (h5 &amp; ~...</td>\n",
       "      <td>(h1 | h3 | h6 | h9)</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.4002</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.230375</td>\n",
       "      <td>0.078820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>psi</td>\n",
       "      <td>4</td>\n",
       "      <td>(~h1 &amp; ~h6 &amp; (h2 | h7))</td>\n",
       "      <td>(h1 | h9 | (h3 &amp; ~h2 &amp; ~h5))</td>\n",
       "      <td>0.9242</td>\n",
       "      <td>0.7244</td>\n",
       "      <td>0.9242</td>\n",
       "      <td>0.196474</td>\n",
       "      <td>0.130683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>psi</td>\n",
       "      <td>5</td>\n",
       "      <td>(h2 &amp; ~h6 &amp; ~h9)</td>\n",
       "      <td>(h9 &amp; ~h5 &amp; ~h7)</td>\n",
       "      <td>0.7513</td>\n",
       "      <td>0.6507</td>\n",
       "      <td>0.6442</td>\n",
       "      <td>0.085772</td>\n",
       "      <td>0.046874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>psi</td>\n",
       "      <td>6</td>\n",
       "      <td>(h0 | h2 | h5)</td>\n",
       "      <td>(h6 | (h3 &amp; ~h2 &amp; ~h4))</td>\n",
       "      <td>0.7144</td>\n",
       "      <td>0.7720</td>\n",
       "      <td>0.6481</td>\n",
       "      <td>0.038864</td>\n",
       "      <td>0.144613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>psi</td>\n",
       "      <td>7</td>\n",
       "      <td>(h2 &amp; ~h3)</td>\n",
       "      <td>(h3 | h6)</td>\n",
       "      <td>0.6481</td>\n",
       "      <td>0.6507</td>\n",
       "      <td>0.6481</td>\n",
       "      <td>0.104704</td>\n",
       "      <td>0.054854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>psi</td>\n",
       "      <td>8</td>\n",
       "      <td>((h2 | ~h9) &amp; (h4 | ~h6) &amp; (h5 | ~h1))</td>\n",
       "      <td>((h9 | ~h0) &amp; (h9 | ~h5) &amp; (h3 | h6 | h9) &amp; (~...</td>\n",
       "      <td>0.7849</td>\n",
       "      <td>0.4092</td>\n",
       "      <td>0.5663</td>\n",
       "      <td>0.122673</td>\n",
       "      <td>0.152592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>psi</td>\n",
       "      <td>9</td>\n",
       "      <td>(~h1 &amp; ~h3 &amp; (h2 | ~h9))</td>\n",
       "      <td>(~h4)</td>\n",
       "      <td>0.7514</td>\n",
       "      <td>0.4861</td>\n",
       "      <td>0.5563</td>\n",
       "      <td>0.078754</td>\n",
       "      <td>0.034938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  split                                        explanation  \\\n",
       "0    psi      0                                    (h0 | h2 | ~h1)   \n",
       "1    psi      1  ((h2 | h5) & (h2 | ~h1) & (h5 | ~h3) & (~h1 | ...   \n",
       "2    psi      2               (~h1 & (h2 | ~h9) & (h0 | h7 | ~h6))   \n",
       "3    psi      3  ((h2 & h5) | (h2 & ~h3) | (h2 & ~h9) | (h5 & ~...   \n",
       "4    psi      4                            (~h1 & ~h6 & (h2 | h7))   \n",
       "5    psi      5                                   (h2 & ~h6 & ~h9)   \n",
       "6    psi      6                                     (h0 | h2 | h5)   \n",
       "7    psi      7                                         (h2 & ~h3)   \n",
       "8    psi      8             ((h2 | ~h9) & (h4 | ~h6) & (h5 | ~h1))   \n",
       "9    psi      9                           (~h1 & ~h3 & (h2 | ~h9))   \n",
       "\n",
       "                                     explanation_inv  model_accuracy  \\\n",
       "0                           (~h4 & ~h5 & (h6 | ~h7))          0.7143   \n",
       "1                            (~h4 & ~h5 & (h1 | h3))          0.7874   \n",
       "2                            (~h0 & ~h2 & ~h5 & ~h7)          0.8457   \n",
       "3                                (h1 | h3 | h6 | h9)          0.9928   \n",
       "4                       (h1 | h9 | (h3 & ~h2 & ~h5))          0.9242   \n",
       "5                                   (h9 & ~h5 & ~h7)          0.7513   \n",
       "6                            (h6 | (h3 & ~h2 & ~h4))          0.7144   \n",
       "7                                          (h3 | h6)          0.6481   \n",
       "8  ((h9 | ~h0) & (h9 | ~h5) & (h3 | h6 | h9) & (~...          0.7849   \n",
       "9                                              (~h4)          0.7514   \n",
       "\n",
       "   explanation_accuracy  explanation_accuracy_inv  elapsed_time  \\\n",
       "0                0.5202                    0.5663      0.074800   \n",
       "1                0.2847                    0.7874      0.075799   \n",
       "2                0.3072                    0.8457      0.089794   \n",
       "3                0.4002                    0.9928      0.230375   \n",
       "4                0.7244                    0.9242      0.196474   \n",
       "5                0.6507                    0.6442      0.085772   \n",
       "6                0.7720                    0.6481      0.038864   \n",
       "7                0.6507                    0.6481      0.104704   \n",
       "8                0.4092                    0.5663      0.122673   \n",
       "9                0.4861                    0.5563      0.078754   \n",
       "\n",
       "   elapsed_time_inv  \n",
       "0          0.081781  \n",
       "1          0.054853  \n",
       "2          0.054852  \n",
       "3          0.078820  \n",
       "4          0.130683  \n",
       "5          0.046874  \n",
       "6          0.144613  \n",
       "7          0.054854  \n",
       "8          0.152592  \n",
       "9          0.034938  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_psi = pd.DataFrame({\n",
    "    'method': methods,\n",
    "    'split': splits,\n",
    "    'explanation': explanations,\n",
    "    'explanation_inv': explanations_inv,\n",
    "    'model_accuracy': model_accuracies,\n",
    "    'explanation_accuracy': explanation_accuracies,\n",
    "    'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "    'elapsed_time': elapsed_times,\n",
    "    'elapsed_time_inv': elapsed_times_inv,\n",
    "})\n",
    "results_psi.to_csv(os.path.join(results_dir, 'results_psi.csv'))\n",
    "results_psi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed [1/10]\n",
      "\t Model's accuracy: 0.9928\n",
      "\t Class 1 - Global explanation: (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 <= 0.50 & h7 <= 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 <= 0.50 & h7 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "\t Class 0 - Global explanation: (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 > 0.50) | (h1 <= 0.50 & h9 > 0.50) | (h1 > 0.50)\n",
      "\t Elapsed time 0.0009636878967285156\n",
      "Seed [2/10]\n",
      "\t Model's accuracy: 0.9928\n",
      "\t Class 1 - Global explanation: (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 <= 0.50 & h7 <= 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 <= 0.50 & h7 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 > 0.50)\n",
      "\t Elapsed time 0.0009970664978027344\n",
      "\t Class 0 - Global explanation: (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 > 0.50) | (h1 <= 0.50 & h9 > 0.50) | (h1 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "Seed [3/10]\n",
      "\t Model's accuracy: 0.9928\n",
      "\t Class 1 - Global explanation: (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 <= 0.50 & h7 <= 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 <= 0.50 & h7 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "\t Class 0 - Global explanation: (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 > 0.50) | (h1 <= 0.50 & h9 > 0.50) | (h1 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "Seed [4/10]\n",
      "\t Model's accuracy: 0.9928\n",
      "\t Class 1 - Global explanation: (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 <= 0.50 & h7 <= 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 <= 0.50 & h7 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "\t Class 0 - Global explanation: (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 > 0.50) | (h1 <= 0.50 & h9 > 0.50) | (h1 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "Seed [5/10]\n",
      "\t Model's accuracy: 0.9928\n",
      "\t Class 1 - Global explanation: (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 <= 0.50 & h7 <= 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 <= 0.50 & h7 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "\t Class 0 - Global explanation: (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 > 0.50) | (h1 <= 0.50 & h9 > 0.50) | (h1 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "Seed [6/10]\n",
      "\t Model's accuracy: 0.9928\n",
      "\t Class 1 - Global explanation: (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 <= 0.50 & h7 <= 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 <= 0.50 & h7 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "\t Class 0 - Global explanation: (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 > 0.50) | (h1 <= 0.50 & h9 > 0.50) | (h1 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "Seed [7/10]\n",
      "\t Model's accuracy: 0.9928\n",
      "\t Class 1 - Global explanation: (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 <= 0.50 & h7 <= 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 <= 0.50 & h7 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "\t Class 0 - Global explanation: (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 > 0.50) | (h1 <= 0.50 & h9 > 0.50) | (h1 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "Seed [8/10]\n",
      "\t Model's accuracy: 0.9928\n",
      "\t Class 1 - Global explanation: (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 <= 0.50 & h7 <= 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 <= 0.50 & h7 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "\t Class 0 - Global explanation: (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 > 0.50) | (h1 <= 0.50 & h9 > 0.50) | (h1 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "Seed [9/10]\n",
      "\t Model's accuracy: 0.9928\n",
      "\t Class 1 - Global explanation: (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 <= 0.50 & h7 <= 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 <= 0.50 & h7 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "\t Class 0 - Global explanation: (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 > 0.50) | (h1 <= 0.50 & h9 > 0.50) | (h1 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "Seed [10/10]\n",
      "\t Model's accuracy: 0.9928\n",
      "\t Class 1 - Global explanation: (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 <= 0.50 & h7 <= 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 <= 0.50 & h7 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 <= 0.50 & h2 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= 0.50 & h8 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "\t Class 0 - Global explanation: (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 > 0.50) | (h1 <= 0.50 & h9 <= 0.50 & h3 > 0.50) | (h1 <= 0.50 & h9 > 0.50) | (h1 > 0.50)\n",
      "\t Elapsed time 0.0\n"
     ]
    }
   ],
   "source": [
    "need_pruning = False\n",
    "method = 'decision_tree'\n",
    "methods = []\n",
    "splits = []\n",
    "explanations = []\n",
    "explanations_inv = []\n",
    "model_accuracies = []\n",
    "explanation_accuracies = []\n",
    "explanation_accuracies_inv = []\n",
    "elapsed_times = []\n",
    "elapsed_times_inv = []\n",
    "for seed in range(n_rep):\n",
    "    print(f'Seed [{seed+1}/{n_rep}]')\n",
    "    \n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(x_train.cpu().detach().numpy(), y_train.cpu().detach().numpy())\n",
    "    y_preds = classifier.predict(x_test.cpu().detach().numpy())\n",
    "    model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds)\n",
    "    print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "    \n",
    "    target_class = 1\n",
    "    start = time.time()\n",
    "    explanation = tree_to_formula(classifier, concepts, target_class)\n",
    "    elapsed_time = time.time() - start\n",
    "    print(f'\\t Class {target_class} - Global explanation: {explanation}')\n",
    "    print(f'\\t Elapsed time {elapsed_time}')\n",
    "    \n",
    "    target_class = 0\n",
    "    start = time.time()\n",
    "    explanation_inv = tree_to_formula(classifier, concepts, target_class)\n",
    "    elapsed_time_inv = time.time() - start\n",
    "    print(f'\\t Class {target_class} - Global explanation: {explanation_inv}')\n",
    "    print(f'\\t Elapsed time {elapsed_time_inv}')\n",
    "    \n",
    "    methods.append(method)\n",
    "    splits.append(seed)\n",
    "    explanations.append(explanation)\n",
    "    explanations_inv.append(explanation_inv)\n",
    "    model_accuracies.append(model_accuracy)\n",
    "    explanation_accuracies.append(model_accuracy)\n",
    "    explanation_accuracies_inv.append(model_accuracy)\n",
    "    elapsed_times.append(0)\n",
    "    elapsed_times_inv.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>explanation_inv</th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_accuracy_inv</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>elapsed_time_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0</td>\n",
       "      <td>(h1 &lt;= 0.50 &amp; h9 &lt;= 0.50 &amp; h3 &lt;= 0.50 &amp; h6 &lt;= ...</td>\n",
       "      <td>(h1 &lt;= 0.50 &amp; h9 &lt;= 0.50 &amp; h3 &lt;= 0.50 &amp; h6 &gt; 0...</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>1</td>\n",
       "      <td>(h1 &lt;= 0.50 &amp; h9 &lt;= 0.50 &amp; h3 &lt;= 0.50 &amp; h6 &lt;= ...</td>\n",
       "      <td>(h1 &lt;= 0.50 &amp; h9 &lt;= 0.50 &amp; h3 &lt;= 0.50 &amp; h6 &gt; 0...</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>2</td>\n",
       "      <td>(h1 &lt;= 0.50 &amp; h9 &lt;= 0.50 &amp; h3 &lt;= 0.50 &amp; h6 &lt;= ...</td>\n",
       "      <td>(h1 &lt;= 0.50 &amp; h9 &lt;= 0.50 &amp; h3 &lt;= 0.50 &amp; h6 &gt; 0...</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>3</td>\n",
       "      <td>(h1 &lt;= 0.50 &amp; h9 &lt;= 0.50 &amp; h3 &lt;= 0.50 &amp; h6 &lt;= ...</td>\n",
       "      <td>(h1 &lt;= 0.50 &amp; h9 &lt;= 0.50 &amp; h3 &lt;= 0.50 &amp; h6 &gt; 0...</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>4</td>\n",
       "      <td>(h1 &lt;= 0.50 &amp; h9 &lt;= 0.50 &amp; h3 &lt;= 0.50 &amp; h6 &lt;= ...</td>\n",
       "      <td>(h1 &lt;= 0.50 &amp; h9 &lt;= 0.50 &amp; h3 &lt;= 0.50 &amp; h6 &gt; 0...</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>5</td>\n",
       "      <td>(h1 &lt;= 0.50 &amp; h9 &lt;= 0.50 &amp; h3 &lt;= 0.50 &amp; h6 &lt;= ...</td>\n",
       "      <td>(h1 &lt;= 0.50 &amp; h9 &lt;= 0.50 &amp; h3 &lt;= 0.50 &amp; h6 &gt; 0...</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>6</td>\n",
       "      <td>(h1 &lt;= 0.50 &amp; h9 &lt;= 0.50 &amp; h3 &lt;= 0.50 &amp; h6 &lt;= ...</td>\n",
       "      <td>(h1 &lt;= 0.50 &amp; h9 &lt;= 0.50 &amp; h3 &lt;= 0.50 &amp; h6 &gt; 0...</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>7</td>\n",
       "      <td>(h1 &lt;= 0.50 &amp; h9 &lt;= 0.50 &amp; h3 &lt;= 0.50 &amp; h6 &lt;= ...</td>\n",
       "      <td>(h1 &lt;= 0.50 &amp; h9 &lt;= 0.50 &amp; h3 &lt;= 0.50 &amp; h6 &gt; 0...</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>8</td>\n",
       "      <td>(h1 &lt;= 0.50 &amp; h9 &lt;= 0.50 &amp; h3 &lt;= 0.50 &amp; h6 &lt;= ...</td>\n",
       "      <td>(h1 &lt;= 0.50 &amp; h9 &lt;= 0.50 &amp; h3 &lt;= 0.50 &amp; h6 &gt; 0...</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>9</td>\n",
       "      <td>(h1 &lt;= 0.50 &amp; h9 &lt;= 0.50 &amp; h3 &lt;= 0.50 &amp; h6 &lt;= ...</td>\n",
       "      <td>(h1 &lt;= 0.50 &amp; h9 &lt;= 0.50 &amp; h3 &lt;= 0.50 &amp; h6 &gt; 0...</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          method  split                                        explanation  \\\n",
       "0  decision_tree      0  (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= ...   \n",
       "1  decision_tree      1  (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= ...   \n",
       "2  decision_tree      2  (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= ...   \n",
       "3  decision_tree      3  (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= ...   \n",
       "4  decision_tree      4  (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= ...   \n",
       "5  decision_tree      5  (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= ...   \n",
       "6  decision_tree      6  (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= ...   \n",
       "7  decision_tree      7  (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= ...   \n",
       "8  decision_tree      8  (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= ...   \n",
       "9  decision_tree      9  (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 <= ...   \n",
       "\n",
       "                                     explanation_inv  model_accuracy  \\\n",
       "0  (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 > 0...          0.9928   \n",
       "1  (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 > 0...          0.9928   \n",
       "2  (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 > 0...          0.9928   \n",
       "3  (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 > 0...          0.9928   \n",
       "4  (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 > 0...          0.9928   \n",
       "5  (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 > 0...          0.9928   \n",
       "6  (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 > 0...          0.9928   \n",
       "7  (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 > 0...          0.9928   \n",
       "8  (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 > 0...          0.9928   \n",
       "9  (h1 <= 0.50 & h9 <= 0.50 & h3 <= 0.50 & h6 > 0...          0.9928   \n",
       "\n",
       "   explanation_accuracy  explanation_accuracy_inv  elapsed_time  \\\n",
       "0                0.9928                    0.9928             0   \n",
       "1                0.9928                    0.9928             0   \n",
       "2                0.9928                    0.9928             0   \n",
       "3                0.9928                    0.9928             0   \n",
       "4                0.9928                    0.9928             0   \n",
       "5                0.9928                    0.9928             0   \n",
       "6                0.9928                    0.9928             0   \n",
       "7                0.9928                    0.9928             0   \n",
       "8                0.9928                    0.9928             0   \n",
       "9                0.9928                    0.9928             0   \n",
       "\n",
       "   elapsed_time_inv  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "5                 0  \n",
       "6                 0  \n",
       "7                 0  \n",
       "8                 0  \n",
       "9                 0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_tree = pd.DataFrame({\n",
    "    'method': methods,\n",
    "    'split': splits,\n",
    "    'explanation': explanations,\n",
    "    'explanation_inv': explanations_inv,\n",
    "    'model_accuracy': model_accuracies,\n",
    "    'explanation_accuracy': explanation_accuracies,\n",
    "    'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "    'elapsed_time': elapsed_times,\n",
    "    'elapsed_time_inv': elapsed_times_inv,\n",
    "})\n",
    "results_tree.to_csv(os.path.join(results_dir, 'results_tree.csv'))\n",
    "results_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_accuracy_mean</th>\n",
       "      <th>explanation_accuracy_mean</th>\n",
       "      <th>explanation_accuracy_inv_mean</th>\n",
       "      <th>elapsed_time_mean</th>\n",
       "      <th>elapsed_time_inv_mean</th>\n",
       "      <th>model_accuracy_sem</th>\n",
       "      <th>explanation_accuracy_sem</th>\n",
       "      <th>explanation_accuracy_inv_sem</th>\n",
       "      <th>elapsed_time_sem</th>\n",
       "      <th>elapsed_time_inv_sem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pruning</th>\n",
       "      <td>0.99280</td>\n",
       "      <td>0.99280</td>\n",
       "      <td>0.99280</td>\n",
       "      <td>58.752320</td>\n",
       "      <td>56.423216</td>\n",
       "      <td>3.700743e-17</td>\n",
       "      <td>3.700743e-17</td>\n",
       "      <td>3.700743e-17</td>\n",
       "      <td>1.263801</td>\n",
       "      <td>1.234340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weights</th>\n",
       "      <td>0.99280</td>\n",
       "      <td>0.74574</td>\n",
       "      <td>0.98437</td>\n",
       "      <td>114.944162</td>\n",
       "      <td>110.888210</td>\n",
       "      <td>3.700743e-17</td>\n",
       "      <td>9.939579e-02</td>\n",
       "      <td>8.430000e-03</td>\n",
       "      <td>1.548800</td>\n",
       "      <td>1.541385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psi</th>\n",
       "      <td>0.79145</td>\n",
       "      <td>0.52054</td>\n",
       "      <td>0.71794</td>\n",
       "      <td>0.109801</td>\n",
       "      <td>0.083486</td>\n",
       "      <td>3.279919e-02</td>\n",
       "      <td>5.455612e-02</td>\n",
       "      <td>5.017173e-02</td>\n",
       "      <td>0.018737</td>\n",
       "      <td>0.013712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>0.99280</td>\n",
       "      <td>0.99280</td>\n",
       "      <td>0.99280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.700743e-17</td>\n",
       "      <td>3.700743e-17</td>\n",
       "      <td>3.700743e-17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model_accuracy_mean  explanation_accuracy_mean  \\\n",
       "pruning              0.99280                    0.99280   \n",
       "weights              0.99280                    0.74574   \n",
       "psi                  0.79145                    0.52054   \n",
       "tree                 0.99280                    0.99280   \n",
       "\n",
       "         explanation_accuracy_inv_mean  elapsed_time_mean  \\\n",
       "pruning                        0.99280          58.752320   \n",
       "weights                        0.98437         114.944162   \n",
       "psi                            0.71794           0.109801   \n",
       "tree                           0.99280           0.000000   \n",
       "\n",
       "         elapsed_time_inv_mean  model_accuracy_sem  explanation_accuracy_sem  \\\n",
       "pruning              56.423216        3.700743e-17              3.700743e-17   \n",
       "weights             110.888210        3.700743e-17              9.939579e-02   \n",
       "psi                   0.083486        3.279919e-02              5.455612e-02   \n",
       "tree                  0.000000        3.700743e-17              3.700743e-17   \n",
       "\n",
       "         explanation_accuracy_inv_sem  elapsed_time_sem  elapsed_time_inv_sem  \n",
       "pruning                  3.700743e-17          1.263801              1.234340  \n",
       "weights                  8.430000e-03          1.548800              1.541385  \n",
       "psi                      5.017173e-02          0.018737              0.013712  \n",
       "tree                     3.700743e-17          0.000000              0.000000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['model_accuracy', 'explanation_accuracy', 'explanation_accuracy_inv', 'elapsed_time', 'elapsed_time_inv']\n",
    "mean_cols = [f'{c}_mean' for c in cols]\n",
    "sem_cols = [f'{c}_sem' for c in cols]\n",
    "\n",
    "# pruning\n",
    "df_mean = results_pruning[cols].mean()\n",
    "df_sem = results_pruning[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_pruning = pd.concat([df_mean, df_sem])\n",
    "summary_pruning.name = 'pruning'\n",
    "\n",
    "# # lime\n",
    "# df_mean = results_lime[cols].mean()\n",
    "# df_sem = results_lime[cols].sem()\n",
    "# df_mean.columns = mean_cols\n",
    "# df_sem.columns = sem_cols\n",
    "# summary_lime = pd.concat([df_mean, df_sem])\n",
    "# summary_lime.name = 'lime'\n",
    "\n",
    "# weights\n",
    "df_mean = results_weights[cols].mean()\n",
    "df_sem = results_weights[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_weights = pd.concat([df_mean, df_sem])\n",
    "summary_weights.name = 'weights'\n",
    "\n",
    "# psi\n",
    "df_mean = results_psi[cols].mean()\n",
    "df_sem = results_psi[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_psi = pd.concat([df_mean, df_sem])\n",
    "summary_psi.name = 'psi'\n",
    "\n",
    "# tree\n",
    "df_mean = results_tree[cols].mean()\n",
    "df_sem = results_tree[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_tree = pd.concat([df_mean, df_sem])\n",
    "summary_tree.name = 'tree'\n",
    "\n",
    "summary = pd.concat([summary_pruning, \n",
    "#                      summary_lime, \n",
    "                     summary_weights, summary_psi, summary_tree], axis=1).T\n",
    "summary.columns = mean_cols + sem_cols\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_csv(os.path.join(results_dir, 'summary.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
