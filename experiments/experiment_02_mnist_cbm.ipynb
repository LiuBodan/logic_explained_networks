{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sympy import simplify_logic\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.tree import _tree, export_text\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from deep_logic.utils.base import validate_network, set_seed, tree_to_formula\n",
    "from deep_logic.utils.relunn import get_reduced_model, prune_features\n",
    "from deep_logic.utils.sigmoidnn import prune_equal_fanin\n",
    "from deep_logic import logic\n",
    "\n",
    "results_dir = 'results/mnist'\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "concepts = [f'c{i}' for i in range(10)]\n",
    "n_rep = 10\n",
    "tot_epochs = 4001\n",
    "prune_epochs = 2000\n",
    "concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST problem\n",
    "num_workers = 0\n",
    "batch_size = 128\n",
    "valid_size = 0.2\n",
    "# Data augmentation for train data + conversion to tensor\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "   \n",
    "])# Data augmentation for test data + conversion to tensor\n",
    "test_transforms= transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(0.5,))\n",
    "])\n",
    "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=train_transforms)\n",
    "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding indices for validation set\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "#Randomize indices\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(num_train*valid_size))\n",
    "train_index, test_index = indices[split:], indices[:split]# Making samplers for training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_index)\n",
    "valid_sampler = SubsetRandomSampler(test_index)# Creating data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # convolutional layers\n",
    "        self.conv1 = torch.nn.Conv2d(1, 8, 3, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(8, 16, 3, padding =1)\n",
    "        # linear layers\n",
    "        self.fc1 = torch.nn.Linear(784, 256)\n",
    "        self.fc2 = torch.nn.Linear(256, 128)\n",
    "        self.fc3 = torch.nn.Linear(128, 64)\n",
    "        self.fc4 = torch.nn.Linear(64, 10) \n",
    "        # dropout\n",
    "        self.dropout = torch.nn.Dropout(p=0.2)\n",
    "        # max pooling\n",
    "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # convolutional layers with ReLU and pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # flattening the image\n",
    "        x = x.view(-1, 7*7*16)\n",
    "        # linear layers\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = self.fc4(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "        \n",
    "model = Net()\n",
    "print(model)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "if os.path.isfile('trained_model.pt'):\n",
    "    model.load_state_dict(torch.load('trained_model.pt'))\n",
    "\n",
    "else:\n",
    "    # epochs to train for\n",
    "    epochs = 25\n",
    "    set_seed(0)\n",
    "\n",
    "    # tracks validation loss change after each epoch\n",
    "    minimum_validation_loss = np.inf \n",
    "\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr = 0.001)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(1, epochs+1):\n",
    "\n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "\n",
    "        # training steps\n",
    "        model.train()\n",
    "        for batch_index, (data, target) in enumerate(train_loader):\n",
    "            # moves tensors to GPU\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            # clears gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass\n",
    "            output = model(data)\n",
    "            # loss in batch\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass for loss gradient\n",
    "            loss.backward()\n",
    "            # update paremeters\n",
    "            optimizer.step()\n",
    "            # update training loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "\n",
    "        # validation steps\n",
    "        model.eval()\n",
    "        for batch_index, (data, target) in enumerate(valid_loader):\n",
    "            # moves tensors to GPU\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            # forward pass\n",
    "            output = model(data)\n",
    "            # loss in batch\n",
    "            loss = criterion(output, target)\n",
    "            # update validation loss\n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "\n",
    "        # average loss calculations\n",
    "        train_loss = train_loss/len(train_loader.sampler)\n",
    "        valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "\n",
    "        # Display loss statistics\n",
    "        print(f'Current Epoch: {epoch}\\nTraining Loss: {round(train_loss, 6)}\\nValidation Loss: {round(valid_loss, 6)}')\n",
    "\n",
    "        # Saving model every time validation loss decreases\n",
    "        if valid_loss <= minimum_validation_loss and epoch > 20:\n",
    "            print(f'Validation loss decreased from {round(minimum_validation_loss, 6)} to {round(valid_loss, 6)}')\n",
    "            torch.save(model.state_dict(), 'trained_model.pt')\n",
    "            minimum_validation_loss = valid_loss\n",
    "            print('Saving New Model')\n",
    "    \n",
    "    model.load_state_dict(torch.load('trained_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.472841\n",
      "Test Accuracy of 0: 98.68%\n",
      "Test Accuracy of 1: 98.89%\n",
      "Test Accuracy of 2: 100.0%\n",
      "Test Accuracy of 3: 98.63%\n",
      "Test Accuracy of 4: 100.0%\n",
      "Test Accuracy of 5: 97.06%\n",
      "Test Accuracy of 6: 98.39%\n",
      "Test Accuracy of 7: 100.0%\n",
      "Test Accuracy of 8: 100.0%\n",
      "Test Accuracy of 9: 98.8%\n",
      "Full Test Accuracy: 99.11% 783.0 out of 790.0\n"
     ]
    }
   ],
   "source": [
    "# tracking test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model.eval()\n",
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    # move tensors to GPU\n",
    "    data, target = data.cuda(), target.cuda()\n",
    "    # forward pass\n",
    "    output = model(data)\n",
    "    # batch loss\n",
    "    loss = criterion(output, target)\n",
    "    # test loss update\n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(10):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print(f'Test Loss: {round(test_loss, 6)}')\n",
    "\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print(f'Test Accuracy of {classes[i]}: {round(100*class_correct[i]/class_total[i], 2)}%')\n",
    "    else:\n",
    "        print(f'Test Accuracy of {classes[i]}s: N/A (no training examples)')\n",
    "        \n",
    "        \n",
    "print(f'Full Test Accuracy: {round(100. * np.sum(class_correct) / np.sum(class_total), 2)}% {np.sum(class_correct)} out of {np.sum(class_total)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_c_train = []\n",
    "true_c_train = []\n",
    "model.eval()\n",
    "for batch_index, (data, target) in enumerate(train_loader):\n",
    "    # moves tensors to GPU\n",
    "    data, target = data.cuda(), target.cuda()\n",
    "    # forward pass\n",
    "    output = model(data)\n",
    "    pred = torch.argmax(output, 1)\n",
    "    pred_c_train.append(pred)\n",
    "    true_c_train.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_c_train = torch.cat(pred_c_train)\n",
    "true_c_train = torch.cat(true_c_train)\n",
    "pred_c_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = (true_c_train % 2 == 1).to(torch.long)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48000, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = OneHotEncoder(sparse=False).fit_transform(pred_c_train.cpu().detach().numpy().reshape(-1, 1))\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_c_test = []\n",
    "true_c_test = []\n",
    "model.eval()\n",
    "for batch_index, (data, target) in enumerate(test_loader):\n",
    "    # moves tensors to GPU\n",
    "    data, target = data.cuda(), target.cuda()\n",
    "    # forward pass\n",
    "    output = model(data)\n",
    "    pred = torch.argmax(output, 1)\n",
    "    pred_c_test.append(pred)\n",
    "    true_c_test.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_c_test = torch.cat(pred_c_test)\n",
    "true_c_test = torch.cat(true_c_test)\n",
    "pred_c_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = (true_c_test % 2 == 1).to(torch.long)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = OneHotEncoder(sparse=False).fit_transform(true_c_test.cpu().detach().numpy().reshape(-1, 1))\n",
    "x_test = torch.FloatTensor(x_test)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(x_train, y_train, need_pruning, seed, device, relu=False):\n",
    "    set_seed(seed)\n",
    "    x_train = x_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    layers = [\n",
    "        torch.nn.Linear(x_train.size(1), 100),\n",
    "        torch.nn.ReLU() if relu else torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(100, 50),\n",
    "        torch.nn.ReLU() if relu else torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(50, 30),\n",
    "        torch.nn.ReLU() if relu else torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(30, 2),\n",
    "        torch.nn.Softmax(dim=1),\n",
    "    ]\n",
    "    model = torch.nn.Sequential(*layers).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "    loss_form = torch.nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    for epoch in range(tot_epochs):\n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_train)\n",
    "        # Compute Loss\n",
    "        loss = loss_form(y_pred, y_train)\n",
    "\n",
    "        for module in model.children():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                loss += 0.01 * torch.norm(module.weight, 1)\n",
    "                loss += 0.01 * torch.norm(module.bias, 1)\n",
    "                break\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch > prune_epochs and need_pruning:\n",
    "            prune_features(model, n_classes=1, device=device)\n",
    "            need_pruning = False\n",
    "            \n",
    "        # compute accuracy\n",
    "        if epoch % 500 == 0:\n",
    "            y_pred_d = torch.argmax(y_pred, dim=1)\n",
    "            accuracy = y_pred_d.eq(y_train).sum().item() / y_train.size(0)\n",
    "            print(f'\\t Epoch {epoch}: train accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed [1/10]\n",
      "\t Epoch 0: train accuracy: 0.4924\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.9960\n",
      "\t Epoch 3000: train accuracy: 0.9960\n",
      "\t Epoch 3500: train accuracy: 0.9960\n",
      "\t Epoch 4000: train accuracy: 0.9960\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: \"~c0 & ~c2 & ~c4 & ~c6 & ~c8\" - Accuracy: 1.0000\n",
      "\t Elapsed time 53.99287390708923\n",
      "\t Class 0 - Global explanation: \"c0 | c2 | c4 | c6 | c8\" - Accuracy: 1.0000\n",
      "\t Elapsed time 57.6913800239563\n",
      "Seed [2/10]\n",
      "\t Epoch 0: train accuracy: 0.4924\n",
      "\t Epoch 500: train accuracy: 0.9960\n"
     ]
    }
   ],
   "source": [
    "need_pruning = True\n",
    "method = 'pruning'\n",
    "methods = []\n",
    "splits = []\n",
    "explanations = []\n",
    "explanations_inv = []\n",
    "model_accuracies = []\n",
    "explanation_accuracies = []\n",
    "explanation_accuracies_inv = []\n",
    "elapsed_times = []\n",
    "elapsed_times_inv = []\n",
    "for seed in range(n_rep):\n",
    "    print(f'Seed [{seed+1}/{n_rep}]')\n",
    "    \n",
    "    model = train_nn(x_train, y_train, need_pruning, seed, device)\n",
    "    \n",
    "    y_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "    model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds.argmax(axis=1))\n",
    "    print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "    \n",
    "    # positive class\n",
    "    target_class = 1\n",
    "    start = time.time()\n",
    "    global_explanation, _, _ = logic.relunn.combine_local_explanations(model, \n",
    "                                                                       x_train.to(device), y_train.to(device), \n",
    "                                                                       target_class=target_class,\n",
    "                                                                       topk_explanations=10,\n",
    "                                                                       method=method, device=device)\n",
    "    elapsed_time = time.time() - start\n",
    "    if global_explanation:\n",
    "        explanation_accuracy, _ = logic.base.test_explanation(global_explanation, target_class, x_test, y_test)\n",
    "        explanation = logic.base.replace_names(global_explanation, concepts)\n",
    "    print(f'\\t Class {target_class} - Global explanation: \"{explanation}\" - Accuracy: {explanation_accuracy:.4f}')\n",
    "    print(f'\\t Elapsed time {elapsed_time}')\n",
    "        \n",
    "    # negative class\n",
    "    target_class = 0\n",
    "    start = time.time()\n",
    "    global_explanation_inv, _, _ = logic.relunn.combine_local_explanations(model, \n",
    "                                                                           x_train.to(device), y_train.to(device), \n",
    "                                                                           target_class=target_class,\n",
    "                                                                           topk_explanations=10,\n",
    "                                                                           method=method, device=device)\n",
    "    elapsed_time_inv = time.time() - start\n",
    "    if global_explanation_inv:\n",
    "        explanation_accuracy_inv, _ = logic.base.test_explanation(global_explanation_inv, target_class, x_test, y_test)\n",
    "        explanation_inv = logic.base.replace_names(global_explanation_inv, concepts)\n",
    "    print(f'\\t Class {target_class} - Global explanation: \"{explanation_inv}\" - Accuracy: {explanation_accuracy_inv:.4f}')\n",
    "    print(f'\\t Elapsed time {elapsed_time_inv}')\n",
    "    \n",
    "    methods.append(method)\n",
    "    splits.append(seed)\n",
    "    explanations.append(explanation)\n",
    "    explanations_inv.append(explanation_inv)\n",
    "    model_accuracies.append(model_accuracy)\n",
    "    explanation_accuracies.append(explanation_accuracy)\n",
    "    explanation_accuracies_inv.append(explanation_accuracy_inv)\n",
    "    elapsed_times.append(elapsed_time)\n",
    "    elapsed_times_inv.append(elapsed_time_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pruning = pd.DataFrame({\n",
    "    'method': methods,\n",
    "    'split': splits,\n",
    "    'explanation': explanations,\n",
    "    'explanation_inv': explanations_inv,\n",
    "    'model_accuracy': model_accuracies,\n",
    "    'explanation_accuracy': explanation_accuracies,\n",
    "    'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "    'elapsed_time': elapsed_times,\n",
    "    'elapsed_time_inv': elapsed_times_inv,\n",
    "})\n",
    "results_pruning.to_csv(os.path.join(results_dir, 'results_pruning.csv'))\n",
    "results_pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need_pruning = False\n",
    "# method = 'lime'\n",
    "# methods = []\n",
    "# splits = []\n",
    "# explanations = []\n",
    "# explanations_inv = []\n",
    "# model_accuracies = []\n",
    "# explanation_accuracies = []\n",
    "# explanation_accuracies_inv = []\n",
    "# elapsed_times = []\n",
    "# elapsed_times_inv = []\n",
    "# for seed in range(n_rep):\n",
    "#     print(f'Seed [{seed+1}/{n_rep}]')\n",
    "    \n",
    "#     model = train_nn(x_train, y_train, need_pruning, seed, device)\n",
    "    \n",
    "#     y_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "#     model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds.argmax(axis=1))\n",
    "#     print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "    \n",
    "#     # positive class\n",
    "#     target_class = 1\n",
    "#     start = time.time()\n",
    "#     global_explanation, _, _ = logic.relunn.combine_local_explanations(model, \n",
    "#                                                                        x_train.to(device), y_train.to(device), \n",
    "#                                                                        target_class=target_class,\n",
    "#                                                                        method=method, device=device)\n",
    "#     elapsed_time = time.time() - start\n",
    "#     if global_explanation:\n",
    "#         explanation_accuracy, _ = logic.base.test_explanation(global_explanation, target_class, x_test, y_test)\n",
    "#         explanation = logic.base.replace_names(global_explanation, concepts)\n",
    "#     print(f'\\t Class {target_class} - Global explanation: \"{explanation}\" - Accuracy: {explanation_accuracy:.4f}')\n",
    "#     print(f'\\t Elapsed time {elapsed_time}')\n",
    "        \n",
    "#     # negative class\n",
    "#     target_class = 0\n",
    "#     start = time.time()\n",
    "#     global_explanation_inv, _, _ = logic.relunn.combine_local_explanations(model, \n",
    "#                                                                            x_train.to(device), y_train.to(device), \n",
    "#                                                                            target_class=target_class,\n",
    "#                                                                            method=method, device=device)\n",
    "#     elapsed_time_inv = time.time() - start\n",
    "#     if global_explanation_inv:\n",
    "#         explanation_accuracy_inv, _ = logic.base.test_explanation(global_explanation_inv, target_class, x_test, y_test)\n",
    "#         explanation_inv = logic.base.replace_names(global_explanation_inv, concepts)\n",
    "#     print(f'\\t Class {target_class} - Global explanation: \"{explanation_inv}\" - Accuracy: {explanation_accuracy_inv:.4f}')\n",
    "#     print(f'\\t Elapsed time {elapsed_time_inv}')\n",
    "    \n",
    "#     methods.append(method)\n",
    "#     splits.append(seed)\n",
    "#     explanations.append(explanation)\n",
    "#     explanations_inv.append(explanation_inv)\n",
    "#     model_accuracies.append(model_accuracy)\n",
    "#     explanation_accuracies.append(explanation_accuracy)\n",
    "#     explanation_accuracies_inv.append(explanation_accuracy_inv)\n",
    "#     elapsed_times.append(elapsed_time)\n",
    "#     elapsed_times_inv.append(elapsed_time_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_lime = pd.DataFrame({\n",
    "#     'method': methods,\n",
    "#     'split': splits,\n",
    "#     'explanation': explanations,\n",
    "#     'explanation_inv': explanations_inv,\n",
    "#     'model_accuracy': model_accuracies,\n",
    "#     'explanation_accuracy': explanation_accuracies,\n",
    "#     'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "#     'elapsed_time': elapsed_times,\n",
    "#     'elapsed_time_inv': elapsed_times_inv,\n",
    "# })\n",
    "# results_lime.to_csv(os.path.join(results_dir, 'results_lime.csv'))\n",
    "# results_lime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "need_pruning = False\n",
    "method = 'weights'\n",
    "methods = []\n",
    "splits = []\n",
    "explanations = []\n",
    "explanations_inv = []\n",
    "model_accuracies = []\n",
    "explanation_accuracies = []\n",
    "explanation_accuracies_inv = []\n",
    "elapsed_times = []\n",
    "elapsed_times_inv = []\n",
    "for seed in range(n_rep):\n",
    "    print(f'Seed [{seed+1}/{n_rep}]')\n",
    "    \n",
    "    model = train_nn(x_train, y_train, need_pruning, seed, device, relu=True)\n",
    "    \n",
    "    y_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "    model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds.argmax(axis=1))\n",
    "    print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "    \n",
    "    # positive class\n",
    "    target_class = 1\n",
    "    start = time.time()\n",
    "    global_explanation, _, _ = logic.relunn.combine_local_explanations(model, \n",
    "                                                                       x_train.to(device), y_train.to(device),\n",
    "                                                                       topk_explanations=10, \n",
    "                                                                       target_class=target_class,\n",
    "                                                                       method=method, device=device)\n",
    "    elapsed_time = time.time() - start\n",
    "    if global_explanation:\n",
    "        explanation_accuracy, _ = logic.base.test_explanation(global_explanation, target_class, x_test, y_test)\n",
    "        explanation = logic.base.replace_names(global_explanation, concepts)\n",
    "    print(f'\\t Class {target_class} - Global explanation: \"{explanation}\" - Accuracy: {explanation_accuracy:.4f}')\n",
    "    print(f'\\t Elapsed time {elapsed_time}')\n",
    "        \n",
    "    # negative class\n",
    "    target_class = 0\n",
    "    start = time.time()\n",
    "    global_explanation_inv, _, _ = logic.relunn.combine_local_explanations(model, \n",
    "                                                                           x_train.to(device), y_train.to(device), \n",
    "                                                                           topk_explanations=10, \n",
    "                                                                           target_class=target_class,\n",
    "                                                                           method=method, device=device)\n",
    "    elapsed_time_inv = time.time() - start\n",
    "    if global_explanation_inv:\n",
    "        explanation_accuracy_inv, _ = logic.base.test_explanation(global_explanation_inv, target_class, x_test, y_test)\n",
    "        explanation_inv = logic.base.replace_names(global_explanation_inv, concepts)\n",
    "    print(f'\\t Class {target_class} - Global explanation: \"{explanation_inv}\" - Accuracy: {explanation_accuracy_inv:.4f}')\n",
    "    print(f'\\t Elapsed time {elapsed_time_inv}')\n",
    "    \n",
    "    methods.append(method)\n",
    "    splits.append(seed)\n",
    "    explanations.append(explanation)\n",
    "    explanations_inv.append(explanation_inv)\n",
    "    model_accuracies.append(model_accuracy)\n",
    "    explanation_accuracies.append(explanation_accuracy)\n",
    "    explanation_accuracies_inv.append(explanation_accuracy_inv)\n",
    "    elapsed_times.append(elapsed_time)\n",
    "    elapsed_times_inv.append(elapsed_time_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_weights = pd.DataFrame({\n",
    "    'method': methods,\n",
    "    'split': splits,\n",
    "    'explanation': explanations,\n",
    "    'explanation_inv': explanations_inv,\n",
    "    'model_accuracy': model_accuracies,\n",
    "    'explanation_accuracy': explanation_accuracies,\n",
    "    'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "    'elapsed_time': elapsed_times,\n",
    "    'elapsed_time_inv': elapsed_times_inv,\n",
    "})\n",
    "results_weights.to_csv(os.path.join(results_dir, 'results_weights.csv'))\n",
    "results_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Psi network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_psi_nn(x_train, y_train, need_pruning, seed, device):\n",
    "    set_seed(seed)\n",
    "    x_train = x_train.to(device)\n",
    "    y_train = y_train.to(device).to(torch.float)\n",
    "    layers = [\n",
    "        torch.nn.Linear(x_train.size(1), 10),\n",
    "        torch.nn.Sigmoid(),\n",
    "        torch.nn.Linear(10, 4),\n",
    "        torch.nn.Sigmoid(),\n",
    "        torch.nn.Linear(4, 1),\n",
    "        torch.nn.Sigmoid(),\n",
    "    ]\n",
    "    model = torch.nn.Sequential(*layers).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_form = torch.nn.BCELoss()\n",
    "    model.train()\n",
    "    for epoch in range(tot_epochs):\n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_train).squeeze()\n",
    "        # Compute Loss\n",
    "        loss = loss_form(y_pred, y_train)\n",
    "\n",
    "        for module in model.children():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                loss += 0.00001 * torch.norm(module.weight, 1)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch > prune_epochs and need_pruning:\n",
    "            model = prune_equal_fanin(model, 2, validate=True, device=device)\n",
    "            need_pruning = False\n",
    "            \n",
    "        # compute accuracy\n",
    "        if epoch % 500 == 0:\n",
    "            y_pred_d = y_pred > 0.5\n",
    "            accuracy = y_pred_d.eq(y_train).sum().item() / y_train.size(0)\n",
    "            print(f'\\t Epoch {epoch}: train accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "need_pruning = True\n",
    "method = 'psi'\n",
    "methods = []\n",
    "splits = []\n",
    "explanations = []\n",
    "explanations_inv = []\n",
    "model_accuracies = []\n",
    "explanation_accuracies = []\n",
    "explanation_accuracies_inv = []\n",
    "elapsed_times = []\n",
    "elapsed_times_inv = []\n",
    "for seed in range(n_rep):\n",
    "    print(f'Seed [{seed+1}/{n_rep}]')\n",
    "    \n",
    "    # positive class\n",
    "    target_class = 1\n",
    "    model = train_psi_nn(x_train, y_train, need_pruning, seed, device)\n",
    "    \n",
    "    y_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "    model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds > 0.5)\n",
    "    print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "    \n",
    "    start = time.time()\n",
    "    global_explanation = logic.generate_fol_explanations(model, device)[0]\n",
    "    elapsed_time = time.time() - start\n",
    "    explanation_accuracy, _ = logic.base.test_explanation(global_explanation, target_class, x_test, y_test)\n",
    "    explanation = logic.base.replace_names(global_explanation, concepts)\n",
    "    print(f'\\t Class {target_class} - Global explanation: \"{explanation}\" - Accuracy: {explanation_accuracy:.4f}')\n",
    "    print(f'\\t Elapsed time {elapsed_time}')\n",
    "        \n",
    "    # negative class\n",
    "    target_class = 0\n",
    "    model = train_psi_nn(x_train, y_train.eq(target_class), need_pruning, seed, device)\n",
    "    \n",
    "    y_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "    model_accuracy = accuracy_score(y_test.eq(target_class).cpu().detach().numpy(), y_preds > 0.5)\n",
    "    print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "    \n",
    "    start = time.time()\n",
    "    global_explanation_inv = logic.generate_fol_explanations(model, device)[0]\n",
    "    elapsed_time_inv = time.time() - start\n",
    "    explanation_accuracy_inv, _ = logic.base.test_explanation(global_explanation_inv, \n",
    "                                                              target_class, x_test, y_test)\n",
    "    explanation_inv = logic.base.replace_names(global_explanation_inv, concepts)\n",
    "    print(f'\\t Class {target_class} - Global explanation: \"{explanation_inv}\" - Accuracy: {explanation_accuracy_inv:.4f}')\n",
    "    print(f'\\t Elapsed time {elapsed_time_inv}')\n",
    "    \n",
    "    methods.append(method)\n",
    "    splits.append(seed)\n",
    "    explanations.append(explanation)\n",
    "    explanations_inv.append(explanation_inv)\n",
    "    model_accuracies.append(model_accuracy)\n",
    "    explanation_accuracies.append(explanation_accuracy)\n",
    "    explanation_accuracies_inv.append(explanation_accuracy_inv)\n",
    "    elapsed_times.append(elapsed_time)\n",
    "    elapsed_times_inv.append(elapsed_time_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_psi = pd.DataFrame({\n",
    "    'method': methods,\n",
    "    'split': splits,\n",
    "    'explanation': explanations,\n",
    "    'explanation_inv': explanations_inv,\n",
    "    'model_accuracy': model_accuracies,\n",
    "    'explanation_accuracy': explanation_accuracies,\n",
    "    'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "    'elapsed_time': elapsed_times,\n",
    "    'elapsed_time_inv': elapsed_times_inv,\n",
    "})\n",
    "results_psi.to_csv(os.path.join(results_dir, 'results_psi.csv'))\n",
    "results_psi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "need_pruning = False\n",
    "method = 'decision_tree'\n",
    "methods = []\n",
    "splits = []\n",
    "explanations = []\n",
    "explanations_inv = []\n",
    "model_accuracies = []\n",
    "explanation_accuracies = []\n",
    "explanation_accuracies_inv = []\n",
    "elapsed_times = []\n",
    "elapsed_times_inv = []\n",
    "for seed in range(n_rep):\n",
    "    print(f'Seed [{seed+1}/{n_rep}]')\n",
    "    \n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(x_train.cpu().detach().numpy(), y_train.cpu().detach().numpy())\n",
    "    y_preds = classifier.predict(x_test.cpu().detach().numpy())\n",
    "    model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds)\n",
    "    print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "    \n",
    "    target_class = 1\n",
    "    start = time.time()\n",
    "    explanation = tree_to_formula(classifier, concepts, target_class)\n",
    "    elapsed_time = time.time() - start\n",
    "    print(f'\\t Class {target_class} - Global explanation: {explanation}')\n",
    "    print(f'\\t Elapsed time {elapsed_time}')\n",
    "    \n",
    "    target_class = 0\n",
    "    start = time.time()\n",
    "    explanation_inv = tree_to_formula(classifier, concepts, target_class)\n",
    "    elapsed_time_inv = time.time() - start\n",
    "    print(f'\\t Class {target_class} - Global explanation: {explanation_inv}')\n",
    "    print(f'\\t Elapsed time {elapsed_time_inv}')\n",
    "    \n",
    "    methods.append(method)\n",
    "    splits.append(seed)\n",
    "    explanations.append(explanation)\n",
    "    explanations_inv.append(explanation_inv)\n",
    "    model_accuracies.append(model_accuracy)\n",
    "    explanation_accuracies.append(model_accuracy)\n",
    "    explanation_accuracies_inv.append(model_accuracy)\n",
    "    elapsed_times.append(0)\n",
    "    elapsed_times_inv.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tree = pd.DataFrame({\n",
    "    'method': methods,\n",
    "    'split': splits,\n",
    "    'explanation': explanations,\n",
    "    'explanation_inv': explanations_inv,\n",
    "    'model_accuracy': model_accuracies,\n",
    "    'explanation_accuracy': explanation_accuracies,\n",
    "    'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "    'elapsed_time': elapsed_times,\n",
    "    'elapsed_time_inv': elapsed_times_inv,\n",
    "})\n",
    "results_tree.to_csv(os.path.join(results_dir, 'results_tree.csv'))\n",
    "results_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['model_accuracy', 'explanation_accuracy', 'explanation_accuracy_inv', 'elapsed_time', 'elapsed_time_inv']\n",
    "mean_cols = [f'{c}_mean' for c in cols]\n",
    "sem_cols = [f'{c}_sem' for c in cols]\n",
    "\n",
    "# pruning\n",
    "df_mean = results_pruning[cols].mean()\n",
    "df_sem = results_pruning[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_pruning = pd.concat([df_mean, df_sem])\n",
    "summary_pruning.name = 'pruning'\n",
    "\n",
    "# # lime\n",
    "# df_mean = results_lime[cols].mean()\n",
    "# df_sem = results_lime[cols].sem()\n",
    "# df_mean.columns = mean_cols\n",
    "# df_sem.columns = sem_cols\n",
    "# summary_lime = pd.concat([df_mean, df_sem])\n",
    "# summary_lime.name = 'lime'\n",
    "\n",
    "# weights\n",
    "df_mean = results_weights[cols].mean()\n",
    "df_sem = results_weights[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_weights = pd.concat([df_mean, df_sem])\n",
    "summary_weights.name = 'weights'\n",
    "\n",
    "# psi\n",
    "df_mean = results_psi[cols].mean()\n",
    "df_sem = results_psi[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_psi = pd.concat([df_mean, df_sem])\n",
    "summary_psi.name = 'psi'\n",
    "\n",
    "# tree\n",
    "df_mean = results_tree[cols].mean()\n",
    "df_sem = results_tree[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_tree = pd.concat([df_mean, df_sem])\n",
    "summary_tree.name = 'tree'\n",
    "\n",
    "summary = pd.concat([summary_pruning, \n",
    "#                      summary_lime, \n",
    "                     summary_weights, summary_psi, summary_tree], axis=1).T\n",
    "summary.columns = mean_cols + sem_cols\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_csv(os.path.join(results_dir, 'summary.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
