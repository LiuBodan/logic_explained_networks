{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sympy import simplify_logic\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.tree import _tree, export_text\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from deep_logic.utils.base import validate_network, set_seed, tree_to_formula\n",
    "from deep_logic.utils.relunn import get_reduced_model, prune_features\n",
    "from deep_logic.utils.sigmoidnn import prune_equal_fanin\n",
    "from deep_logic import logic\n",
    "\n",
    "results_dir = './results/mnist'\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "concepts = [f'c{i}' for i in range(10)]\n",
    "n_rep = 10\n",
    "tot_epochs = 4001\n",
    "prune_epochs = 2000\n",
    "concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST problem\n",
    "num_workers = 0\n",
    "batch_size = 128\n",
    "valid_size = 0.2\n",
    "# Data augmentation for train data + conversion to tensor\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "   \n",
    "])# Data augmentation for test data + conversion to tensor\n",
    "test_transforms= transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(0.5,))\n",
    "])\n",
    "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=train_transforms)\n",
    "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding indices for validation set\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "#Randomize indices\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(num_train*valid_size))\n",
    "train_index, test_index = indices[split:], indices[:split]# Making samplers for training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_index)\n",
    "valid_sampler = SubsetRandomSampler(test_index)# Creating data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # convolutional layers\n",
    "        self.conv1 = torch.nn.Conv2d(1, 8, 3, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(8, 16, 3, padding =1)\n",
    "        # linear layers\n",
    "        self.fc1 = torch.nn.Linear(784, 256)\n",
    "        self.fc2 = torch.nn.Linear(256, 128)\n",
    "        self.fc3 = torch.nn.Linear(128, 64)\n",
    "        self.fc4 = torch.nn.Linear(64, 10) \n",
    "        # dropout\n",
    "        self.dropout = torch.nn.Dropout(p=0.2)\n",
    "        # max pooling\n",
    "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # convolutional layers with ReLU and pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # flattening the image\n",
    "        x = x.view(-1, 7*7*16)\n",
    "        # linear layers\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = self.fc4(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "        \n",
    "model = Net()\n",
    "print(model)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "if os.path.isfile('trained_model.pt'):\n",
    "    model.load_state_dict(torch.load('trained_model.pt'))\n",
    "\n",
    "else:\n",
    "    # epochs to train for\n",
    "    epochs = 25\n",
    "    set_seed(0)\n",
    "\n",
    "    # tracks validation loss change after each epoch\n",
    "    minimum_validation_loss = np.inf \n",
    "\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr = 0.001)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(1, epochs+1):\n",
    "\n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "\n",
    "        # training steps\n",
    "        model.train()\n",
    "        for batch_index, (data, target) in enumerate(train_loader):\n",
    "            # moves tensors to GPU\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            # clears gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass\n",
    "            output = model(data)\n",
    "            # loss in batch\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass for loss gradient\n",
    "            loss.backward()\n",
    "            # update paremeters\n",
    "            optimizer.step()\n",
    "            # update training loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "\n",
    "        # validation steps\n",
    "        model.eval()\n",
    "        for batch_index, (data, target) in enumerate(valid_loader):\n",
    "            # moves tensors to GPU\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            # forward pass\n",
    "            output = model(data)\n",
    "            # loss in batch\n",
    "            loss = criterion(output, target)\n",
    "            # update validation loss\n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "\n",
    "        # average loss calculations\n",
    "        train_loss = train_loss/len(train_loader.sampler)\n",
    "        valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "\n",
    "        # Display loss statistics\n",
    "        print(f'Current Epoch: {epoch}\\nTraining Loss: {round(train_loss, 6)}\\nValidation Loss: {round(valid_loss, 6)}')\n",
    "\n",
    "        # Saving model every time validation loss decreases\n",
    "        if valid_loss <= minimum_validation_loss and epoch > 20:\n",
    "            print(f'Validation loss decreased from {round(minimum_validation_loss, 6)} to {round(valid_loss, 6)}')\n",
    "            torch.save(model.state_dict(), 'trained_model.pt')\n",
    "            minimum_validation_loss = valid_loss\n",
    "            print('Saving New Model')\n",
    "    \n",
    "    model.load_state_dict(torch.load('trained_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.472841\n",
      "Test Accuracy of 0: 98.68%\n",
      "Test Accuracy of 1: 98.89%\n",
      "Test Accuracy of 2: 100.0%\n",
      "Test Accuracy of 3: 98.63%\n",
      "Test Accuracy of 4: 100.0%\n",
      "Test Accuracy of 5: 97.06%\n",
      "Test Accuracy of 6: 98.39%\n",
      "Test Accuracy of 7: 100.0%\n",
      "Test Accuracy of 8: 100.0%\n",
      "Test Accuracy of 9: 98.8%\n",
      "Full Test Accuracy: 99.11% 783.0 out of 790.0\n"
     ]
    }
   ],
   "source": [
    "# tracking test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model.eval()\n",
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    # move tensors to GPU\n",
    "    data, target = data.cuda(), target.cuda()\n",
    "    # forward pass\n",
    "    output = model(data)\n",
    "    # batch loss\n",
    "    loss = criterion(output, target)\n",
    "    # test loss update\n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(10):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print(f'Test Loss: {round(test_loss, 6)}')\n",
    "\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print(f'Test Accuracy of {classes[i]}: {round(100*class_correct[i]/class_total[i], 2)}%')\n",
    "    else:\n",
    "        print(f'Test Accuracy of {classes[i]}s: N/A (no training examples)')\n",
    "        \n",
    "        \n",
    "print(f'Full Test Accuracy: {round(100. * np.sum(class_correct) / np.sum(class_total), 2)}% {np.sum(class_correct)} out of {np.sum(class_total)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_c_train = []\n",
    "true_c_train = []\n",
    "model.eval()\n",
    "for batch_index, (data, target) in enumerate(train_loader):\n",
    "    # moves tensors to GPU\n",
    "    data, target = data.cuda(), target.cuda()\n",
    "    # forward pass\n",
    "    output = model(data)\n",
    "    pred = torch.argmax(output, 1)\n",
    "    pred_c_train.append(pred)\n",
    "    true_c_train.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_c_train = torch.cat(pred_c_train)\n",
    "true_c_train = torch.cat(true_c_train)\n",
    "pred_c_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = (true_c_train % 2 == 1).to(torch.long)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48000, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = OneHotEncoder(sparse=False).fit_transform(pred_c_train.cpu().detach().numpy().reshape(-1, 1))\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_c_test = []\n",
    "true_c_test = []\n",
    "model.eval()\n",
    "for batch_index, (data, target) in enumerate(test_loader):\n",
    "    # moves tensors to GPU\n",
    "    data, target = data.cuda(), target.cuda()\n",
    "    # forward pass\n",
    "    output = model(data)\n",
    "    pred = torch.argmax(output, 1)\n",
    "    pred_c_test.append(pred)\n",
    "    true_c_test.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_c_test = torch.cat(pred_c_test)\n",
    "true_c_test = torch.cat(true_c_test)\n",
    "pred_c_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = (true_c_test % 2 == 1).to(torch.long)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = OneHotEncoder(sparse=False).fit_transform(true_c_test.cpu().detach().numpy().reshape(-1, 1))\n",
    "x_test = torch.FloatTensor(x_test)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(x_train, y_train, need_pruning, seed, device, relu=False):\n",
    "    set_seed(seed)\n",
    "    x_train = x_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    layers = [\n",
    "        torch.nn.Linear(x_train.size(1), 100),\n",
    "        torch.nn.ReLU() if relu else torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(100, 50),\n",
    "        torch.nn.ReLU() if relu else torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(50, 30),\n",
    "        torch.nn.ReLU() if relu else torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(30, 2),\n",
    "        torch.nn.Softmax(dim=1),\n",
    "    ]\n",
    "    model = torch.nn.Sequential(*layers).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "    loss_form = torch.nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    for epoch in range(tot_epochs):\n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_train)\n",
    "        # Compute Loss\n",
    "        loss = loss_form(y_pred, y_train)\n",
    "\n",
    "        for module in model.children():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                loss += 0.01 * torch.norm(module.weight, 1)\n",
    "                loss += 0.01 * torch.norm(module.bias, 1)\n",
    "                break\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch > prune_epochs and need_pruning:\n",
    "            prune_features(model, n_classes=1, device=device)\n",
    "            need_pruning = False\n",
    "            \n",
    "        # compute accuracy\n",
    "        if epoch % 500 == 0:\n",
    "            y_pred_d = torch.argmax(y_pred, dim=1)\n",
    "            accuracy = y_pred_d.eq(y_train).sum().item() / y_train.size(0)\n",
    "            print(f'\\t Epoch {epoch}: train accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed [1/10]\n",
      "\t Epoch 0: train accuracy: 0.4924\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.9960\n",
      "\t Epoch 3000: train accuracy: 0.9960\n",
      "\t Epoch 3500: train accuracy: 0.9960\n",
      "\t Epoch 4000: train accuracy: 0.9960\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: \"~c0 & ~c2 & ~c4 & ~c6 & ~c8\" - Accuracy: 1.0000\n",
      "\t Elapsed time 53.99287390708923\n",
      "\t Class 0 - Global explanation: \"c0 | c2 | c4 | c6 | c8\" - Accuracy: 1.0000\n",
      "\t Elapsed time 57.6913800239563\n",
      "Seed [2/10]\n",
      "\t Epoch 0: train accuracy: 0.4924\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.9960\n",
      "\t Epoch 3000: train accuracy: 0.9960\n",
      "\t Epoch 3500: train accuracy: 0.9960\n",
      "\t Epoch 4000: train accuracy: 0.9960\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: \"c1 | c3 | c5 | c7 | c9\" - Accuracy: 1.0000\n",
      "\t Elapsed time 53.825268030166626\n",
      "\t Class 0 - Global explanation: \"~c1 & ~c3 & ~c5 & ~c7 & ~c9\" - Accuracy: 1.0000\n",
      "\t Elapsed time 55.06784701347351\n",
      "Seed [3/10]\n",
      "\t Epoch 0: train accuracy: 0.5076\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.9960\n",
      "\t Epoch 3000: train accuracy: 0.9960\n",
      "\t Epoch 3500: train accuracy: 0.9960\n",
      "\t Epoch 4000: train accuracy: 0.9960\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: \"c1 | c3 | c5 | c7 | c9\" - Accuracy: 1.0000\n",
      "\t Elapsed time 58.97556805610657\n",
      "\t Class 0 - Global explanation: \"~c1 & ~c3 & ~c5 & ~c7 & ~c9\" - Accuracy: 1.0000\n",
      "\t Elapsed time 50.578590631484985\n",
      "Seed [4/10]\n",
      "\t Epoch 0: train accuracy: 0.5076\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.9960\n",
      "\t Epoch 3000: train accuracy: 0.9960\n",
      "\t Epoch 3500: train accuracy: 0.9960\n",
      "\t Epoch 4000: train accuracy: 0.9960\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: \"~c0 & ~c2 & ~c4 & ~c6 & ~c8\" - Accuracy: 1.0000\n",
      "\t Elapsed time 46.087958574295044\n",
      "\t Class 0 - Global explanation: \"c0 | c2 | c4 | c6 | c8\" - Accuracy: 1.0000\n",
      "\t Elapsed time 44.425676584243774\n",
      "Seed [5/10]\n",
      "\t Epoch 0: train accuracy: 0.5076\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.9960\n",
      "\t Epoch 3000: train accuracy: 0.9960\n",
      "\t Epoch 3500: train accuracy: 0.9960\n",
      "\t Epoch 4000: train accuracy: 0.9960\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: \"c1 | c3 | c5 | c7 | c9\" - Accuracy: 1.0000\n",
      "\t Elapsed time 58.79706907272339\n",
      "\t Class 0 - Global explanation: \"~c1 & ~c3 & ~c5 & ~c7 & ~c9\" - Accuracy: 1.0000\n",
      "\t Elapsed time 56.528682470321655\n",
      "Seed [6/10]\n",
      "\t Epoch 0: train accuracy: 0.5076\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.9960\n",
      "\t Epoch 3000: train accuracy: 0.9960\n",
      "\t Epoch 3500: train accuracy: 0.9960\n",
      "\t Epoch 4000: train accuracy: 0.9960\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: \"c1 | c3 | c5 | c7 | c9\" - Accuracy: 1.0000\n",
      "\t Elapsed time 57.04067587852478\n",
      "\t Class 0 - Global explanation: \"~c1 & ~c3 & ~c5 & ~c7 & ~c9\" - Accuracy: 1.0000\n",
      "\t Elapsed time 51.34967255592346\n",
      "Seed [7/10]\n",
      "\t Epoch 0: train accuracy: 0.5076\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.9960\n",
      "\t Epoch 3000: train accuracy: 0.9960\n",
      "\t Epoch 3500: train accuracy: 0.9960\n",
      "\t Epoch 4000: train accuracy: 0.9960\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: \"c1 | c3 | c5 | c7 | c9\" - Accuracy: 1.0000\n",
      "\t Elapsed time 53.86235952377319\n",
      "\t Class 0 - Global explanation: \"~c1 & ~c3 & ~c5 & ~c7 & ~c9\" - Accuracy: 1.0000\n",
      "\t Elapsed time 68.91378331184387\n",
      "Seed [8/10]\n",
      "\t Epoch 0: train accuracy: 0.4924\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.9960\n",
      "\t Epoch 3000: train accuracy: 0.9960\n",
      "\t Epoch 3500: train accuracy: 0.9960\n",
      "\t Epoch 4000: train accuracy: 0.9960\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: \"~c0 & ~c2 & ~c4 & ~c6 & ~c8\" - Accuracy: 1.0000\n",
      "\t Elapsed time 84.72551655769348\n",
      "\t Class 0 - Global explanation: \"c0 | c2 | c4 | c6 | c8\" - Accuracy: 1.0000\n",
      "\t Elapsed time 84.12775802612305\n",
      "Seed [9/10]\n",
      "\t Epoch 0: train accuracy: 0.4924\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.9960\n",
      "\t Epoch 3000: train accuracy: 0.9960\n",
      "\t Epoch 3500: train accuracy: 0.9960\n",
      "\t Epoch 4000: train accuracy: 0.9960\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: \"~c0 & ~c2 & ~c4 & ~c6 & ~c8\" - Accuracy: 1.0000\n",
      "\t Elapsed time 94.52656435966492\n",
      "\t Class 0 - Global explanation: \"c0 | c2 | c4 | c6 | c8\" - Accuracy: 1.0000\n",
      "\t Elapsed time 92.34714794158936\n",
      "Seed [10/10]\n",
      "\t Epoch 0: train accuracy: 0.5076\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.9960\n",
      "\t Epoch 3000: train accuracy: 0.9960\n",
      "\t Epoch 3500: train accuracy: 0.9960\n",
      "\t Epoch 4000: train accuracy: 0.9960\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: \"~c0 & ~c2 & ~c4 & ~c6 & ~c8\" - Accuracy: 1.0000\n",
      "\t Elapsed time 79.41059947013855\n",
      "\t Class 0 - Global explanation: \"c0 | c2 | c4 | c6 | c8\" - Accuracy: 1.0000\n",
      "\t Elapsed time 70.12884163856506\n"
     ]
    }
   ],
   "source": [
    "need_pruning = True\n",
    "method = 'pruning'\n",
    "methods = []\n",
    "splits = []\n",
    "explanations = []\n",
    "explanations_inv = []\n",
    "model_accuracies = []\n",
    "explanation_accuracies = []\n",
    "explanation_accuracies_inv = []\n",
    "elapsed_times = []\n",
    "elapsed_times_inv = []\n",
    "for seed in range(n_rep):\n",
    "    print(f'Seed [{seed+1}/{n_rep}]')\n",
    "    \n",
    "    model = train_nn(x_train, y_train, need_pruning, seed, device)\n",
    "    \n",
    "    y_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "    model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds.argmax(axis=1))\n",
    "    print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "    \n",
    "    # positive class\n",
    "    target_class = 1\n",
    "    start = time.time()\n",
    "    global_explanation, _, _ = logic.relunn.combine_local_explanations(model, \n",
    "                                                                       x_train.to(device), y_train.to(device), \n",
    "                                                                       target_class=target_class,\n",
    "                                                                       topk_explanations=10,\n",
    "                                                                       method=method, device=device)\n",
    "    elapsed_time = time.time() - start\n",
    "    if global_explanation:\n",
    "        explanation_accuracy, _ = logic.base.test_explanation(global_explanation, target_class, x_test, y_test)\n",
    "        explanation = logic.base.replace_names(global_explanation, concepts)\n",
    "    print(f'\\t Class {target_class} - Global explanation: \"{explanation}\" - Accuracy: {explanation_accuracy:.4f}')\n",
    "    print(f'\\t Elapsed time {elapsed_time}')\n",
    "        \n",
    "    # negative class\n",
    "    target_class = 0\n",
    "    start = time.time()\n",
    "    global_explanation_inv, _, _ = logic.relunn.combine_local_explanations(model, \n",
    "                                                                           x_train.to(device), y_train.to(device), \n",
    "                                                                           target_class=target_class,\n",
    "                                                                           topk_explanations=10,\n",
    "                                                                           method=method, device=device)\n",
    "    elapsed_time_inv = time.time() - start\n",
    "    if global_explanation_inv:\n",
    "        explanation_accuracy_inv, _ = logic.base.test_explanation(global_explanation_inv, target_class, x_test, y_test)\n",
    "        explanation_inv = logic.base.replace_names(global_explanation_inv, concepts)\n",
    "    print(f'\\t Class {target_class} - Global explanation: \"{explanation_inv}\" - Accuracy: {explanation_accuracy_inv:.4f}')\n",
    "    print(f'\\t Elapsed time {elapsed_time_inv}')\n",
    "    \n",
    "    methods.append(method)\n",
    "    splits.append(seed)\n",
    "    explanations.append(explanation)\n",
    "    explanations_inv.append(explanation_inv)\n",
    "    model_accuracies.append(model_accuracy)\n",
    "    explanation_accuracies.append(explanation_accuracy)\n",
    "    explanation_accuracies_inv.append(explanation_accuracy_inv)\n",
    "    elapsed_times.append(elapsed_time)\n",
    "    elapsed_times_inv.append(elapsed_time_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>explanation_inv</th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_accuracy_inv</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>elapsed_time_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pruning</td>\n",
       "      <td>0</td>\n",
       "      <td>~c0 &amp; ~c2 &amp; ~c4 &amp; ~c6 &amp; ~c8</td>\n",
       "      <td>c0 | c2 | c4 | c6 | c8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.992874</td>\n",
       "      <td>57.691380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pruning</td>\n",
       "      <td>1</td>\n",
       "      <td>c1 | c3 | c5 | c7 | c9</td>\n",
       "      <td>~c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.825268</td>\n",
       "      <td>55.067847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pruning</td>\n",
       "      <td>2</td>\n",
       "      <td>c1 | c3 | c5 | c7 | c9</td>\n",
       "      <td>~c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.975568</td>\n",
       "      <td>50.578591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pruning</td>\n",
       "      <td>3</td>\n",
       "      <td>~c0 &amp; ~c2 &amp; ~c4 &amp; ~c6 &amp; ~c8</td>\n",
       "      <td>c0 | c2 | c4 | c6 | c8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.087959</td>\n",
       "      <td>44.425677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pruning</td>\n",
       "      <td>4</td>\n",
       "      <td>c1 | c3 | c5 | c7 | c9</td>\n",
       "      <td>~c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.797069</td>\n",
       "      <td>56.528682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pruning</td>\n",
       "      <td>5</td>\n",
       "      <td>c1 | c3 | c5 | c7 | c9</td>\n",
       "      <td>~c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.040676</td>\n",
       "      <td>51.349673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pruning</td>\n",
       "      <td>6</td>\n",
       "      <td>c1 | c3 | c5 | c7 | c9</td>\n",
       "      <td>~c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.862360</td>\n",
       "      <td>68.913783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pruning</td>\n",
       "      <td>7</td>\n",
       "      <td>~c0 &amp; ~c2 &amp; ~c4 &amp; ~c6 &amp; ~c8</td>\n",
       "      <td>c0 | c2 | c4 | c6 | c8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.725517</td>\n",
       "      <td>84.127758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pruning</td>\n",
       "      <td>8</td>\n",
       "      <td>~c0 &amp; ~c2 &amp; ~c4 &amp; ~c6 &amp; ~c8</td>\n",
       "      <td>c0 | c2 | c4 | c6 | c8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.526564</td>\n",
       "      <td>92.347148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pruning</td>\n",
       "      <td>9</td>\n",
       "      <td>~c0 &amp; ~c2 &amp; ~c4 &amp; ~c6 &amp; ~c8</td>\n",
       "      <td>c0 | c2 | c4 | c6 | c8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.410599</td>\n",
       "      <td>70.128842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    method  split                  explanation              explanation_inv  \\\n",
       "0  pruning      0  ~c0 & ~c2 & ~c4 & ~c6 & ~c8       c0 | c2 | c4 | c6 | c8   \n",
       "1  pruning      1       c1 | c3 | c5 | c7 | c9  ~c1 & ~c3 & ~c5 & ~c7 & ~c9   \n",
       "2  pruning      2       c1 | c3 | c5 | c7 | c9  ~c1 & ~c3 & ~c5 & ~c7 & ~c9   \n",
       "3  pruning      3  ~c0 & ~c2 & ~c4 & ~c6 & ~c8       c0 | c2 | c4 | c6 | c8   \n",
       "4  pruning      4       c1 | c3 | c5 | c7 | c9  ~c1 & ~c3 & ~c5 & ~c7 & ~c9   \n",
       "5  pruning      5       c1 | c3 | c5 | c7 | c9  ~c1 & ~c3 & ~c5 & ~c7 & ~c9   \n",
       "6  pruning      6       c1 | c3 | c5 | c7 | c9  ~c1 & ~c3 & ~c5 & ~c7 & ~c9   \n",
       "7  pruning      7  ~c0 & ~c2 & ~c4 & ~c6 & ~c8       c0 | c2 | c4 | c6 | c8   \n",
       "8  pruning      8  ~c0 & ~c2 & ~c4 & ~c6 & ~c8       c0 | c2 | c4 | c6 | c8   \n",
       "9  pruning      9  ~c0 & ~c2 & ~c4 & ~c6 & ~c8       c0 | c2 | c4 | c6 | c8   \n",
       "\n",
       "   model_accuracy  explanation_accuracy  explanation_accuracy_inv  \\\n",
       "0             1.0                   1.0                       1.0   \n",
       "1             1.0                   1.0                       1.0   \n",
       "2             1.0                   1.0                       1.0   \n",
       "3             1.0                   1.0                       1.0   \n",
       "4             1.0                   1.0                       1.0   \n",
       "5             1.0                   1.0                       1.0   \n",
       "6             1.0                   1.0                       1.0   \n",
       "7             1.0                   1.0                       1.0   \n",
       "8             1.0                   1.0                       1.0   \n",
       "9             1.0                   1.0                       1.0   \n",
       "\n",
       "   elapsed_time  elapsed_time_inv  \n",
       "0     53.992874         57.691380  \n",
       "1     53.825268         55.067847  \n",
       "2     58.975568         50.578591  \n",
       "3     46.087959         44.425677  \n",
       "4     58.797069         56.528682  \n",
       "5     57.040676         51.349673  \n",
       "6     53.862360         68.913783  \n",
       "7     84.725517         84.127758  \n",
       "8     94.526564         92.347148  \n",
       "9     79.410599         70.128842  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_pruning = pd.DataFrame({\n",
    "    'method': methods,\n",
    "    'split': splits,\n",
    "    'explanation': explanations,\n",
    "    'explanation_inv': explanations_inv,\n",
    "    'model_accuracy': model_accuracies,\n",
    "    'explanation_accuracy': explanation_accuracies,\n",
    "    'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "    'elapsed_time': elapsed_times,\n",
    "    'elapsed_time_inv': elapsed_times_inv,\n",
    "})\n",
    "results_pruning.to_csv(os.path.join(results_dir, 'results_pruning.csv'))\n",
    "results_pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need_pruning = False\n",
    "# method = 'lime'\n",
    "# methods = []\n",
    "# splits = []\n",
    "# explanations = []\n",
    "# explanations_inv = []\n",
    "# model_accuracies = []\n",
    "# explanation_accuracies = []\n",
    "# explanation_accuracies_inv = []\n",
    "# elapsed_times = []\n",
    "# elapsed_times_inv = []\n",
    "# for seed in range(n_rep):\n",
    "#     print(f'Seed [{seed+1}/{n_rep}]')\n",
    "    \n",
    "#     model = train_nn(x_train, y_train, need_pruning, seed, device)\n",
    "    \n",
    "#     y_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "#     model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds.argmax(axis=1))\n",
    "#     print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "    \n",
    "#     # positive class\n",
    "#     target_class = 1\n",
    "#     start = time.time()\n",
    "#     global_explanation, _, _ = logic.relunn.combine_local_explanations(model, \n",
    "#                                                                        x_train.to(device), y_train.to(device), \n",
    "#                                                                        target_class=target_class,\n",
    "#                                                                        method=method, device=device)\n",
    "#     elapsed_time = time.time() - start\n",
    "#     if global_explanation:\n",
    "#         explanation_accuracy, _ = logic.base.test_explanation(global_explanation, target_class, x_test, y_test)\n",
    "#         explanation = logic.base.replace_names(global_explanation, concepts)\n",
    "#     print(f'\\t Class {target_class} - Global explanation: \"{explanation}\" - Accuracy: {explanation_accuracy:.4f}')\n",
    "#     print(f'\\t Elapsed time {elapsed_time}')\n",
    "        \n",
    "#     # negative class\n",
    "#     target_class = 0\n",
    "#     start = time.time()\n",
    "#     global_explanation_inv, _, _ = logic.relunn.combine_local_explanations(model, \n",
    "#                                                                            x_train.to(device), y_train.to(device), \n",
    "#                                                                            target_class=target_class,\n",
    "#                                                                            method=method, device=device)\n",
    "#     elapsed_time_inv = time.time() - start\n",
    "#     if global_explanation_inv:\n",
    "#         explanation_accuracy_inv, _ = logic.base.test_explanation(global_explanation_inv, target_class, x_test, y_test)\n",
    "#         explanation_inv = logic.base.replace_names(global_explanation_inv, concepts)\n",
    "#     print(f'\\t Class {target_class} - Global explanation: \"{explanation_inv}\" - Accuracy: {explanation_accuracy_inv:.4f}')\n",
    "#     print(f'\\t Elapsed time {elapsed_time_inv}')\n",
    "    \n",
    "#     methods.append(method)\n",
    "#     splits.append(seed)\n",
    "#     explanations.append(explanation)\n",
    "#     explanations_inv.append(explanation_inv)\n",
    "#     model_accuracies.append(model_accuracy)\n",
    "#     explanation_accuracies.append(explanation_accuracy)\n",
    "#     explanation_accuracies_inv.append(explanation_accuracy_inv)\n",
    "#     elapsed_times.append(elapsed_time)\n",
    "#     elapsed_times_inv.append(elapsed_time_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_lime = pd.DataFrame({\n",
    "#     'method': methods,\n",
    "#     'split': splits,\n",
    "#     'explanation': explanations,\n",
    "#     'explanation_inv': explanations_inv,\n",
    "#     'model_accuracy': model_accuracies,\n",
    "#     'explanation_accuracy': explanation_accuracies,\n",
    "#     'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "#     'elapsed_time': elapsed_times,\n",
    "#     'elapsed_time_inv': elapsed_times_inv,\n",
    "# })\n",
    "# results_lime.to_csv(os.path.join(results_dir, 'results_lime.csv'))\n",
    "# results_lime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed [1/10]\n",
      "\t Epoch 0: train accuracy: 0.4924\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.9960\n",
      "\t Epoch 3000: train accuracy: 0.9960\n",
      "\t Epoch 3500: train accuracy: 0.9960\n",
      "\t Epoch 4000: train accuracy: 0.9960\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: \"c1 | c3 | c5 | c7 | c9\" - Accuracy: 1.0000\n",
      "\t Elapsed time 71.51128125190735\n",
      "\t Class 0 - Global explanation: \"c4 | (~c1 & ~c3 & ~c5 & ~c7 & ~c9)\" - Accuracy: 1.0000\n",
      "\t Elapsed time 63.094101667404175\n",
      "Seed [2/10]\n",
      "\t Epoch 0: train accuracy: 0.4924\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.9960\n",
      "\t Epoch 3000: train accuracy: 0.9960\n",
      "\t Epoch 3500: train accuracy: 0.9960\n",
      "\t Epoch 4000: train accuracy: 0.9960\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: \"c1 | c3 | c5 | c7 | c9\" - Accuracy: 1.0000\n",
      "\t Elapsed time 80.8535327911377\n",
      "\t Class 0 - Global explanation: \"~c1 & ~c3 & ~c5 & ~c7 & ~c9\" - Accuracy: 1.0000\n",
      "\t Elapsed time 76.03640818595886\n",
      "Seed [3/10]\n",
      "\t Epoch 0: train accuracy: 0.5076\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.9960\n",
      "\t Epoch 3000: train accuracy: 0.9960\n",
      "\t Epoch 3500: train accuracy: 0.9960\n",
      "\t Epoch 4000: train accuracy: 0.9960\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: \"c1 | c3 | c5 | c7 | c9\" - Accuracy: 1.0000\n",
      "\t Elapsed time 72.00050115585327\n",
      "\t Class 0 - Global explanation: \"(~c1 & ~c3 & ~c5 & ~c7 & ~c9) | (~c1 & ~c2 & ~c3 & ~c4 & ~c6 & ~c7)\" - Accuracy: 0.8099\n",
      "\t Elapsed time 78.61089515686035\n",
      "Seed [4/10]\n",
      "\t Epoch 0: train accuracy: 0.5076\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.9960\n",
      "\t Epoch 3000: train accuracy: 0.9960\n",
      "\t Epoch 3500: train accuracy: 0.9960\n",
      "\t Epoch 4000: train accuracy: 0.9960\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: \"c5 | (~c0 & ~c2 & ~c4 & ~c6 & ~c8)\" - Accuracy: 0.9108\n",
      "\t Elapsed time 93.33064532279968\n",
      "\t Class 0 - Global explanation: \"c0 | c2 | c4 | c6 | c8\" - Accuracy: 1.0000\n",
      "\t Elapsed time 79.7328314781189\n",
      "Seed [5/10]\n",
      "\t Epoch 0: train accuracy: 0.5076\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.9960\n",
      "\t Epoch 3000: train accuracy: 0.9960\n",
      "\t Epoch 3500: train accuracy: 0.9960\n",
      "\t Epoch 4000: train accuracy: 0.9960\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: \"c1 | c3 | c5 | c7 | c9\" - Accuracy: 1.0000\n",
      "\t Elapsed time 80.39111256599426\n",
      "\t Class 0 - Global explanation: \"c6 | (~c1 & ~c3 & ~c5 & ~c7 & ~c9)\" - Accuracy: 1.0000\n",
      "\t Elapsed time 78.42005014419556\n",
      "Seed [6/10]\n",
      "\t Epoch 0: train accuracy: 0.5076\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.9960\n",
      "\t Epoch 3000: train accuracy: 0.9960\n",
      "\t Epoch 3500: train accuracy: 0.9960\n",
      "\t Epoch 4000: train accuracy: 0.9960\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: \"c3 | c9 | (~c0 & ~c2 & ~c4 & ~c6 & ~c8)\" - Accuracy: 0.7981\n",
      "\t Elapsed time 78.7939190864563\n",
      "\t Class 0 - Global explanation: \"c0 | c2 | c4 | c6 | c8\" - Accuracy: 1.0000\n",
      "\t Elapsed time 77.95794916152954\n",
      "Seed [7/10]\n",
      "\t Epoch 0: train accuracy: 0.5076\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.9960\n",
      "\t Epoch 3000: train accuracy: 0.9960\n",
      "\t Epoch 3500: train accuracy: 0.9960\n",
      "\t Epoch 4000: train accuracy: 0.9960\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: \"c1 | c3 | c5 | c7 | c9\" - Accuracy: 1.0000\n",
      "\t Elapsed time 79.90230584144592\n",
      "\t Class 0 - Global explanation: \"c0 | c4 | (~c1 & ~c3 & ~c5 & ~c7 & ~c9)\" - Accuracy: 1.0000\n",
      "\t Elapsed time 77.0436429977417\n",
      "Seed [8/10]\n",
      "\t Epoch 0: train accuracy: 0.4924\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.9960\n",
      "\t Epoch 3000: train accuracy: 0.9960\n",
      "\t Epoch 3500: train accuracy: 0.9960\n",
      "\t Epoch 4000: train accuracy: 0.9960\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: \"(~c0 & ~c2 & ~c4 & ~c6 & ~c8) | (~c2 & ~c4 & ~c5 & ~c8 & ~c9)\" - Accuracy: 0.4889\n",
      "\t Elapsed time 80.10816597938538\n",
      "\t Class 0 - Global explanation: \"c0 | c2 | c4 | c6 | c8\" - Accuracy: 1.0000\n",
      "\t Elapsed time 78.32670545578003\n",
      "Seed [9/10]\n",
      "\t Epoch 0: train accuracy: 0.4924\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.9960\n",
      "\t Epoch 3000: train accuracy: 0.9960\n",
      "\t Epoch 3500: train accuracy: 0.9960\n",
      "\t Epoch 4000: train accuracy: 0.9960\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: \"c1 | c3 | c5 | c7 | c9\" - Accuracy: 1.0000\n",
      "\t Elapsed time 81.18668961524963\n",
      "\t Class 0 - Global explanation: \"~c4 | (~c1 & ~c3 & ~c5 & ~c7 & ~c9)\" - Accuracy: 0.4926\n",
      "\t Elapsed time 76.37357020378113\n",
      "Seed [10/10]\n",
      "\t Epoch 0: train accuracy: 0.5076\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.9960\n",
      "\t Epoch 3000: train accuracy: 0.9960\n",
      "\t Epoch 3500: train accuracy: 0.9960\n",
      "\t Epoch 4000: train accuracy: 0.9960\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: \"(~c3 & ~c6) | (~c0 & ~c2 & ~c4 & ~c6 & ~c8)\" - Accuracy: 0.1968\n",
      "\t Elapsed time 79.29751372337341\n",
      "\t Class 0 - Global explanation: \"c0 | c2 | c4 | c6 | c8\" - Accuracy: 1.0000\n",
      "\t Elapsed time 78.45754814147949\n"
     ]
    }
   ],
   "source": [
    "need_pruning = False\n",
    "method = 'weights'\n",
    "methods = []\n",
    "splits = []\n",
    "explanations = []\n",
    "explanations_inv = []\n",
    "model_accuracies = []\n",
    "explanation_accuracies = []\n",
    "explanation_accuracies_inv = []\n",
    "elapsed_times = []\n",
    "elapsed_times_inv = []\n",
    "for seed in range(n_rep):\n",
    "    print(f'Seed [{seed+1}/{n_rep}]')\n",
    "    \n",
    "    model = train_nn(x_train, y_train, need_pruning, seed, device, relu=True)\n",
    "    \n",
    "    y_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "    model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds.argmax(axis=1))\n",
    "    print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "    \n",
    "    # positive class\n",
    "    target_class = 1\n",
    "    start = time.time()\n",
    "    global_explanation, _, _ = logic.relunn.combine_local_explanations(model, \n",
    "                                                                       x_train.to(device), y_train.to(device),\n",
    "                                                                       topk_explanations=10, \n",
    "                                                                       target_class=target_class,\n",
    "                                                                       method=method, device=device)\n",
    "    elapsed_time = time.time() - start\n",
    "    if global_explanation:\n",
    "        explanation_accuracy, _ = logic.base.test_explanation(global_explanation, target_class, x_test, y_test)\n",
    "        explanation = logic.base.replace_names(global_explanation, concepts)\n",
    "    print(f'\\t Class {target_class} - Global explanation: \"{explanation}\" - Accuracy: {explanation_accuracy:.4f}')\n",
    "    print(f'\\t Elapsed time {elapsed_time}')\n",
    "        \n",
    "    # negative class\n",
    "    target_class = 0\n",
    "    start = time.time()\n",
    "    global_explanation_inv, _, _ = logic.relunn.combine_local_explanations(model, \n",
    "                                                                           x_train.to(device), y_train.to(device), \n",
    "                                                                           topk_explanations=10, \n",
    "                                                                           target_class=target_class,\n",
    "                                                                           method=method, device=device)\n",
    "    elapsed_time_inv = time.time() - start\n",
    "    if global_explanation_inv:\n",
    "        explanation_accuracy_inv, _ = logic.base.test_explanation(global_explanation_inv, target_class, x_test, y_test)\n",
    "        explanation_inv = logic.base.replace_names(global_explanation_inv, concepts)\n",
    "    print(f'\\t Class {target_class} - Global explanation: \"{explanation_inv}\" - Accuracy: {explanation_accuracy_inv:.4f}')\n",
    "    print(f'\\t Elapsed time {elapsed_time_inv}')\n",
    "    \n",
    "    methods.append(method)\n",
    "    splits.append(seed)\n",
    "    explanations.append(explanation)\n",
    "    explanations_inv.append(explanation_inv)\n",
    "    model_accuracies.append(model_accuracy)\n",
    "    explanation_accuracies.append(explanation_accuracy)\n",
    "    explanation_accuracies_inv.append(explanation_accuracy_inv)\n",
    "    elapsed_times.append(elapsed_time)\n",
    "    elapsed_times_inv.append(elapsed_time_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>explanation_inv</th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_accuracy_inv</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>elapsed_time_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weights</td>\n",
       "      <td>0</td>\n",
       "      <td>c1 | c3 | c5 | c7 | c9</td>\n",
       "      <td>c4 | (~c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>71.511281</td>\n",
       "      <td>63.094102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weights</td>\n",
       "      <td>1</td>\n",
       "      <td>c1 | c3 | c5 | c7 | c9</td>\n",
       "      <td>~c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>80.853533</td>\n",
       "      <td>76.036408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weights</td>\n",
       "      <td>2</td>\n",
       "      <td>c1 | c3 | c5 | c7 | c9</td>\n",
       "      <td>(~c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9) | (~c1 &amp; ~c2 &amp; ~...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8099</td>\n",
       "      <td>72.000501</td>\n",
       "      <td>78.610895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weights</td>\n",
       "      <td>3</td>\n",
       "      <td>c5 | (~c0 &amp; ~c2 &amp; ~c4 &amp; ~c6 &amp; ~c8)</td>\n",
       "      <td>c0 | c2 | c4 | c6 | c8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9108</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>93.330645</td>\n",
       "      <td>79.732831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weights</td>\n",
       "      <td>4</td>\n",
       "      <td>c1 | c3 | c5 | c7 | c9</td>\n",
       "      <td>c6 | (~c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>80.391113</td>\n",
       "      <td>78.420050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weights</td>\n",
       "      <td>5</td>\n",
       "      <td>c3 | c9 | (~c0 &amp; ~c2 &amp; ~c4 &amp; ~c6 &amp; ~c8)</td>\n",
       "      <td>c0 | c2 | c4 | c6 | c8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7981</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>78.793919</td>\n",
       "      <td>77.957949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weights</td>\n",
       "      <td>6</td>\n",
       "      <td>c1 | c3 | c5 | c7 | c9</td>\n",
       "      <td>c0 | c4 | (~c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>79.902306</td>\n",
       "      <td>77.043643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weights</td>\n",
       "      <td>7</td>\n",
       "      <td>(~c0 &amp; ~c2 &amp; ~c4 &amp; ~c6 &amp; ~c8) | (~c2 &amp; ~c4 &amp; ~...</td>\n",
       "      <td>c0 | c2 | c4 | c6 | c8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4889</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>80.108166</td>\n",
       "      <td>78.326705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weights</td>\n",
       "      <td>8</td>\n",
       "      <td>c1 | c3 | c5 | c7 | c9</td>\n",
       "      <td>~c4 | (~c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4926</td>\n",
       "      <td>81.186690</td>\n",
       "      <td>76.373570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>weights</td>\n",
       "      <td>9</td>\n",
       "      <td>(~c3 &amp; ~c6) | (~c0 &amp; ~c2 &amp; ~c4 &amp; ~c6 &amp; ~c8)</td>\n",
       "      <td>c0 | c2 | c4 | c6 | c8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1968</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>79.297514</td>\n",
       "      <td>78.457548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    method  split                                        explanation  \\\n",
       "0  weights      0                             c1 | c3 | c5 | c7 | c9   \n",
       "1  weights      1                             c1 | c3 | c5 | c7 | c9   \n",
       "2  weights      2                             c1 | c3 | c5 | c7 | c9   \n",
       "3  weights      3                 c5 | (~c0 & ~c2 & ~c4 & ~c6 & ~c8)   \n",
       "4  weights      4                             c1 | c3 | c5 | c7 | c9   \n",
       "5  weights      5            c3 | c9 | (~c0 & ~c2 & ~c4 & ~c6 & ~c8)   \n",
       "6  weights      6                             c1 | c3 | c5 | c7 | c9   \n",
       "7  weights      7  (~c0 & ~c2 & ~c4 & ~c6 & ~c8) | (~c2 & ~c4 & ~...   \n",
       "8  weights      8                             c1 | c3 | c5 | c7 | c9   \n",
       "9  weights      9        (~c3 & ~c6) | (~c0 & ~c2 & ~c4 & ~c6 & ~c8)   \n",
       "\n",
       "                                     explanation_inv  model_accuracy  \\\n",
       "0                 c4 | (~c1 & ~c3 & ~c5 & ~c7 & ~c9)             1.0   \n",
       "1                        ~c1 & ~c3 & ~c5 & ~c7 & ~c9             1.0   \n",
       "2  (~c1 & ~c3 & ~c5 & ~c7 & ~c9) | (~c1 & ~c2 & ~...             1.0   \n",
       "3                             c0 | c2 | c4 | c6 | c8             1.0   \n",
       "4                 c6 | (~c1 & ~c3 & ~c5 & ~c7 & ~c9)             1.0   \n",
       "5                             c0 | c2 | c4 | c6 | c8             1.0   \n",
       "6            c0 | c4 | (~c1 & ~c3 & ~c5 & ~c7 & ~c9)             1.0   \n",
       "7                             c0 | c2 | c4 | c6 | c8             1.0   \n",
       "8                ~c4 | (~c1 & ~c3 & ~c5 & ~c7 & ~c9)             1.0   \n",
       "9                             c0 | c2 | c4 | c6 | c8             1.0   \n",
       "\n",
       "   explanation_accuracy  explanation_accuracy_inv  elapsed_time  \\\n",
       "0                1.0000                    1.0000     71.511281   \n",
       "1                1.0000                    1.0000     80.853533   \n",
       "2                1.0000                    0.8099     72.000501   \n",
       "3                0.9108                    1.0000     93.330645   \n",
       "4                1.0000                    1.0000     80.391113   \n",
       "5                0.7981                    1.0000     78.793919   \n",
       "6                1.0000                    1.0000     79.902306   \n",
       "7                0.4889                    1.0000     80.108166   \n",
       "8                1.0000                    0.4926     81.186690   \n",
       "9                0.1968                    1.0000     79.297514   \n",
       "\n",
       "   elapsed_time_inv  \n",
       "0         63.094102  \n",
       "1         76.036408  \n",
       "2         78.610895  \n",
       "3         79.732831  \n",
       "4         78.420050  \n",
       "5         77.957949  \n",
       "6         77.043643  \n",
       "7         78.326705  \n",
       "8         76.373570  \n",
       "9         78.457548  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_weights = pd.DataFrame({\n",
    "    'method': methods,\n",
    "    'split': splits,\n",
    "    'explanation': explanations,\n",
    "    'explanation_inv': explanations_inv,\n",
    "    'model_accuracy': model_accuracies,\n",
    "    'explanation_accuracy': explanation_accuracies,\n",
    "    'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "    'elapsed_time': elapsed_times,\n",
    "    'elapsed_time_inv': elapsed_times_inv,\n",
    "})\n",
    "results_weights.to_csv(os.path.join(results_dir, 'results_weights.csv'))\n",
    "results_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Psi network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_psi_nn(x_train, y_train, need_pruning, seed, device):\n",
    "    set_seed(seed)\n",
    "    x_train = x_train.to(device)\n",
    "    y_train = y_train.to(device).to(torch.float)\n",
    "    layers = [\n",
    "        torch.nn.Linear(x_train.size(1), 10),\n",
    "        torch.nn.Sigmoid(),\n",
    "        torch.nn.Linear(10, 4),\n",
    "        torch.nn.Sigmoid(),\n",
    "        torch.nn.Linear(4, 1),\n",
    "        torch.nn.Sigmoid(),\n",
    "    ]\n",
    "    model = torch.nn.Sequential(*layers).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_form = torch.nn.BCELoss()\n",
    "    model.train()\n",
    "    for epoch in range(tot_epochs):\n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_train).squeeze()\n",
    "        # Compute Loss\n",
    "        loss = loss_form(y_pred, y_train)\n",
    "\n",
    "        for module in model.children():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                loss += 0.00001 * torch.norm(module.weight, 1)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch > prune_epochs and need_pruning:\n",
    "            model = prune_equal_fanin(model, 2, validate=True, device=device)\n",
    "            need_pruning = False\n",
    "            \n",
    "        # compute accuracy\n",
    "        if epoch % 500 == 0:\n",
    "            y_pred_d = y_pred > 0.5\n",
    "            accuracy = y_pred_d.eq(y_train).sum().item() / y_train.size(0)\n",
    "            print(f'\\t Epoch {epoch}: train accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed [1/10]\n",
      "\t Epoch 0: train accuracy: 0.4924\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.7977\n",
      "\t Epoch 3000: train accuracy: 0.7977\n",
      "\t Epoch 3500: train accuracy: 0.7977\n",
      "\t Epoch 4000: train accuracy: 0.7977\n",
      "\t Model's accuracy: 0.7988\n",
      "\t Class 1 - Global explanation: \"(c7 & ~c4)\" - Accuracy: 0.5954\n",
      "\t Elapsed time 0.05112743377685547\n",
      "\t Epoch 0: train accuracy: 0.5076\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.8995\n",
      "\t Epoch 3000: train accuracy: 0.8995\n",
      "\t Epoch 3500: train accuracy: 0.8995\n",
      "\t Epoch 4000: train accuracy: 0.8995\n",
      "\t Model's accuracy: 0.8991\n",
      "\t Class 0 - Global explanation: \"(~c1 & ~c3 & ~c5 & ~c7)\" - Accuracy: 0.8991\n",
      "\t Elapsed time 0.03689980506896973\n",
      "Seed [2/10]\n",
      "\t Epoch 0: train accuracy: 0.4924\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.6993\n",
      "\t Epoch 3000: train accuracy: 0.6993\n",
      "\t Epoch 3500: train accuracy: 0.6993\n",
      "\t Epoch 4000: train accuracy: 0.6993\n",
      "\t Model's accuracy: 0.7030\n",
      "\t Class 1 - Global explanation: \"(~c4 & (c1 | c3) & (c1 | ~c8))\" - Accuracy: 0.4913\n",
      "\t Elapsed time 0.049866676330566406\n",
      "\t Epoch 0: train accuracy: 0.5076\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.7956\n",
      "\t Epoch 3000: train accuracy: 0.7956\n",
      "\t Epoch 3500: train accuracy: 0.7956\n",
      "\t Epoch 4000: train accuracy: 0.7956\n",
      "\t Model's accuracy: 0.7963\n",
      "\t Class 0 - Global explanation: \"(~c1 & (c0 | c6) & (c0 | ~c3) & (c4 | ~c5))\" - Accuracy: 0.5818\n",
      "\t Elapsed time 0.07579660415649414\n",
      "Seed [3/10]\n",
      "\t Epoch 0: train accuracy: 0.5076\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.8995\n",
      "\t Epoch 3000: train accuracy: 0.8995\n",
      "\t Epoch 3500: train accuracy: 0.8995\n",
      "\t Epoch 4000: train accuracy: 0.8995\n",
      "\t Model's accuracy: 0.9018\n",
      "\t Class 1 - Global explanation: \"(~c8 & (c1 | ~c2) & (c3 | ~c0) & (~c2 | ~c6))\" - Accuracy: 0.1956\n",
      "\t Elapsed time 0.10571432113647461\n",
      "\t Epoch 0: train accuracy: 0.4924\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.8038\n",
      "\t Epoch 3000: train accuracy: 0.8038\n",
      "\t Epoch 3500: train accuracy: 0.8038\n",
      "\t Epoch 4000: train accuracy: 0.8038\n",
      "\t Model's accuracy: 0.8098\n",
      "\t Class 0 - Global explanation: \"(~c1 & ~c9 & (c0 | ~c7))\" - Accuracy: 0.5954\n",
      "\t Elapsed time 0.04787158966064453\n",
      "Seed [4/10]\n",
      "\t Epoch 0: train accuracy: 0.5076\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.7988\n",
      "\t Epoch 3000: train accuracy: 0.7947\n",
      "\t Epoch 3500: train accuracy: 0.7947\n",
      "\t Epoch 4000: train accuracy: 0.7988\n",
      "\t Model's accuracy: 0.8010\n",
      "\t Class 1 - Global explanation: \"(c7 | c9 | (~c4 & ~c8) | (c3 & ~c0 & ~c4))\" - Accuracy: 0.3983\n",
      "\t Elapsed time 0.17752695083618164\n",
      "\t Epoch 0: train accuracy: 0.4924\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.7980\n",
      "\t Epoch 3000: train accuracy: 0.7980\n",
      "\t Epoch 3500: train accuracy: 0.7980\n",
      "\t Epoch 4000: train accuracy: 0.7980\n",
      "\t Model's accuracy: 0.8062\n",
      "\t Class 0 - Global explanation: \"(~c3 & (c2 | c4 | c8) & (c2 | c8 | ~c7))\" - Accuracy: 0.5954\n",
      "\t Elapsed time 0.07899999618530273\n",
      "Seed [5/10]\n",
      "\t Epoch 0: train accuracy: 0.4924\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.8965\n",
      "\t Epoch 3000: train accuracy: 0.8965\n",
      "\t Epoch 3500: train accuracy: 0.8965\n",
      "\t Epoch 4000: train accuracy: 0.8965\n",
      "\t Model's accuracy: 0.9020\n",
      "\t Class 1 - Global explanation: \"(~c4 & ~c8 & (c7 | ~c6) & (c9 | ~c2))\" - Accuracy: 0.4069\n",
      "\t Elapsed time 0.10024547576904297\n",
      "\t Epoch 0: train accuracy: 0.5076\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.8995\n",
      "\t Epoch 3000: train accuracy: 0.8995\n",
      "\t Epoch 3500: train accuracy: 0.8995\n",
      "\t Epoch 4000: train accuracy: 0.8995\n",
      "\t Model's accuracy: 0.9018\n",
      "\t Class 0 - Global explanation: \"((c0 & c8) | (c2 & c8) | (c0 & ~c1) | (c2 & ~c1) | (~c3 & ~c7))\" - Accuracy: 0.6964\n",
      "\t Elapsed time 0.1246652603149414\n",
      "Seed [6/10]\n",
      "\t Epoch 0: train accuracy: 0.4924\n",
      "\t Epoch 500: train accuracy: 0.6981\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.8995\n",
      "\t Epoch 3000: train accuracy: 0.8995\n",
      "\t Epoch 3500: train accuracy: 0.8995\n",
      "\t Epoch 4000: train accuracy: 0.8995\n",
      "\t Model's accuracy: 0.9018\n",
      "\t Class 1 - Global explanation: \"(~c0 & ~c2 & ~c6 & ~c8)\" - Accuracy: 0.9018\n",
      "\t Elapsed time 0.0528712272644043\n",
      "\t Epoch 0: train accuracy: 0.5076\n",
      "\t Epoch 500: train accuracy: 0.5076\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.6791\n",
      "\t Epoch 3000: train accuracy: 0.6791\n",
      "\t Epoch 3500: train accuracy: 0.6791\n",
      "\t Epoch 4000: train accuracy: 0.6791\n",
      "\t Model's accuracy: 0.6827\n",
      "\t Class 0 - Global explanation: \"(~c5 & (c4 | ~c9))\" - Accuracy: 0.5935\n",
      "\t Elapsed time 0.05884242057800293\n",
      "Seed [7/10]\n",
      "\t Epoch 0: train accuracy: 0.5076\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.7029\n",
      "\t Epoch 3000: train accuracy: 0.7884\n",
      "\t Epoch 3500: train accuracy: 0.7884\n",
      "\t Epoch 4000: train accuracy: 0.7884\n",
      "\t Model's accuracy: 0.7856\n",
      "\t Class 1 - Global explanation: \"(c5 & ~c4)\" - Accuracy: 0.5818\n",
      "\t Elapsed time 0.03690075874328613\n",
      "\t Epoch 0: train accuracy: 0.4924\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.8021\n",
      "\t Epoch 3000: train accuracy: 0.8021\n",
      "\t Epoch 3500: train accuracy: 0.9009\n",
      "\t Epoch 4000: train accuracy: 0.9009\n",
      "\t Model's accuracy: 0.9026\n",
      "\t Class 0 - Global explanation: \"(c0 | c2 | c4 | c6)\" - Accuracy: 0.9026\n",
      "\t Elapsed time 0.052129268646240234\n",
      "Seed [8/10]\n",
      "\t Epoch 0: train accuracy: 0.5076\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.8976\n",
      "\t Epoch 3000: train accuracy: 0.8976\n",
      "\t Epoch 3500: train accuracy: 0.8976\n",
      "\t Epoch 4000: train accuracy: 0.8976\n",
      "\t Model's accuracy: 0.9042\n",
      "\t Class 1 - Global explanation: \"(~c2 & ~c8 & (c1 | ~c0) & (c9 | ~c4))\" - Accuracy: 0.3912\n",
      "\t Elapsed time 0.08875703811645508\n",
      "\t Epoch 0: train accuracy: 0.4924\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.8007\n",
      "\t Epoch 3000: train accuracy: 0.8007\n",
      "\t Epoch 3500: train accuracy: 0.8007\n",
      "\t Epoch 4000: train accuracy: 0.8007\n",
      "\t Model's accuracy: 0.7986\n",
      "\t Class 0 - Global explanation: \"(c0 | c6 | (c8 & ~c7))\" - Accuracy: 0.7986\n",
      "\t Elapsed time 0.04487872123718262\n",
      "Seed [9/10]\n",
      "\t Epoch 0: train accuracy: 0.4924\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.7056\n",
      "\t Epoch 3000: train accuracy: 0.7056\n",
      "\t Epoch 3500: train accuracy: 0.7056\n",
      "\t Epoch 4000: train accuracy: 0.7056\n",
      "\t Model's accuracy: 0.7012\n",
      "\t Class 1 - Global explanation: \"(~c0 | ~c6)\" - Accuracy: 0.2988\n",
      "\t Elapsed time 0.030919313430786133\n",
      "\t Epoch 0: train accuracy: 0.5076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.9058\n",
      "\t Epoch 3000: train accuracy: 0.9058\n",
      "\t Epoch 3500: train accuracy: 0.9058\n",
      "\t Epoch 4000: train accuracy: 0.9058\n",
      "\t Model's accuracy: 0.9108\n",
      "\t Class 0 - Global explanation: \"(~c1 & ~c3 & (c6 | ~c9) & (~c7 | ~c9))\" - Accuracy: 0.5935\n",
      "\t Elapsed time 0.03590559959411621\n",
      "Seed [10/10]\n",
      "\t Epoch 0: train accuracy: 0.4924\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.4924\n",
      "\t Epoch 3000: train accuracy: 0.8995\n",
      "\t Epoch 3500: train accuracy: 0.8995\n",
      "\t Epoch 4000: train accuracy: 0.8995\n",
      "\t Model's accuracy: 0.9018\n",
      "\t Class 1 - Global explanation: \"(~c0 & ~c2 & ~c6 & ~c8)\" - Accuracy: 0.9018\n",
      "\t Elapsed time 0.04986715316772461\n",
      "\t Epoch 0: train accuracy: 0.5076\n",
      "\t Epoch 500: train accuracy: 0.9960\n",
      "\t Epoch 1000: train accuracy: 0.9960\n",
      "\t Epoch 1500: train accuracy: 0.9960\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.5076\n",
      "\t Epoch 3000: train accuracy: 0.6064\n",
      "\t Epoch 3500: train accuracy: 0.6064\n",
      "\t Epoch 4000: train accuracy: 0.8019\n",
      "\t Model's accuracy: 0.8080\n",
      "\t Class 0 - Global explanation: \"(~c1 & ~c3 & (c2 | ~c9))\" - Accuracy: 0.5935\n",
      "\t Elapsed time 0.04887032508850098\n"
     ]
    }
   ],
   "source": [
    "need_pruning = True\n",
    "method = 'psi'\n",
    "methods = []\n",
    "splits = []\n",
    "explanations = []\n",
    "explanations_inv = []\n",
    "model_accuracies = []\n",
    "explanation_accuracies = []\n",
    "explanation_accuracies_inv = []\n",
    "elapsed_times = []\n",
    "elapsed_times_inv = []\n",
    "for seed in range(n_rep):\n",
    "    print(f'Seed [{seed+1}/{n_rep}]')\n",
    "    \n",
    "    # positive class\n",
    "    target_class = 1\n",
    "    model = train_psi_nn(x_train, y_train, need_pruning, seed, device)\n",
    "    \n",
    "    y_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "    model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds > 0.5)\n",
    "    print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "    \n",
    "    start = time.time()\n",
    "    global_explanation = logic.generate_fol_explanations(model, device)[0]\n",
    "    elapsed_time = time.time() - start\n",
    "    explanation_accuracy, _ = logic.base.test_explanation(global_explanation, target_class, x_test, y_test)\n",
    "    explanation = logic.base.replace_names(global_explanation, concepts)\n",
    "    print(f'\\t Class {target_class} - Global explanation: \"{explanation}\" - Accuracy: {explanation_accuracy:.4f}')\n",
    "    print(f'\\t Elapsed time {elapsed_time}')\n",
    "        \n",
    "    # negative class\n",
    "    target_class = 0\n",
    "    model = train_psi_nn(x_train, y_train.eq(target_class), need_pruning, seed, device)\n",
    "    \n",
    "    y_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "    model_accuracy = accuracy_score(y_test.eq(target_class).cpu().detach().numpy(), y_preds > 0.5)\n",
    "    print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "    \n",
    "    start = time.time()\n",
    "    global_explanation_inv = logic.generate_fol_explanations(model, device)[0]\n",
    "    elapsed_time_inv = time.time() - start\n",
    "    explanation_accuracy_inv, _ = logic.base.test_explanation(global_explanation_inv, \n",
    "                                                              target_class, x_test, y_test)\n",
    "    explanation_inv = logic.base.replace_names(global_explanation_inv, concepts)\n",
    "    print(f'\\t Class {target_class} - Global explanation: \"{explanation_inv}\" - Accuracy: {explanation_accuracy_inv:.4f}')\n",
    "    print(f'\\t Elapsed time {elapsed_time_inv}')\n",
    "    \n",
    "    methods.append(method)\n",
    "    splits.append(seed)\n",
    "    explanations.append(explanation)\n",
    "    explanations_inv.append(explanation_inv)\n",
    "    model_accuracies.append(model_accuracy)\n",
    "    explanation_accuracies.append(explanation_accuracy)\n",
    "    explanation_accuracies_inv.append(explanation_accuracy_inv)\n",
    "    elapsed_times.append(elapsed_time)\n",
    "    elapsed_times_inv.append(elapsed_time_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>explanation_inv</th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_accuracy_inv</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>elapsed_time_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>psi</td>\n",
       "      <td>0</td>\n",
       "      <td>(c7 &amp; ~c4)</td>\n",
       "      <td>(~c1 &amp; ~c3 &amp; ~c5 &amp; ~c7)</td>\n",
       "      <td>0.8991</td>\n",
       "      <td>0.5954</td>\n",
       "      <td>0.8991</td>\n",
       "      <td>0.051127</td>\n",
       "      <td>0.036900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>psi</td>\n",
       "      <td>1</td>\n",
       "      <td>(~c4 &amp; (c1 | c3) &amp; (c1 | ~c8))</td>\n",
       "      <td>(~c1 &amp; (c0 | c6) &amp; (c0 | ~c3) &amp; (c4 | ~c5))</td>\n",
       "      <td>0.7963</td>\n",
       "      <td>0.4913</td>\n",
       "      <td>0.5818</td>\n",
       "      <td>0.049867</td>\n",
       "      <td>0.075797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>psi</td>\n",
       "      <td>2</td>\n",
       "      <td>(~c8 &amp; (c1 | ~c2) &amp; (c3 | ~c0) &amp; (~c2 | ~c6))</td>\n",
       "      <td>(~c1 &amp; ~c9 &amp; (c0 | ~c7))</td>\n",
       "      <td>0.8098</td>\n",
       "      <td>0.1956</td>\n",
       "      <td>0.5954</td>\n",
       "      <td>0.105714</td>\n",
       "      <td>0.047872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>psi</td>\n",
       "      <td>3</td>\n",
       "      <td>(c7 | c9 | (~c4 &amp; ~c8) | (c3 &amp; ~c0 &amp; ~c4))</td>\n",
       "      <td>(~c3 &amp; (c2 | c4 | c8) &amp; (c2 | c8 | ~c7))</td>\n",
       "      <td>0.8062</td>\n",
       "      <td>0.3983</td>\n",
       "      <td>0.5954</td>\n",
       "      <td>0.177527</td>\n",
       "      <td>0.079000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>psi</td>\n",
       "      <td>4</td>\n",
       "      <td>(~c4 &amp; ~c8 &amp; (c7 | ~c6) &amp; (c9 | ~c2))</td>\n",
       "      <td>((c0 &amp; c8) | (c2 &amp; c8) | (c0 &amp; ~c1) | (c2 &amp; ~c...</td>\n",
       "      <td>0.9018</td>\n",
       "      <td>0.4069</td>\n",
       "      <td>0.6964</td>\n",
       "      <td>0.100245</td>\n",
       "      <td>0.124665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>psi</td>\n",
       "      <td>5</td>\n",
       "      <td>(~c0 &amp; ~c2 &amp; ~c6 &amp; ~c8)</td>\n",
       "      <td>(~c5 &amp; (c4 | ~c9))</td>\n",
       "      <td>0.6827</td>\n",
       "      <td>0.9018</td>\n",
       "      <td>0.5935</td>\n",
       "      <td>0.052871</td>\n",
       "      <td>0.058842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>psi</td>\n",
       "      <td>6</td>\n",
       "      <td>(c5 &amp; ~c4)</td>\n",
       "      <td>(c0 | c2 | c4 | c6)</td>\n",
       "      <td>0.9026</td>\n",
       "      <td>0.5818</td>\n",
       "      <td>0.9026</td>\n",
       "      <td>0.036901</td>\n",
       "      <td>0.052129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>psi</td>\n",
       "      <td>7</td>\n",
       "      <td>(~c2 &amp; ~c8 &amp; (c1 | ~c0) &amp; (c9 | ~c4))</td>\n",
       "      <td>(c0 | c6 | (c8 &amp; ~c7))</td>\n",
       "      <td>0.7986</td>\n",
       "      <td>0.3912</td>\n",
       "      <td>0.7986</td>\n",
       "      <td>0.088757</td>\n",
       "      <td>0.044879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>psi</td>\n",
       "      <td>8</td>\n",
       "      <td>(~c0 | ~c6)</td>\n",
       "      <td>(~c1 &amp; ~c3 &amp; (c6 | ~c9) &amp; (~c7 | ~c9))</td>\n",
       "      <td>0.9108</td>\n",
       "      <td>0.2988</td>\n",
       "      <td>0.5935</td>\n",
       "      <td>0.030919</td>\n",
       "      <td>0.035906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>psi</td>\n",
       "      <td>9</td>\n",
       "      <td>(~c0 &amp; ~c2 &amp; ~c6 &amp; ~c8)</td>\n",
       "      <td>(~c1 &amp; ~c3 &amp; (c2 | ~c9))</td>\n",
       "      <td>0.8080</td>\n",
       "      <td>0.9018</td>\n",
       "      <td>0.5935</td>\n",
       "      <td>0.049867</td>\n",
       "      <td>0.048870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  split                                    explanation  \\\n",
       "0    psi      0                                     (c7 & ~c4)   \n",
       "1    psi      1                 (~c4 & (c1 | c3) & (c1 | ~c8))   \n",
       "2    psi      2  (~c8 & (c1 | ~c2) & (c3 | ~c0) & (~c2 | ~c6))   \n",
       "3    psi      3     (c7 | c9 | (~c4 & ~c8) | (c3 & ~c0 & ~c4))   \n",
       "4    psi      4          (~c4 & ~c8 & (c7 | ~c6) & (c9 | ~c2))   \n",
       "5    psi      5                        (~c0 & ~c2 & ~c6 & ~c8)   \n",
       "6    psi      6                                     (c5 & ~c4)   \n",
       "7    psi      7          (~c2 & ~c8 & (c1 | ~c0) & (c9 | ~c4))   \n",
       "8    psi      8                                    (~c0 | ~c6)   \n",
       "9    psi      9                        (~c0 & ~c2 & ~c6 & ~c8)   \n",
       "\n",
       "                                     explanation_inv  model_accuracy  \\\n",
       "0                            (~c1 & ~c3 & ~c5 & ~c7)          0.8991   \n",
       "1        (~c1 & (c0 | c6) & (c0 | ~c3) & (c4 | ~c5))          0.7963   \n",
       "2                           (~c1 & ~c9 & (c0 | ~c7))          0.8098   \n",
       "3           (~c3 & (c2 | c4 | c8) & (c2 | c8 | ~c7))          0.8062   \n",
       "4  ((c0 & c8) | (c2 & c8) | (c0 & ~c1) | (c2 & ~c...          0.9018   \n",
       "5                                 (~c5 & (c4 | ~c9))          0.6827   \n",
       "6                                (c0 | c2 | c4 | c6)          0.9026   \n",
       "7                             (c0 | c6 | (c8 & ~c7))          0.7986   \n",
       "8             (~c1 & ~c3 & (c6 | ~c9) & (~c7 | ~c9))          0.9108   \n",
       "9                           (~c1 & ~c3 & (c2 | ~c9))          0.8080   \n",
       "\n",
       "   explanation_accuracy  explanation_accuracy_inv  elapsed_time  \\\n",
       "0                0.5954                    0.8991      0.051127   \n",
       "1                0.4913                    0.5818      0.049867   \n",
       "2                0.1956                    0.5954      0.105714   \n",
       "3                0.3983                    0.5954      0.177527   \n",
       "4                0.4069                    0.6964      0.100245   \n",
       "5                0.9018                    0.5935      0.052871   \n",
       "6                0.5818                    0.9026      0.036901   \n",
       "7                0.3912                    0.7986      0.088757   \n",
       "8                0.2988                    0.5935      0.030919   \n",
       "9                0.9018                    0.5935      0.049867   \n",
       "\n",
       "   elapsed_time_inv  \n",
       "0          0.036900  \n",
       "1          0.075797  \n",
       "2          0.047872  \n",
       "3          0.079000  \n",
       "4          0.124665  \n",
       "5          0.058842  \n",
       "6          0.052129  \n",
       "7          0.044879  \n",
       "8          0.035906  \n",
       "9          0.048870  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_psi = pd.DataFrame({\n",
    "    'method': methods,\n",
    "    'split': splits,\n",
    "    'explanation': explanations,\n",
    "    'explanation_inv': explanations_inv,\n",
    "    'model_accuracy': model_accuracies,\n",
    "    'explanation_accuracy': explanation_accuracies,\n",
    "    'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "    'elapsed_time': elapsed_times,\n",
    "    'elapsed_time_inv': elapsed_times_inv,\n",
    "})\n",
    "results_psi.to_csv(os.path.join(results_dir, 'results_psi.csv'))\n",
    "results_psi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed [1/10]\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 > 0.50) | (c1 <= 0.50 & c7 > 0.50) | (c1 > 0.50)\n",
      "\t Elapsed time 0.000997781753540039\n",
      "\t Class 0 - Global explanation: (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 <= 0.50 & c8 <= 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 <= 0.50 & c8 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "Seed [2/10]\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 > 0.50) | (c1 <= 0.50 & c7 > 0.50) | (c1 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "\t Class 0 - Global explanation: (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 <= 0.50 & c6 <= 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 <= 0.50 & c6 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "Seed [3/10]\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 > 0.50) | (c1 <= 0.50 & c7 > 0.50) | (c1 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "\t Class 0 - Global explanation: (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 <= 0.50 & c8 <= 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 <= 0.50 & c8 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "Seed [4/10]\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 > 0.50) | (c1 <= 0.50 & c7 > 0.50) | (c1 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "\t Class 0 - Global explanation: (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 <= 0.50 & c6 <= 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 <= 0.50 & c6 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 > 0.50)\n",
      "\t Elapsed time 0.0009975433349609375\n",
      "Seed [5/10]\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 > 0.50) | (c1 <= 0.50 & c7 > 0.50) | (c1 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "\t Class 0 - Global explanation: (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 <= 0.50 & c6 <= 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 <= 0.50 & c6 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "Seed [6/10]\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 > 0.50) | (c1 <= 0.50 & c7 > 0.50) | (c1 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "\t Class 0 - Global explanation: (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 <= 0.50 & c6 <= 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 <= 0.50 & c6 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 > 0.50)\n",
      "\t Elapsed time 0.000993967056274414\n",
      "Seed [7/10]\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 > 0.50) | (c1 <= 0.50 & c7 > 0.50) | (c1 > 0.50)\n",
      "\t Elapsed time 0.0009980201721191406\n",
      "\t Class 0 - Global explanation: (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 <= 0.50 & c6 <= 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 <= 0.50 & c6 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "Seed [8/10]\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 > 0.50) | (c1 <= 0.50 & c7 > 0.50) | (c1 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "\t Class 0 - Global explanation: (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 <= 0.50 & c6 <= 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 <= 0.50 & c6 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "Seed [9/10]\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 > 0.50) | (c1 <= 0.50 & c7 > 0.50) | (c1 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "\t Class 0 - Global explanation: (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 <= 0.50 & c8 <= 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 <= 0.50 & c8 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "Seed [10/10]\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 > 0.50) | (c1 <= 0.50 & c7 > 0.50) | (c1 > 0.50)\n",
      "\t Elapsed time 0.0\n",
      "\t Class 0 - Global explanation: (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 <= 0.50 & c6 <= 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 <= 0.50 & c6 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 <= 0.50 & c0 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 <= 0.50 & c2 > 0.50) | (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= 0.50 & c5 <= 0.50 & c4 > 0.50)\n",
      "\t Elapsed time 0.0\n"
     ]
    }
   ],
   "source": [
    "need_pruning = False\n",
    "method = 'decision_tree'\n",
    "methods = []\n",
    "splits = []\n",
    "explanations = []\n",
    "explanations_inv = []\n",
    "model_accuracies = []\n",
    "explanation_accuracies = []\n",
    "explanation_accuracies_inv = []\n",
    "elapsed_times = []\n",
    "elapsed_times_inv = []\n",
    "for seed in range(n_rep):\n",
    "    print(f'Seed [{seed+1}/{n_rep}]')\n",
    "    \n",
    "    classifier = DecisionTreeClassifier(random_state=seed)\n",
    "    classifier.fit(x_train.cpu().detach().numpy(), y_train.cpu().detach().numpy())\n",
    "    y_preds = classifier.predict(x_test.cpu().detach().numpy())\n",
    "    model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds)\n",
    "    print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "    \n",
    "    target_class = 1\n",
    "    start = time.time()\n",
    "    explanation = tree_to_formula(classifier, concepts, target_class)\n",
    "    elapsed_time = time.time() - start\n",
    "    print(f'\\t Class {target_class} - Global explanation: {explanation}')\n",
    "    print(f'\\t Elapsed time {elapsed_time}')\n",
    "    \n",
    "    target_class = 0\n",
    "    start = time.time()\n",
    "    explanation_inv = tree_to_formula(classifier, concepts, target_class)\n",
    "    elapsed_time_inv = time.time() - start\n",
    "    print(f'\\t Class {target_class} - Global explanation: {explanation_inv}')\n",
    "    print(f'\\t Elapsed time {elapsed_time_inv}')\n",
    "    \n",
    "    methods.append(method)\n",
    "    splits.append(seed)\n",
    "    explanations.append(explanation)\n",
    "    explanations_inv.append(explanation_inv)\n",
    "    model_accuracies.append(model_accuracy)\n",
    "    explanation_accuracies.append(model_accuracy)\n",
    "    explanation_accuracies_inv.append(model_accuracy)\n",
    "    elapsed_times.append(0)\n",
    "    elapsed_times_inv.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>explanation_inv</th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_accuracy_inv</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>elapsed_time_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>1</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>2</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>3</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>4</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>5</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>6</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>7</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>8</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>9</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          method  split                                        explanation  \\\n",
       "0  decision_tree      0  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...   \n",
       "1  decision_tree      1  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...   \n",
       "2  decision_tree      2  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...   \n",
       "3  decision_tree      3  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...   \n",
       "4  decision_tree      4  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...   \n",
       "5  decision_tree      5  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...   \n",
       "6  decision_tree      6  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...   \n",
       "7  decision_tree      7  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...   \n",
       "8  decision_tree      8  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...   \n",
       "9  decision_tree      9  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...   \n",
       "\n",
       "                                     explanation_inv  model_accuracy  \\\n",
       "0  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...             1.0   \n",
       "1  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...             1.0   \n",
       "2  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...             1.0   \n",
       "3  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...             1.0   \n",
       "4  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...             1.0   \n",
       "5  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...             1.0   \n",
       "6  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...             1.0   \n",
       "7  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...             1.0   \n",
       "8  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...             1.0   \n",
       "9  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...             1.0   \n",
       "\n",
       "   explanation_accuracy  explanation_accuracy_inv  elapsed_time  \\\n",
       "0                   1.0                       1.0             0   \n",
       "1                   1.0                       1.0             0   \n",
       "2                   1.0                       1.0             0   \n",
       "3                   1.0                       1.0             0   \n",
       "4                   1.0                       1.0             0   \n",
       "5                   1.0                       1.0             0   \n",
       "6                   1.0                       1.0             0   \n",
       "7                   1.0                       1.0             0   \n",
       "8                   1.0                       1.0             0   \n",
       "9                   1.0                       1.0             0   \n",
       "\n",
       "   elapsed_time_inv  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "5                 0  \n",
       "6                 0  \n",
       "7                 0  \n",
       "8                 0  \n",
       "9                 0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_tree = pd.DataFrame({\n",
    "    'method': methods,\n",
    "    'split': splits,\n",
    "    'explanation': explanations,\n",
    "    'explanation_inv': explanations_inv,\n",
    "    'model_accuracy': model_accuracies,\n",
    "    'explanation_accuracy': explanation_accuracies,\n",
    "    'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "    'elapsed_time': elapsed_times,\n",
    "    'elapsed_time_inv': elapsed_times_inv,\n",
    "})\n",
    "results_tree.to_csv(os.path.join(results_dir, 'results_tree.csv'))\n",
    "results_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_accuracy_mean</th>\n",
       "      <th>explanation_accuracy_mean</th>\n",
       "      <th>explanation_accuracy_inv_mean</th>\n",
       "      <th>elapsed_time_mean</th>\n",
       "      <th>elapsed_time_inv_mean</th>\n",
       "      <th>model_accuracy_sem</th>\n",
       "      <th>explanation_accuracy_sem</th>\n",
       "      <th>explanation_accuracy_inv_sem</th>\n",
       "      <th>elapsed_time_sem</th>\n",
       "      <th>elapsed_time_inv_sem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pruning</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>64.124445</td>\n",
       "      <td>63.115938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.084594</td>\n",
       "      <td>4.900455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weights</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.83946</td>\n",
       "      <td>0.93025</td>\n",
       "      <td>79.737567</td>\n",
       "      <td>76.405370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088024</td>\n",
       "      <td>0.052169</td>\n",
       "      <td>1.877726</td>\n",
       "      <td>1.520392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psi</th>\n",
       "      <td>0.83159</td>\n",
       "      <td>0.51629</td>\n",
       "      <td>0.68498</td>\n",
       "      <td>0.074380</td>\n",
       "      <td>0.060486</td>\n",
       "      <td>0.022848</td>\n",
       "      <td>0.074542</td>\n",
       "      <td>0.041906</td>\n",
       "      <td>0.014140</td>\n",
       "      <td>0.008477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model_accuracy_mean  explanation_accuracy_mean  \\\n",
       "pruning              1.00000                    1.00000   \n",
       "weights              1.00000                    0.83946   \n",
       "psi                  0.83159                    0.51629   \n",
       "tree                 1.00000                    1.00000   \n",
       "\n",
       "         explanation_accuracy_inv_mean  elapsed_time_mean  \\\n",
       "pruning                        1.00000          64.124445   \n",
       "weights                        0.93025          79.737567   \n",
       "psi                            0.68498           0.074380   \n",
       "tree                           1.00000           0.000000   \n",
       "\n",
       "         elapsed_time_inv_mean  model_accuracy_sem  explanation_accuracy_sem  \\\n",
       "pruning              63.115938            0.000000                  0.000000   \n",
       "weights              76.405370            0.000000                  0.088024   \n",
       "psi                   0.060486            0.022848                  0.074542   \n",
       "tree                  0.000000            0.000000                  0.000000   \n",
       "\n",
       "         explanation_accuracy_inv_sem  elapsed_time_sem  elapsed_time_inv_sem  \n",
       "pruning                      0.000000          5.084594              4.900455  \n",
       "weights                      0.052169          1.877726              1.520392  \n",
       "psi                          0.041906          0.014140              0.008477  \n",
       "tree                         0.000000          0.000000              0.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['model_accuracy', 'explanation_accuracy', 'explanation_accuracy_inv', 'elapsed_time', 'elapsed_time_inv']\n",
    "mean_cols = [f'{c}_mean' for c in cols]\n",
    "sem_cols = [f'{c}_sem' for c in cols]\n",
    "\n",
    "# pruning\n",
    "df_mean = results_pruning[cols].mean()\n",
    "df_sem = results_pruning[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_pruning = pd.concat([df_mean, df_sem])\n",
    "summary_pruning.name = 'pruning'\n",
    "\n",
    "# # lime\n",
    "# df_mean = results_lime[cols].mean()\n",
    "# df_sem = results_lime[cols].sem()\n",
    "# df_mean.columns = mean_cols\n",
    "# df_sem.columns = sem_cols\n",
    "# summary_lime = pd.concat([df_mean, df_sem])\n",
    "# summary_lime.name = 'lime'\n",
    "\n",
    "# weights\n",
    "df_mean = results_weights[cols].mean()\n",
    "df_sem = results_weights[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_weights = pd.concat([df_mean, df_sem])\n",
    "summary_weights.name = 'weights'\n",
    "\n",
    "# psi\n",
    "df_mean = results_psi[cols].mean()\n",
    "df_sem = results_psi[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_psi = pd.concat([df_mean, df_sem])\n",
    "summary_psi.name = 'psi'\n",
    "\n",
    "# tree\n",
    "df_mean = results_tree[cols].mean()\n",
    "df_sem = results_tree[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_tree = pd.concat([df_mean, df_sem])\n",
    "summary_tree.name = 'tree'\n",
    "\n",
    "summary = pd.concat([summary_pruning, \n",
    "#                      summary_lime, \n",
    "                     summary_weights, summary_psi, summary_tree], axis=1).T\n",
    "summary.columns = mean_cols + sem_cols\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_csv(os.path.join(results_dir, 'summary.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
