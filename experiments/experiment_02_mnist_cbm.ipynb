{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sympy import simplify_logic\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.tree import _tree, export_text\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from deep_logic.utils.base import validate_network, set_seed, tree_to_formula\n",
    "from deep_logic.utils.relu_nn import get_reduced_model, prune_features\n",
    "from deep_logic.utils.psi_nn import prune_equal_fanin\n",
    "from deep_logic import logic\n",
    "\n",
    "results_dir = './results/mnist'\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "concepts = [f'c{i}' for i in range(10)]\n",
    "n_rep = 10\n",
    "tot_epochs = 4001\n",
    "prune_epochs = 2000\n",
    "concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST problem\n",
    "num_workers = 0\n",
    "batch_size = 128\n",
    "valid_size = 0.2\n",
    "# Data augmentation for train data + conversion to tensor\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "   \n",
    "])# Data augmentation for test data + conversion to tensor\n",
    "test_transforms= transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(0.5,))\n",
    "])\n",
    "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=train_transforms)\n",
    "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding indices for validation set\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "#Randomize indices\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(num_train*valid_size))\n",
    "train_index, test_index = indices[split:], indices[:split]# Making samplers for training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_index)\n",
    "valid_sampler = SubsetRandomSampler(test_index)# Creating data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # convolutional layers\n",
    "        self.conv1 = torch.nn.Conv2d(1, 8, 3, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(8, 16, 3, padding =1)\n",
    "        # linear layers\n",
    "        self.fc1 = torch.nn.Linear(784, 256)\n",
    "        self.fc2 = torch.nn.Linear(256, 128)\n",
    "        self.fc3 = torch.nn.Linear(128, 64)\n",
    "        self.fc4 = torch.nn.Linear(64, 10) \n",
    "        # dropout\n",
    "        self.dropout = torch.nn.Dropout(p=0.2)\n",
    "        # max pooling\n",
    "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # convolutional layers with ReLU and pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # flattening the image\n",
    "        x = x.view(-1, 7*7*16)\n",
    "        # linear layers\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = self.fc4(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "        \n",
    "model = Net()\n",
    "print(model)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "if os.path.isfile('./models/mnist/trained_model.pt'):\n",
    "    model.load_state_dict(torch.load('./models/mnist/trained_model.pt'))\n",
    "\n",
    "else:\n",
    "    # epochs to train for\n",
    "    epochs = 25\n",
    "    set_seed(0)\n",
    "\n",
    "    # tracks validation loss change after each epoch\n",
    "    minimum_validation_loss = np.inf \n",
    "\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr = 0.001)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(1, epochs+1):\n",
    "\n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "\n",
    "        # training steps\n",
    "        model.train()\n",
    "        for batch_index, (data, target) in enumerate(train_loader):\n",
    "            # moves tensors to GPU\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            # clears gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass\n",
    "            output = model(data)\n",
    "            # loss in batch\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass for loss gradient\n",
    "            loss.backward()\n",
    "            # update paremeters\n",
    "            optimizer.step()\n",
    "            # update training loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "\n",
    "        # validation steps\n",
    "        model.eval()\n",
    "        for batch_index, (data, target) in enumerate(valid_loader):\n",
    "            # moves tensors to GPU\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            # forward pass\n",
    "            output = model(data)\n",
    "            # loss in batch\n",
    "            loss = criterion(output, target)\n",
    "            # update validation loss\n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "\n",
    "        # average loss calculations\n",
    "        train_loss = train_loss/len(train_loader.sampler)\n",
    "        valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "\n",
    "        # Display loss statistics\n",
    "        print(f'Current Epoch: {epoch}\\nTraining Loss: {round(train_loss, 6)}\\nValidation Loss: {round(valid_loss, 6)}')\n",
    "\n",
    "        # Saving model every time validation loss decreases\n",
    "        if valid_loss <= minimum_validation_loss and epoch > 20:\n",
    "            print(f'Validation loss decreased from {round(minimum_validation_loss, 6)} to {round(valid_loss, 6)}')\n",
    "            torch.save(model.state_dict(), './models/mnist/trained_model.pt')\n",
    "            minimum_validation_loss = valid_loss\n",
    "            print('Saving New Model')\n",
    "    \n",
    "    model.load_state_dict(torch.load('./models/mnist/trained_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.472841\n",
      "Test Accuracy of 0: 98.68%\n",
      "Test Accuracy of 1: 98.89%\n",
      "Test Accuracy of 2: 100.0%\n",
      "Test Accuracy of 3: 98.63%\n",
      "Test Accuracy of 4: 100.0%\n",
      "Test Accuracy of 5: 97.06%\n",
      "Test Accuracy of 6: 98.39%\n",
      "Test Accuracy of 7: 100.0%\n",
      "Test Accuracy of 8: 100.0%\n",
      "Test Accuracy of 9: 98.8%\n",
      "Full Test Accuracy: 99.11% 783.0 out of 790.0\n"
     ]
    }
   ],
   "source": [
    "# tracking test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model.eval()\n",
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    # move tensors to GPU\n",
    "    data, target = data.cuda(), target.cuda()\n",
    "    # forward pass\n",
    "    output = model(data)\n",
    "    # batch loss\n",
    "    loss = criterion(output, target)\n",
    "    # test loss update\n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(10):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print(f'Test Loss: {round(test_loss, 6)}')\n",
    "\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print(f'Test Accuracy of {classes[i]}: {round(100*class_correct[i]/class_total[i], 2)}%')\n",
    "    else:\n",
    "        print(f'Test Accuracy of {classes[i]}s: N/A (no training examples)')\n",
    "        \n",
    "        \n",
    "print(f'Full Test Accuracy: {round(100. * np.sum(class_correct) / np.sum(class_total), 2)}% {np.sum(class_correct)} out of {np.sum(class_total)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_c_train = []\n",
    "true_c_train = []\n",
    "model.eval()\n",
    "for batch_index, (data, target) in enumerate(train_loader):\n",
    "    # moves tensors to GPU\n",
    "    data, target = data.cuda(), target.cuda()\n",
    "    # forward pass\n",
    "    output = model(data)\n",
    "    pred = torch.argmax(output, 1)\n",
    "    pred_c_train.append(pred)\n",
    "    true_c_train.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_c_train = torch.cat(pred_c_train)\n",
    "true_c_train = torch.cat(true_c_train)\n",
    "pred_c_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trainval = (true_c_train % 2 == 1).to(torch.long)\n",
    "y_trainval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47700, 10])\n",
      "torch.Size([300, 10])\n"
     ]
    }
   ],
   "source": [
    "x_trainval = OneHotEncoder(sparse=False).fit_transform(pred_c_train.cpu().detach().numpy().reshape(-1, 1))\n",
    "x_trainval = torch.FloatTensor(x_trainval)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_trainval, y_trainval, test_size=300, random_state=42)\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_c_test = []\n",
    "true_c_test = []\n",
    "model.eval()\n",
    "for batch_index, (data, target) in enumerate(test_loader):\n",
    "    # moves tensors to GPU\n",
    "    data, target = data.cuda(), target.cuda()\n",
    "    # forward pass\n",
    "    output = model(data)\n",
    "    pred = torch.argmax(output, 1)\n",
    "    pred_c_test.append(pred)\n",
    "    true_c_test.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_c_test = torch.cat(pred_c_test)\n",
    "true_c_test = torch.cat(true_c_test)\n",
    "pred_c_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = (true_c_test % 2 == 1).to(torch.long)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = OneHotEncoder(sparse=False).fit_transform(true_c_test.cpu().detach().numpy().reshape(-1, 1))\n",
    "x_test = torch.FloatTensor(x_test)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(x_train, y_train, need_pruning, seed, device, relu=False, verbose=False):\n",
    "    set_seed(seed)\n",
    "    x_train = x_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    layers = [\n",
    "        torch.nn.Linear(x_train.size(1), 100),\n",
    "        torch.nn.ReLU() if relu else torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(100, 50),\n",
    "        torch.nn.ReLU() if relu else torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(50, 30),\n",
    "        torch.nn.ReLU() if relu else torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(30, 2),\n",
    "        torch.nn.Softmax(dim=1),\n",
    "    ]\n",
    "    model = torch.nn.Sequential(*layers).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "    loss_form = torch.nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    for epoch in range(tot_epochs):\n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_train)\n",
    "        # Compute Loss\n",
    "        loss = loss_form(y_pred, y_train)\n",
    "\n",
    "        for module in model.children():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                loss += 0.001 * torch.norm(module.weight, 1)\n",
    "                loss += 0.001 * torch.norm(module.bias, 1)\n",
    "                break\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch > prune_epochs and need_pruning:\n",
    "            prune_features(model, n_classes=1, device=device)\n",
    "            need_pruning = False\n",
    "            \n",
    "        # compute accuracy\n",
    "        if epoch % 500 == 0 and verbose:\n",
    "            y_pred_d = torch.argmax(y_pred, dim=1)\n",
    "            accuracy = y_pred_d.eq(y_train).sum().item() / y_train.size(0)\n",
    "            print(f'\\t Epoch {epoch}: train accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_psi_nn(x_train, y_train, need_pruning, seed, device, verbose=False):\n",
    "    set_seed(seed)\n",
    "    x_train = x_train.to(device)\n",
    "    y_train = y_train.to(device).to(torch.float)\n",
    "    layers = [\n",
    "        torch.nn.Linear(x_train.size(1), 10),\n",
    "        torch.nn.Sigmoid(),\n",
    "        torch.nn.Linear(10, 4),\n",
    "        torch.nn.Sigmoid(),\n",
    "        torch.nn.Linear(4, 1),\n",
    "        torch.nn.Sigmoid(),\n",
    "    ]\n",
    "    model = torch.nn.Sequential(*layers).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_form = torch.nn.BCELoss()\n",
    "    model.train()\n",
    "    for epoch in range(tot_epochs):\n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_train).squeeze()\n",
    "        # Compute Loss\n",
    "        loss = loss_form(y_pred, y_train)\n",
    "\n",
    "        for module in model.children():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                loss += 0.00001 * torch.norm(module.weight, 1)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch > prune_epochs and need_pruning:\n",
    "            model = prune_equal_fanin(model, 2, validate=True, device=device)\n",
    "            need_pruning = False\n",
    "            \n",
    "        # compute accuracy\n",
    "        if epoch % 500 == 0 and verbose:\n",
    "            y_pred_d = y_pred > 0.5\n",
    "            accuracy = y_pred_d.eq(y_train).sum().item() / y_train.size(0)\n",
    "            print(f'\\t Epoch {epoch}: train accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_to_y(method, need_pruning, relu, verbose=False):\n",
    "    methods = []\n",
    "    splits = []\n",
    "    explanations = []\n",
    "    explanations_inv = []\n",
    "    model_accuracies = []\n",
    "    explanation_accuracies = []\n",
    "    explanation_accuracies_inv = []\n",
    "    elapsed_times = []\n",
    "    elapsed_times_inv = []\n",
    "    for seed in range(n_rep):\n",
    "        explanation, explanation_inv = '', ''\n",
    "        explanation_accuracy, explanation_accuracy_inv = 0, 0\n",
    "        \n",
    "        print(f'Seed [{seed+1}/{n_rep}]')\n",
    "        \n",
    "        if method == 'tree':\n",
    "            classifier = DecisionTreeClassifier(random_state=seed)\n",
    "            classifier.fit(x_train.cpu().detach().numpy(), y_train.cpu().detach().numpy())\n",
    "            y_preds = classifier.predict(x_test.cpu().detach().numpy())\n",
    "            model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds)\n",
    "\n",
    "            target_class = 1\n",
    "            start = time.time()\n",
    "            explanation = tree_to_formula(classifier, concepts, target_class)\n",
    "            elapsed_time = time.time() - start\n",
    "            explanation_accuracy = model_accuracy\n",
    "\n",
    "            target_class_inv = 0\n",
    "            start = time.time()\n",
    "            explanation_inv = tree_to_formula(classifier, concepts, target_class_inv)\n",
    "            elapsed_time_inv = time.time() - start\n",
    "            explanation_accuracy_inv = model_accuracy\n",
    "        \n",
    "        else:\n",
    "            if method == 'psi':\n",
    "                # positive class\n",
    "                target_class = 1\n",
    "                model = train_psi_nn(x_train, y_train.eq(target_class), need_pruning, seed, device, verbose)\n",
    "                y_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "                model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds>0.5)\n",
    "                \n",
    "            else:\n",
    "                model = train_nn(x_train, y_train, need_pruning, seed, device, relu, verbose)\n",
    "                y_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "                model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds.argmax(axis=1))\n",
    "\n",
    "            # positive class\n",
    "            target_class = 1\n",
    "            start = time.time()\n",
    "            if method == 'psi':\n",
    "                global_explanation = logic.generate_fol_explanations(model, device)[0]\n",
    "            else:\n",
    "                global_explanation, _, _ = logic.relu_nn.combine_local_explanations(model, \n",
    "                                                                                   x_val.to(device), \n",
    "                                                                                   y_val.to(device), \n",
    "                                                                                   topk_explanations=5,\n",
    "                                                                                   target_class=target_class,\n",
    "                                                                                   method=method, device=device)\n",
    "            elapsed_time = time.time() - start\n",
    "            \n",
    "            if global_explanation:\n",
    "                explanation_accuracy, _ = logic.base.test_explanation(global_explanation, target_class, x_test, y_test)\n",
    "                explanation = logic.base.replace_names(global_explanation, concepts)\n",
    "\n",
    "            # negative class\n",
    "            target_class_inv = 0\n",
    "            if method == 'psi':\n",
    "                model = train_psi_nn(x_train, y_train.eq(target_class_inv), need_pruning, seed, device, verbose)\n",
    "            \n",
    "            start = time.time()\n",
    "            if method == 'psi':\n",
    "                global_explanation_inv = logic.generate_fol_explanations(model, device)[0]\n",
    "            else:\n",
    "                global_explanation_inv, _, _ = logic.relu_nn.combine_local_explanations(model, \n",
    "                                                                                       x_val.to(device), \n",
    "                                                                                       y_val.to(device), \n",
    "                                                                                       topk_explanations=5,\n",
    "                                                                                       target_class=target_class_inv,\n",
    "                                                                                       method=method, device=device)\n",
    "            elapsed_time_inv = time.time() - start\n",
    "            if global_explanation_inv:\n",
    "                explanation_accuracy_inv, _ = logic.base.test_explanation(global_explanation_inv, \n",
    "                                                                          target_class_inv, x_test, y_test)\n",
    "                explanation_inv = logic.base.replace_names(global_explanation_inv, concepts)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "            print(f'\\t Class {target_class} - Global explanation: \"{explanation}\" - Accuracy: {explanation_accuracy:.4f}')\n",
    "            print(f'\\t Elapsed time {elapsed_time}')\n",
    "            print(f'\\t Class {target_class_inv} - Global explanation: \"{explanation_inv}\" - Accuracy: {explanation_accuracy_inv:.4f}')\n",
    "            print(f'\\t Elapsed time {elapsed_time_inv}')\n",
    "\n",
    "        methods.append(method)\n",
    "        splits.append(seed)\n",
    "        explanations.append(explanation)\n",
    "        explanations_inv.append(explanation_inv)\n",
    "        model_accuracies.append(model_accuracy)\n",
    "        explanation_accuracies.append(explanation_accuracy)\n",
    "        explanation_accuracies_inv.append(explanation_accuracy_inv)\n",
    "        elapsed_times.append(elapsed_time)\n",
    "        elapsed_times_inv.append(elapsed_time_inv)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'method': methods,\n",
    "        'split': splits,\n",
    "        'explanation': explanations,\n",
    "        'explanation_inv': explanations_inv,\n",
    "        'model_accuracy': model_accuracies,\n",
    "        'explanation_accuracy': explanation_accuracies,\n",
    "        'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "        'elapsed_time': elapsed_times,\n",
    "        'elapsed_time_inv': elapsed_times_inv,\n",
    "    })\n",
    "    results.to_csv(os.path.join(results_dir, f'results_{method}.csv'))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed [1/10]\n",
      "Seed [2/10]\n",
      "Seed [3/10]\n",
      "Seed [4/10]\n",
      "Seed [5/10]\n",
      "Seed [6/10]\n",
      "Seed [7/10]\n",
      "Seed [8/10]\n",
      "Seed [9/10]\n",
      "Seed [10/10]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>explanation_inv</th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_accuracy_inv</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>elapsed_time_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pruning</td>\n",
       "      <td>0</td>\n",
       "      <td>(c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9) | (c3 &amp; ~c1 &amp; ~c5...</td>\n",
       "      <td>~c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.057918</td>\n",
       "      <td>0.018052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pruning</td>\n",
       "      <td>1</td>\n",
       "      <td>(c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9) | (c3 &amp; ~c1 &amp; ~c5...</td>\n",
       "      <td>~c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.052520</td>\n",
       "      <td>0.010012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pruning</td>\n",
       "      <td>2</td>\n",
       "      <td>(c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9) | (c3 &amp; ~c1 &amp; ~c5...</td>\n",
       "      <td>~c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.046860</td>\n",
       "      <td>0.022095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pruning</td>\n",
       "      <td>3</td>\n",
       "      <td>~c0 &amp; ~c2 &amp; ~c4 &amp; ~c6 &amp; ~c8</td>\n",
       "      <td>(c0 &amp; ~c2 &amp; ~c4 &amp; ~c6 &amp; ~c8) | (c2 &amp; ~c0 &amp; ~c4...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.015610</td>\n",
       "      <td>0.068961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pruning</td>\n",
       "      <td>4</td>\n",
       "      <td>(c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9) | (c3 &amp; ~c1 &amp; ~c5...</td>\n",
       "      <td>~c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.062505</td>\n",
       "      <td>0.020091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pruning</td>\n",
       "      <td>5</td>\n",
       "      <td>~c0 &amp; ~c2 &amp; ~c4 &amp; ~c6 &amp; ~c8</td>\n",
       "      <td>(c0 &amp; ~c2 &amp; ~c4 &amp; ~c6 &amp; ~c8) | (c2 &amp; ~c0 &amp; ~c4...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.015613</td>\n",
       "      <td>0.053342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pruning</td>\n",
       "      <td>6</td>\n",
       "      <td>(c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9) | (c3 &amp; ~c1 &amp; ~c5...</td>\n",
       "      <td>~c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.049949</td>\n",
       "      <td>0.012085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pruning</td>\n",
       "      <td>7</td>\n",
       "      <td>~c0 &amp; ~c2 &amp; ~c4 &amp; ~c6 &amp; ~c8</td>\n",
       "      <td>(c0 &amp; ~c2 &amp; ~c4 &amp; ~c6 &amp; ~c8) | (c2 &amp; ~c0 &amp; ~c4...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.015622</td>\n",
       "      <td>0.046864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pruning</td>\n",
       "      <td>8</td>\n",
       "      <td>(c1 &amp; ~c0 &amp; ~c2 &amp; ~c3 &amp; ~c4 &amp; ~c5 &amp; ~c6 &amp; ~c7 ...</td>\n",
       "      <td>(c0 &amp; ~c1 &amp; ~c2 &amp; ~c3 &amp; ~c4 &amp; ~c5 &amp; ~c6 &amp; ~c7 ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.950675</td>\n",
       "      <td>0.931551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pruning</td>\n",
       "      <td>9</td>\n",
       "      <td>~c0 &amp; ~c2 &amp; ~c4 &amp; ~c6 &amp; ~c8</td>\n",
       "      <td>(c0 &amp; ~c2 &amp; ~c4 &amp; ~c6 &amp; ~c8) | (c2 &amp; ~c0 &amp; ~c4...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.018109</td>\n",
       "      <td>0.062459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    method  split                                        explanation  \\\n",
       "0  pruning      0  (c1 & ~c3 & ~c5 & ~c7 & ~c9) | (c3 & ~c1 & ~c5...   \n",
       "1  pruning      1  (c1 & ~c3 & ~c5 & ~c7 & ~c9) | (c3 & ~c1 & ~c5...   \n",
       "2  pruning      2  (c1 & ~c3 & ~c5 & ~c7 & ~c9) | (c3 & ~c1 & ~c5...   \n",
       "3  pruning      3                        ~c0 & ~c2 & ~c4 & ~c6 & ~c8   \n",
       "4  pruning      4  (c1 & ~c3 & ~c5 & ~c7 & ~c9) | (c3 & ~c1 & ~c5...   \n",
       "5  pruning      5                        ~c0 & ~c2 & ~c4 & ~c6 & ~c8   \n",
       "6  pruning      6  (c1 & ~c3 & ~c5 & ~c7 & ~c9) | (c3 & ~c1 & ~c5...   \n",
       "7  pruning      7                        ~c0 & ~c2 & ~c4 & ~c6 & ~c8   \n",
       "8  pruning      8  (c1 & ~c0 & ~c2 & ~c3 & ~c4 & ~c5 & ~c6 & ~c7 ...   \n",
       "9  pruning      9                        ~c0 & ~c2 & ~c4 & ~c6 & ~c8   \n",
       "\n",
       "                                     explanation_inv  model_accuracy  \\\n",
       "0                        ~c1 & ~c3 & ~c5 & ~c7 & ~c9             1.0   \n",
       "1                        ~c1 & ~c3 & ~c5 & ~c7 & ~c9             1.0   \n",
       "2                        ~c1 & ~c3 & ~c5 & ~c7 & ~c9             1.0   \n",
       "3  (c0 & ~c2 & ~c4 & ~c6 & ~c8) | (c2 & ~c0 & ~c4...             1.0   \n",
       "4                        ~c1 & ~c3 & ~c5 & ~c7 & ~c9             1.0   \n",
       "5  (c0 & ~c2 & ~c4 & ~c6 & ~c8) | (c2 & ~c0 & ~c4...             1.0   \n",
       "6                        ~c1 & ~c3 & ~c5 & ~c7 & ~c9             1.0   \n",
       "7  (c0 & ~c2 & ~c4 & ~c6 & ~c8) | (c2 & ~c0 & ~c4...             1.0   \n",
       "8  (c0 & ~c1 & ~c2 & ~c3 & ~c4 & ~c5 & ~c6 & ~c7 ...             1.0   \n",
       "9  (c0 & ~c2 & ~c4 & ~c6 & ~c8) | (c2 & ~c0 & ~c4...             1.0   \n",
       "\n",
       "   explanation_accuracy  explanation_accuracy_inv  elapsed_time  \\\n",
       "0                 100.0                     100.0      0.057918   \n",
       "1                 100.0                     100.0      0.052520   \n",
       "2                 100.0                     100.0      0.046860   \n",
       "3                 100.0                     100.0      0.015610   \n",
       "4                 100.0                     100.0      0.062505   \n",
       "5                 100.0                     100.0      0.015613   \n",
       "6                 100.0                     100.0      0.049949   \n",
       "7                 100.0                     100.0      0.015622   \n",
       "8                 100.0                     100.0      0.950675   \n",
       "9                 100.0                     100.0      0.018109   \n",
       "\n",
       "   elapsed_time_inv  \n",
       "0          0.018052  \n",
       "1          0.010012  \n",
       "2          0.022095  \n",
       "3          0.068961  \n",
       "4          0.020091  \n",
       "5          0.053342  \n",
       "6          0.012085  \n",
       "7          0.046864  \n",
       "8          0.931551  \n",
       "9          0.062459  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = 'pruning'\n",
    "need_pruning = True\n",
    "relu = False\n",
    "results_pruning = c_to_y(method, need_pruning, relu)\n",
    "results_pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method = 'lime'\n",
    "# need_pruning = False\n",
    "# relu = False\n",
    "# results_lime = c_to_y(method, need_pruning, relu)\n",
    "# results_lime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed [1/10]\n",
      "Seed [2/10]\n",
      "Seed [3/10]\n",
      "Seed [4/10]\n",
      "Seed [5/10]\n",
      "Seed [6/10]\n",
      "Seed [7/10]\n",
      "Seed [8/10]\n",
      "Seed [9/10]\n",
      "Seed [10/10]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>explanation_inv</th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_accuracy_inv</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>elapsed_time_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weights</td>\n",
       "      <td>0</td>\n",
       "      <td>(c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9) | (c3 &amp; ~c1 &amp; ~c5...</td>\n",
       "      <td>~c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.062486</td>\n",
       "      <td>0.022130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weights</td>\n",
       "      <td>1</td>\n",
       "      <td>(c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9) | (c3 &amp; ~c1 &amp; ~c5...</td>\n",
       "      <td>(c8 &amp; ~c2 &amp; ~c3) | (~c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.058832</td>\n",
       "      <td>0.050204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weights</td>\n",
       "      <td>2</td>\n",
       "      <td>~c0 &amp; ~c2 &amp; ~c4 &amp; ~c6 &amp; ~c8</td>\n",
       "      <td>(c0 &amp; ~c2 &amp; ~c4 &amp; ~c6 &amp; ~c8) | (c2 &amp; ~c0 &amp; ~c4...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.015621</td>\n",
       "      <td>0.069905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weights</td>\n",
       "      <td>3</td>\n",
       "      <td>(~c0 &amp; ~c5) | (c1 &amp; ~c4 &amp; ~c5 &amp; ~c8 &amp; ~c9) | (...</td>\n",
       "      <td>(c0 &amp; ~c2 &amp; ~c4 &amp; ~c6 &amp; ~c8) | (c2 &amp; ~c0 &amp; ~c4...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.54</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.131540</td>\n",
       "      <td>0.074338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weights</td>\n",
       "      <td>4</td>\n",
       "      <td>(c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9) | (c3 &amp; ~c1 &amp; ~c5...</td>\n",
       "      <td>(c2 &amp; ~c6) | (~c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.053367</td>\n",
       "      <td>0.046891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weights</td>\n",
       "      <td>5</td>\n",
       "      <td>(c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9) | (c3 &amp; ~c1 &amp; ~c5...</td>\n",
       "      <td>(c0 &amp; ~c2 &amp; ~c8) | (c6 &amp; ~c2 &amp; ~c3 &amp; ~c7 &amp; ~c8...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.069034</td>\n",
       "      <td>0.253841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weights</td>\n",
       "      <td>6</td>\n",
       "      <td>(~c1 &amp; ~c3 &amp; ~c7 &amp; ~c8) | (~c0 &amp; ~c2 &amp; ~c4 &amp; ~...</td>\n",
       "      <td>(c0 &amp; ~c2 &amp; ~c4 &amp; ~c6 &amp; ~c8) | (c2 &amp; ~c0 &amp; ~c4...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.48</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.182232</td>\n",
       "      <td>0.060256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weights</td>\n",
       "      <td>7</td>\n",
       "      <td>(c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9) | (c3 &amp; ~c1 &amp; ~c5...</td>\n",
       "      <td>~c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.062478</td>\n",
       "      <td>0.028584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weights</td>\n",
       "      <td>8</td>\n",
       "      <td>(c1 &amp; ~c3 &amp; ~c5 &amp; ~c7 &amp; ~c9) | (c3 &amp; ~c1 &amp; ~c5...</td>\n",
       "      <td>(c0 &amp; ~c5 &amp; ~c6) | (~c0 &amp; ~c1 &amp; ~c4 &amp; ~c5 &amp; ~c...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>79.81</td>\n",
       "      <td>0.062485</td>\n",
       "      <td>0.132814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>weights</td>\n",
       "      <td>9</td>\n",
       "      <td>(c5 &amp; ~c1 &amp; ~c3 &amp; ~c7 &amp; ~c9) | (~c0 &amp; ~c2 &amp; ~c...</td>\n",
       "      <td>(c0 &amp; ~c2 &amp; ~c4 &amp; ~c6 &amp; ~c8) | (c2 &amp; ~c0 &amp; ~c4...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.241896</td>\n",
       "      <td>0.060217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    method  split                                        explanation  \\\n",
       "0  weights      0  (c1 & ~c3 & ~c5 & ~c7 & ~c9) | (c3 & ~c1 & ~c5...   \n",
       "1  weights      1  (c1 & ~c3 & ~c5 & ~c7 & ~c9) | (c3 & ~c1 & ~c5...   \n",
       "2  weights      2                        ~c0 & ~c2 & ~c4 & ~c6 & ~c8   \n",
       "3  weights      3  (~c0 & ~c5) | (c1 & ~c4 & ~c5 & ~c8 & ~c9) | (...   \n",
       "4  weights      4  (c1 & ~c3 & ~c5 & ~c7 & ~c9) | (c3 & ~c1 & ~c5...   \n",
       "5  weights      5  (c1 & ~c3 & ~c5 & ~c7 & ~c9) | (c3 & ~c1 & ~c5...   \n",
       "6  weights      6  (~c1 & ~c3 & ~c7 & ~c8) | (~c0 & ~c2 & ~c4 & ~...   \n",
       "7  weights      7  (c1 & ~c3 & ~c5 & ~c7 & ~c9) | (c3 & ~c1 & ~c5...   \n",
       "8  weights      8  (c1 & ~c3 & ~c5 & ~c7 & ~c9) | (c3 & ~c1 & ~c5...   \n",
       "9  weights      9  (c5 & ~c1 & ~c3 & ~c7 & ~c9) | (~c0 & ~c2 & ~c...   \n",
       "\n",
       "                                     explanation_inv  model_accuracy  \\\n",
       "0                        ~c1 & ~c3 & ~c5 & ~c7 & ~c9             1.0   \n",
       "1   (c8 & ~c2 & ~c3) | (~c1 & ~c3 & ~c5 & ~c7 & ~c9)             1.0   \n",
       "2  (c0 & ~c2 & ~c4 & ~c6 & ~c8) | (c2 & ~c0 & ~c4...             1.0   \n",
       "3  (c0 & ~c2 & ~c4 & ~c6 & ~c8) | (c2 & ~c0 & ~c4...             1.0   \n",
       "4         (c2 & ~c6) | (~c1 & ~c3 & ~c5 & ~c7 & ~c9)             1.0   \n",
       "5  (c0 & ~c2 & ~c8) | (c6 & ~c2 & ~c3 & ~c7 & ~c8...             1.0   \n",
       "6  (c0 & ~c2 & ~c4 & ~c6 & ~c8) | (c2 & ~c0 & ~c4...             1.0   \n",
       "7                        ~c1 & ~c3 & ~c5 & ~c7 & ~c9             1.0   \n",
       "8  (c0 & ~c5 & ~c6) | (~c0 & ~c1 & ~c4 & ~c5 & ~c...             1.0   \n",
       "9  (c0 & ~c2 & ~c4 & ~c6 & ~c8) | (c2 & ~c0 & ~c4...             1.0   \n",
       "\n",
       "   explanation_accuracy  explanation_accuracy_inv  elapsed_time  \\\n",
       "0                100.00                    100.00      0.062486   \n",
       "1                100.00                    100.00      0.058832   \n",
       "2                100.00                    100.00      0.015621   \n",
       "3                 60.54                    100.00      0.131540   \n",
       "4                100.00                    100.00      0.053367   \n",
       "5                100.00                    100.00      0.069034   \n",
       "6                 60.48                    100.00      0.182232   \n",
       "7                100.00                    100.00      0.062478   \n",
       "8                100.00                     79.81      0.062485   \n",
       "9                100.00                    100.00      0.241896   \n",
       "\n",
       "   elapsed_time_inv  \n",
       "0          0.022130  \n",
       "1          0.050204  \n",
       "2          0.069905  \n",
       "3          0.074338  \n",
       "4          0.046891  \n",
       "5          0.253841  \n",
       "6          0.060256  \n",
       "7          0.028584  \n",
       "8          0.132814  \n",
       "9          0.060217  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = 'weights'\n",
    "need_pruning = False\n",
    "relu = True\n",
    "results_weights = c_to_y(method, need_pruning, relu)\n",
    "results_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Psi network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed [1/10]\n",
      "\t Epoch 0: train accuracy: 0.4925\n",
      "\t Epoch 500: train accuracy: 0.9957\n",
      "\t Epoch 1000: train accuracy: 0.9957\n",
      "\t Epoch 1500: train accuracy: 0.9957\n",
      "\t Epoch 2000: train accuracy: 0.9957\n",
      "\t Epoch 2500: train accuracy: 0.7995\n",
      "\t Epoch 3000: train accuracy: 0.7995\n",
      "\t Epoch 3500: train accuracy: 0.7995\n",
      "\t Epoch 4000: train accuracy: 0.7995\n",
      "\t Epoch 0: train accuracy: 0.5075\n",
      "\t Epoch 500: train accuracy: 0.9957\n",
      "\t Epoch 1000: train accuracy: 0.9957\n",
      "\t Epoch 1500: train accuracy: 0.9957\n",
      "\t Epoch 2000: train accuracy: 0.9957\n",
      "\t Epoch 2500: train accuracy: 0.8983\n",
      "\t Epoch 3000: train accuracy: 0.8983\n",
      "\t Epoch 3500: train accuracy: 0.8983\n",
      "\t Epoch 4000: train accuracy: 0.8983\n",
      "\t Model's accuracy: 0.7988\n",
      "\t Class 1 - Global explanation: \"(c7 & ~c4)\" - Accuracy: 59.5400\n",
      "\t Elapsed time 0.04689526557922363\n",
      "\t Class 0 - Global explanation: \"(~c1 & ~c3 & ~c5 & ~c7)\" - Accuracy: 89.9100\n",
      "\t Elapsed time 0.022124767303466797\n",
      "Seed [2/10]\n",
      "\t Epoch 0: train accuracy: 0.4925\n",
      "\t Epoch 500: train accuracy: 0.9957\n",
      "\t Epoch 1000: train accuracy: 0.9957\n",
      "\t Epoch 1500: train accuracy: 0.9957\n",
      "\t Epoch 2000: train accuracy: 0.9957\n",
      "\t Epoch 2500: train accuracy: 0.7008\n",
      "\t Epoch 3000: train accuracy: 0.7008\n",
      "\t Epoch 3500: train accuracy: 0.7008\n",
      "\t Epoch 4000: train accuracy: 0.7008\n",
      "\t Epoch 0: train accuracy: 0.5075\n",
      "\t Epoch 500: train accuracy: 0.9957\n",
      "\t Epoch 1000: train accuracy: 0.9957\n",
      "\t Epoch 1500: train accuracy: 0.9957\n",
      "\t Epoch 2000: train accuracy: 0.9957\n",
      "\t Epoch 2500: train accuracy: 0.7933\n",
      "\t Epoch 3000: train accuracy: 0.7933\n",
      "\t Epoch 3500: train accuracy: 0.7933\n",
      "\t Epoch 4000: train accuracy: 0.7933\n",
      "\t Model's accuracy: 0.7030\n",
      "\t Class 1 - Global explanation: \"(~c4 & (c1 | c3) & (c1 | ~c8))\" - Accuracy: 60.4800\n",
      "\t Elapsed time 0.03124260902404785\n",
      "\t Class 0 - Global explanation: \"(~c1 & (c0 | c6) & (c0 | ~c3) & (c4 | ~c5))\" - Accuracy: 58.1800\n",
      "\t Elapsed time 0.05343127250671387\n",
      "Seed [3/10]\n",
      "\t Epoch 0: train accuracy: 0.5075\n",
      "\t Epoch 500: train accuracy: 0.9957\n",
      "\t Epoch 1000: train accuracy: 0.9957\n",
      "\t Epoch 1500: train accuracy: 0.9957\n",
      "\t Epoch 2000: train accuracy: 0.9957\n",
      "\t Epoch 2500: train accuracy: 0.8991\n",
      "\t Epoch 3000: train accuracy: 0.8991\n",
      "\t Epoch 3500: train accuracy: 0.8991\n",
      "\t Epoch 4000: train accuracy: 0.8991\n",
      "\t Epoch 0: train accuracy: 0.4925\n",
      "\t Epoch 500: train accuracy: 0.9957\n",
      "\t Epoch 1000: train accuracy: 0.9957\n",
      "\t Epoch 1500: train accuracy: 0.9957\n",
      "\t Epoch 2000: train accuracy: 0.9957\n",
      "\t Epoch 2500: train accuracy: 0.8058\n",
      "\t Epoch 3000: train accuracy: 0.8058\n",
      "\t Epoch 3500: train accuracy: 0.8058\n",
      "\t Epoch 4000: train accuracy: 0.8058\n",
      "\t Model's accuracy: 0.9018\n",
      "\t Class 1 - Global explanation: \"(~c8 & (c1 | ~c2) & (c3 | ~c0) & (~c2 | ~c6))\" - Accuracy: 50.7400\n",
      "\t Elapsed time 0.06905221939086914\n",
      "\t Class 0 - Global explanation: \"(~c1 & ~c9 & (c0 | ~c7))\" - Accuracy: 59.5400\n",
      "\t Elapsed time 0.04689455032348633\n",
      "Seed [4/10]\n",
      "\t Epoch 0: train accuracy: 0.5075\n",
      "\t Epoch 500: train accuracy: 0.9957\n",
      "\t Epoch 1000: train accuracy: 0.9957\n",
      "\t Epoch 1500: train accuracy: 0.9957\n",
      "\t Epoch 2000: train accuracy: 0.9957\n",
      "\t Epoch 2500: train accuracy: 0.7974\n",
      "\t Epoch 3000: train accuracy: 0.7958\n",
      "\t Epoch 3500: train accuracy: 0.7958\n",
      "\t Epoch 4000: train accuracy: 0.7958\n",
      "\t Epoch 0: train accuracy: 0.4925\n",
      "\t Epoch 500: train accuracy: 0.9957\n",
      "\t Epoch 1000: train accuracy: 0.9957\n",
      "\t Epoch 1500: train accuracy: 0.9957\n",
      "\t Epoch 2000: train accuracy: 0.9957\n",
      "\t Epoch 2500: train accuracy: 0.8004\n",
      "\t Epoch 3000: train accuracy: 0.8004\n",
      "\t Epoch 3500: train accuracy: 0.8004\n",
      "\t Epoch 4000: train accuracy: 0.8004\n",
      "\t Model's accuracy: 0.7973\n",
      "\t Class 1 - Global explanation: \"(c7 | c9 | (~c4 & ~c8) | (c3 & ~c0 & ~c8))\" - Accuracy: 70.3000\n",
      "\t Elapsed time 0.1002957820892334\n",
      "\t Class 0 - Global explanation: \"(~c3 & (c2 | c4 | c8) & (c2 | c8 | ~c7))\" - Accuracy: 59.5400\n",
      "\t Elapsed time 0.06902146339416504\n",
      "Seed [5/10]\n",
      "\t Epoch 0: train accuracy: 0.4925\n",
      "\t Epoch 500: train accuracy: 0.9957\n",
      "\t Epoch 1000: train accuracy: 0.9957\n",
      "\t Epoch 1500: train accuracy: 0.9957\n",
      "\t Epoch 2000: train accuracy: 0.9957\n",
      "\t Epoch 2500: train accuracy: 0.8991\n",
      "\t Epoch 3000: train accuracy: 0.8991\n",
      "\t Epoch 3500: train accuracy: 0.8991\n",
      "\t Epoch 4000: train accuracy: 0.8991\n",
      "\t Epoch 0: train accuracy: 0.5075\n",
      "\t Epoch 500: train accuracy: 0.9957\n",
      "\t Epoch 1000: train accuracy: 0.9957\n",
      "\t Epoch 1500: train accuracy: 0.9957\n",
      "\t Epoch 2000: train accuracy: 0.9957\n",
      "\t Epoch 2500: train accuracy: 0.8991\n",
      "\t Epoch 3000: train accuracy: 0.8991\n",
      "\t Epoch 3500: train accuracy: 0.8991\n",
      "\t Epoch 4000: train accuracy: 0.8991\n",
      "\t Model's accuracy: 0.9020\n",
      "\t Class 1 - Global explanation: \"(~c4 & ~c8 & (c7 | ~c6) & (c9 | ~c2))\" - Accuracy: 61.0600\n",
      "\t Elapsed time 0.09376096725463867\n",
      "\t Class 0 - Global explanation: \"((c0 & c8) | (c2 & c8) | (c0 & ~c1) | (c2 & ~c1) | (~c3 & ~c7))\" - Accuracy: 69.6400\n",
      "\t Elapsed time 0.10032534599304199\n",
      "Seed [6/10]\n",
      "\t Epoch 0: train accuracy: 0.4925\n",
      "\t Epoch 500: train accuracy: 0.6984\n",
      "\t Epoch 1000: train accuracy: 0.9957\n",
      "\t Epoch 1500: train accuracy: 0.9957\n",
      "\t Epoch 2000: train accuracy: 0.9957\n",
      "\t Epoch 2500: train accuracy: 0.8991\n",
      "\t Epoch 3000: train accuracy: 0.8991\n",
      "\t Epoch 3500: train accuracy: 0.8991\n",
      "\t Epoch 4000: train accuracy: 0.8991\n",
      "\t Epoch 0: train accuracy: 0.5075\n",
      "\t Epoch 500: train accuracy: 0.5075\n",
      "\t Epoch 1000: train accuracy: 0.9957\n",
      "\t Epoch 1500: train accuracy: 0.9957\n",
      "\t Epoch 2000: train accuracy: 0.9957\n",
      "\t Epoch 2500: train accuracy: 0.6788\n",
      "\t Epoch 3000: train accuracy: 0.6788\n",
      "\t Epoch 3500: train accuracy: 0.6788\n",
      "\t Epoch 4000: train accuracy: 0.6788\n",
      "\t Model's accuracy: 0.9018\n",
      "\t Class 1 - Global explanation: \"(~c0 & ~c2 & ~c6 & ~c8)\" - Accuracy: 90.1800\n",
      "\t Elapsed time 0.05336904525756836\n",
      "\t Class 0 - Global explanation: \"(~c5 & (c4 | ~c9))\" - Accuracy: 59.3500\n",
      "\t Elapsed time 0.06251668930053711\n",
      "Seed [7/10]\n",
      "\t Epoch 0: train accuracy: 0.5075\n",
      "\t Epoch 500: train accuracy: 0.9957\n",
      "\t Epoch 1000: train accuracy: 0.9957\n",
      "\t Epoch 1500: train accuracy: 0.9957\n",
      "\t Epoch 2000: train accuracy: 0.9957\n",
      "\t Epoch 2500: train accuracy: 0.7036\n",
      "\t Epoch 3000: train accuracy: 0.7874\n",
      "\t Epoch 3500: train accuracy: 0.7874\n",
      "\t Epoch 4000: train accuracy: 0.7874\n",
      "\t Epoch 0: train accuracy: 0.4925\n",
      "\t Epoch 500: train accuracy: 0.9957\n",
      "\t Epoch 1000: train accuracy: 0.9957\n",
      "\t Epoch 1500: train accuracy: 0.9957\n",
      "\t Epoch 2000: train accuracy: 0.9957\n",
      "\t Epoch 2500: train accuracy: 0.7028\n",
      "\t Epoch 3000: train accuracy: 0.8989\n",
      "\t Epoch 3500: train accuracy: 0.8989\n",
      "\t Epoch 4000: train accuracy: 0.8989\n",
      "\t Model's accuracy: 0.7856\n",
      "\t Class 1 - Global explanation: \"(c5 & ~c4)\" - Accuracy: 58.1800\n",
      "\t Elapsed time 0.031243324279785156\n",
      "\t Class 0 - Global explanation: \"(c0 | c2 | c4 | c6)\" - Accuracy: 90.2600\n",
      "\t Elapsed time 0.06251239776611328\n",
      "Seed [8/10]\n",
      "\t Epoch 0: train accuracy: 0.5075\n",
      "\t Epoch 500: train accuracy: 0.9957\n",
      "\t Epoch 1000: train accuracy: 0.9957\n",
      "\t Epoch 1500: train accuracy: 0.9957\n",
      "\t Epoch 2000: train accuracy: 0.9957\n",
      "\t Epoch 2500: train accuracy: 0.8970\n",
      "\t Epoch 3000: train accuracy: 0.8970\n",
      "\t Epoch 3500: train accuracy: 0.8970\n",
      "\t Epoch 4000: train accuracy: 0.8970\n",
      "\t Epoch 0: train accuracy: 0.4925\n",
      "\t Epoch 500: train accuracy: 0.9957\n",
      "\t Epoch 1000: train accuracy: 0.9957\n",
      "\t Epoch 1500: train accuracy: 0.9957\n",
      "\t Epoch 2000: train accuracy: 0.9957\n",
      "\t Epoch 2500: train accuracy: 0.7996\n",
      "\t Epoch 3000: train accuracy: 0.7996\n",
      "\t Epoch 3500: train accuracy: 0.7996\n",
      "\t Epoch 4000: train accuracy: 0.7996\n",
      "\t Model's accuracy: 0.9042\n",
      "\t Class 1 - Global explanation: \"(~c2 & ~c8 & (c1 | ~c0) & (c9 | ~c4))\" - Accuracy: 60.5600\n",
      "\t Elapsed time 0.0690772533416748\n",
      "\t Class 0 - Global explanation: \"(c0 | c6 | (c8 & ~c7))\" - Accuracy: 79.8600\n",
      "\t Elapsed time 0.03124237060546875\n",
      "Seed [9/10]\n",
      "\t Epoch 0: train accuracy: 0.4925\n",
      "\t Epoch 500: train accuracy: 0.9957\n",
      "\t Epoch 1000: train accuracy: 0.9957\n",
      "\t Epoch 1500: train accuracy: 0.9957\n",
      "\t Epoch 2000: train accuracy: 0.9957\n",
      "\t Epoch 2500: train accuracy: 0.7028\n",
      "\t Epoch 3000: train accuracy: 0.7028\n",
      "\t Epoch 3500: train accuracy: 0.7028\n",
      "\t Epoch 4000: train accuracy: 0.7028\n",
      "\t Epoch 0: train accuracy: 0.5075\n",
      "\t Epoch 500: train accuracy: 0.9957\n",
      "\t Epoch 1000: train accuracy: 0.9957\n",
      "\t Epoch 1500: train accuracy: 0.9957\n",
      "\t Epoch 2000: train accuracy: 0.9957\n",
      "\t Epoch 2500: train accuracy: 0.9068\n",
      "\t Epoch 3000: train accuracy: 0.9068\n",
      "\t Epoch 3500: train accuracy: 0.9068\n",
      "\t Epoch 4000: train accuracy: 0.9068\n",
      "\t Model's accuracy: 0.7012\n",
      "\t Class 1 - Global explanation: \"(~c0 | ~c6)\" - Accuracy: 50.7400\n",
      "\t Elapsed time 0.015654563903808594\n",
      "\t Class 0 - Global explanation: \"(~c1 & ~c3 & (c6 | ~c9) & (~c7 | ~c9))\" - Accuracy: 59.3500\n",
      "\t Elapsed time 0.030127763748168945\n",
      "Seed [10/10]\n",
      "\t Epoch 0: train accuracy: 0.4925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 500: train accuracy: 0.9957\n",
      "\t Epoch 1000: train accuracy: 0.9957\n",
      "\t Epoch 1500: train accuracy: 0.9957\n",
      "\t Epoch 2000: train accuracy: 0.9957\n",
      "\t Epoch 2500: train accuracy: 0.4925\n",
      "\t Epoch 3000: train accuracy: 0.8991\n",
      "\t Epoch 3500: train accuracy: 0.8991\n",
      "\t Epoch 4000: train accuracy: 0.8991\n",
      "\t Epoch 0: train accuracy: 0.5075\n",
      "\t Epoch 500: train accuracy: 0.9957\n",
      "\t Epoch 1000: train accuracy: 0.9957\n",
      "\t Epoch 1500: train accuracy: 0.9957\n",
      "\t Epoch 2000: train accuracy: 0.9957\n",
      "\t Epoch 2500: train accuracy: 0.5075\n",
      "\t Epoch 3000: train accuracy: 0.6071\n",
      "\t Epoch 3500: train accuracy: 0.6071\n",
      "\t Epoch 4000: train accuracy: 0.8018\n",
      "\t Model's accuracy: 0.9018\n",
      "\t Class 1 - Global explanation: \"(~c0 & ~c2 & ~c6 & ~c8)\" - Accuracy: 90.1800\n",
      "\t Elapsed time 0.031270742416381836\n",
      "\t Class 0 - Global explanation: \"(~c1 & ~c3 & (c2 | ~c9))\" - Accuracy: 59.3500\n",
      "\t Elapsed time 0.031243085861206055\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>explanation_inv</th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_accuracy_inv</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>elapsed_time_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>psi</td>\n",
       "      <td>0</td>\n",
       "      <td>(c7 &amp; ~c4)</td>\n",
       "      <td>(~c1 &amp; ~c3 &amp; ~c5 &amp; ~c7)</td>\n",
       "      <td>0.7988</td>\n",
       "      <td>59.54</td>\n",
       "      <td>89.91</td>\n",
       "      <td>0.046895</td>\n",
       "      <td>0.022125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>psi</td>\n",
       "      <td>1</td>\n",
       "      <td>(~c4 &amp; (c1 | c3) &amp; (c1 | ~c8))</td>\n",
       "      <td>(~c1 &amp; (c0 | c6) &amp; (c0 | ~c3) &amp; (c4 | ~c5))</td>\n",
       "      <td>0.7030</td>\n",
       "      <td>60.48</td>\n",
       "      <td>58.18</td>\n",
       "      <td>0.031243</td>\n",
       "      <td>0.053431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>psi</td>\n",
       "      <td>2</td>\n",
       "      <td>(~c8 &amp; (c1 | ~c2) &amp; (c3 | ~c0) &amp; (~c2 | ~c6))</td>\n",
       "      <td>(~c1 &amp; ~c9 &amp; (c0 | ~c7))</td>\n",
       "      <td>0.9018</td>\n",
       "      <td>50.74</td>\n",
       "      <td>59.54</td>\n",
       "      <td>0.069052</td>\n",
       "      <td>0.046895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>psi</td>\n",
       "      <td>3</td>\n",
       "      <td>(c7 | c9 | (~c4 &amp; ~c8) | (c3 &amp; ~c0 &amp; ~c8))</td>\n",
       "      <td>(~c3 &amp; (c2 | c4 | c8) &amp; (c2 | c8 | ~c7))</td>\n",
       "      <td>0.7973</td>\n",
       "      <td>70.30</td>\n",
       "      <td>59.54</td>\n",
       "      <td>0.100296</td>\n",
       "      <td>0.069021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>psi</td>\n",
       "      <td>4</td>\n",
       "      <td>(~c4 &amp; ~c8 &amp; (c7 | ~c6) &amp; (c9 | ~c2))</td>\n",
       "      <td>((c0 &amp; c8) | (c2 &amp; c8) | (c0 &amp; ~c1) | (c2 &amp; ~c...</td>\n",
       "      <td>0.9020</td>\n",
       "      <td>61.06</td>\n",
       "      <td>69.64</td>\n",
       "      <td>0.093761</td>\n",
       "      <td>0.100325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>psi</td>\n",
       "      <td>5</td>\n",
       "      <td>(~c0 &amp; ~c2 &amp; ~c6 &amp; ~c8)</td>\n",
       "      <td>(~c5 &amp; (c4 | ~c9))</td>\n",
       "      <td>0.9018</td>\n",
       "      <td>90.18</td>\n",
       "      <td>59.35</td>\n",
       "      <td>0.053369</td>\n",
       "      <td>0.062517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>psi</td>\n",
       "      <td>6</td>\n",
       "      <td>(c5 &amp; ~c4)</td>\n",
       "      <td>(c0 | c2 | c4 | c6)</td>\n",
       "      <td>0.7856</td>\n",
       "      <td>58.18</td>\n",
       "      <td>90.26</td>\n",
       "      <td>0.031243</td>\n",
       "      <td>0.062512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>psi</td>\n",
       "      <td>7</td>\n",
       "      <td>(~c2 &amp; ~c8 &amp; (c1 | ~c0) &amp; (c9 | ~c4))</td>\n",
       "      <td>(c0 | c6 | (c8 &amp; ~c7))</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>60.56</td>\n",
       "      <td>79.86</td>\n",
       "      <td>0.069077</td>\n",
       "      <td>0.031242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>psi</td>\n",
       "      <td>8</td>\n",
       "      <td>(~c0 | ~c6)</td>\n",
       "      <td>(~c1 &amp; ~c3 &amp; (c6 | ~c9) &amp; (~c7 | ~c9))</td>\n",
       "      <td>0.7012</td>\n",
       "      <td>50.74</td>\n",
       "      <td>59.35</td>\n",
       "      <td>0.015655</td>\n",
       "      <td>0.030128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>psi</td>\n",
       "      <td>9</td>\n",
       "      <td>(~c0 &amp; ~c2 &amp; ~c6 &amp; ~c8)</td>\n",
       "      <td>(~c1 &amp; ~c3 &amp; (c2 | ~c9))</td>\n",
       "      <td>0.9018</td>\n",
       "      <td>90.18</td>\n",
       "      <td>59.35</td>\n",
       "      <td>0.031271</td>\n",
       "      <td>0.031243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  split                                    explanation  \\\n",
       "0    psi      0                                     (c7 & ~c4)   \n",
       "1    psi      1                 (~c4 & (c1 | c3) & (c1 | ~c8))   \n",
       "2    psi      2  (~c8 & (c1 | ~c2) & (c3 | ~c0) & (~c2 | ~c6))   \n",
       "3    psi      3     (c7 | c9 | (~c4 & ~c8) | (c3 & ~c0 & ~c8))   \n",
       "4    psi      4          (~c4 & ~c8 & (c7 | ~c6) & (c9 | ~c2))   \n",
       "5    psi      5                        (~c0 & ~c2 & ~c6 & ~c8)   \n",
       "6    psi      6                                     (c5 & ~c4)   \n",
       "7    psi      7          (~c2 & ~c8 & (c1 | ~c0) & (c9 | ~c4))   \n",
       "8    psi      8                                    (~c0 | ~c6)   \n",
       "9    psi      9                        (~c0 & ~c2 & ~c6 & ~c8)   \n",
       "\n",
       "                                     explanation_inv  model_accuracy  \\\n",
       "0                            (~c1 & ~c3 & ~c5 & ~c7)          0.7988   \n",
       "1        (~c1 & (c0 | c6) & (c0 | ~c3) & (c4 | ~c5))          0.7030   \n",
       "2                           (~c1 & ~c9 & (c0 | ~c7))          0.9018   \n",
       "3           (~c3 & (c2 | c4 | c8) & (c2 | c8 | ~c7))          0.7973   \n",
       "4  ((c0 & c8) | (c2 & c8) | (c0 & ~c1) | (c2 & ~c...          0.9020   \n",
       "5                                 (~c5 & (c4 | ~c9))          0.9018   \n",
       "6                                (c0 | c2 | c4 | c6)          0.7856   \n",
       "7                             (c0 | c6 | (c8 & ~c7))          0.9042   \n",
       "8             (~c1 & ~c3 & (c6 | ~c9) & (~c7 | ~c9))          0.7012   \n",
       "9                           (~c1 & ~c3 & (c2 | ~c9))          0.9018   \n",
       "\n",
       "   explanation_accuracy  explanation_accuracy_inv  elapsed_time  \\\n",
       "0                 59.54                     89.91      0.046895   \n",
       "1                 60.48                     58.18      0.031243   \n",
       "2                 50.74                     59.54      0.069052   \n",
       "3                 70.30                     59.54      0.100296   \n",
       "4                 61.06                     69.64      0.093761   \n",
       "5                 90.18                     59.35      0.053369   \n",
       "6                 58.18                     90.26      0.031243   \n",
       "7                 60.56                     79.86      0.069077   \n",
       "8                 50.74                     59.35      0.015655   \n",
       "9                 90.18                     59.35      0.031271   \n",
       "\n",
       "   elapsed_time_inv  \n",
       "0          0.022125  \n",
       "1          0.053431  \n",
       "2          0.046895  \n",
       "3          0.069021  \n",
       "4          0.100325  \n",
       "5          0.062517  \n",
       "6          0.062512  \n",
       "7          0.031242  \n",
       "8          0.030128  \n",
       "9          0.031243  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = 'psi'\n",
    "need_pruning = True\n",
    "relu = False\n",
    "results_psi = c_to_y(method, need_pruning, relu, verbose=False)\n",
    "results_psi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed [1/10]\n",
      "Seed [2/10]\n",
      "Seed [3/10]\n",
      "Seed [4/10]\n",
      "Seed [5/10]\n",
      "Seed [6/10]\n",
      "Seed [7/10]\n",
      "Seed [8/10]\n",
      "Seed [9/10]\n",
      "Seed [10/10]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>explanation_inv</th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_accuracy_inv</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>elapsed_time_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tree</td>\n",
       "      <td>0</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tree</td>\n",
       "      <td>6</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tree</td>\n",
       "      <td>7</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tree</td>\n",
       "      <td>8</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tree</td>\n",
       "      <td>9</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>(c1 &lt;= 0.50 &amp; c7 &lt;= 0.50 &amp; c3 &lt;= 0.50 &amp; c9 &lt;= ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  split                                        explanation  \\\n",
       "0   tree      0  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...   \n",
       "1   tree      1  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...   \n",
       "2   tree      2  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...   \n",
       "3   tree      3  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...   \n",
       "4   tree      4  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...   \n",
       "5   tree      5  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...   \n",
       "6   tree      6  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...   \n",
       "7   tree      7  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...   \n",
       "8   tree      8  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...   \n",
       "9   tree      9  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...   \n",
       "\n",
       "                                     explanation_inv  model_accuracy  \\\n",
       "0  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...             1.0   \n",
       "1  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...             1.0   \n",
       "2  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...             1.0   \n",
       "3  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...             1.0   \n",
       "4  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...             1.0   \n",
       "5  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...             1.0   \n",
       "6  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...             1.0   \n",
       "7  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...             1.0   \n",
       "8  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...             1.0   \n",
       "9  (c1 <= 0.50 & c7 <= 0.50 & c3 <= 0.50 & c9 <= ...             1.0   \n",
       "\n",
       "   explanation_accuracy  explanation_accuracy_inv  elapsed_time  \\\n",
       "0                   1.0                       1.0      0.000000   \n",
       "1                   1.0                       1.0      0.000000   \n",
       "2                   1.0                       1.0      0.000000   \n",
       "3                   1.0                       1.0      0.000000   \n",
       "4                   1.0                       1.0      0.000000   \n",
       "5                   1.0                       1.0      0.000000   \n",
       "6                   1.0                       1.0      0.002009   \n",
       "7                   1.0                       1.0      0.000000   \n",
       "8                   1.0                       1.0      0.000000   \n",
       "9                   1.0                       1.0      0.000000   \n",
       "\n",
       "   elapsed_time_inv  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  \n",
       "5               0.0  \n",
       "6               0.0  \n",
       "7               0.0  \n",
       "8               0.0  \n",
       "9               0.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = 'tree'\n",
    "need_pruning = False\n",
    "relu = False\n",
    "results_tree = c_to_y(method, need_pruning, relu)\n",
    "results_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_accuracy_mean</th>\n",
       "      <th>explanation_accuracy_mean</th>\n",
       "      <th>explanation_accuracy_inv_mean</th>\n",
       "      <th>elapsed_time_mean</th>\n",
       "      <th>elapsed_time_inv_mean</th>\n",
       "      <th>model_accuracy_sem</th>\n",
       "      <th>explanation_accuracy_sem</th>\n",
       "      <th>explanation_accuracy_inv_sem</th>\n",
       "      <th>elapsed_time_sem</th>\n",
       "      <th>elapsed_time_inv_sem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pruning</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.128538</td>\n",
       "      <td>0.124551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091550</td>\n",
       "      <td>0.089927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weights</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>92.102</td>\n",
       "      <td>97.981</td>\n",
       "      <td>0.093997</td>\n",
       "      <td>0.079918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.265335</td>\n",
       "      <td>2.019000</td>\n",
       "      <td>0.022036</td>\n",
       "      <td>0.021577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psi</th>\n",
       "      <td>0.82975</td>\n",
       "      <td>65.196</td>\n",
       "      <td>68.498</td>\n",
       "      <td>0.054186</td>\n",
       "      <td>0.050944</td>\n",
       "      <td>0.026434</td>\n",
       "      <td>4.514738</td>\n",
       "      <td>4.190555</td>\n",
       "      <td>0.008976</td>\n",
       "      <td>0.007525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model_accuracy_mean  explanation_accuracy_mean  \\\n",
       "pruning              1.00000                    100.000   \n",
       "weights              1.00000                     92.102   \n",
       "psi                  0.82975                     65.196   \n",
       "tree                 1.00000                      1.000   \n",
       "\n",
       "         explanation_accuracy_inv_mean  elapsed_time_mean  \\\n",
       "pruning                        100.000           0.128538   \n",
       "weights                         97.981           0.093997   \n",
       "psi                             68.498           0.054186   \n",
       "tree                             1.000           0.000201   \n",
       "\n",
       "         elapsed_time_inv_mean  model_accuracy_sem  explanation_accuracy_sem  \\\n",
       "pruning               0.124551            0.000000                  0.000000   \n",
       "weights               0.079918            0.000000                  5.265335   \n",
       "psi                   0.050944            0.026434                  4.514738   \n",
       "tree                  0.000000            0.000000                  0.000000   \n",
       "\n",
       "         explanation_accuracy_inv_sem  elapsed_time_sem  elapsed_time_inv_sem  \n",
       "pruning                      0.000000          0.091550              0.089927  \n",
       "weights                      2.019000          0.022036              0.021577  \n",
       "psi                          4.190555          0.008976              0.007525  \n",
       "tree                         0.000000          0.000201              0.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['model_accuracy', 'explanation_accuracy', 'explanation_accuracy_inv', 'elapsed_time', 'elapsed_time_inv']\n",
    "mean_cols = [f'{c}_mean' for c in cols]\n",
    "sem_cols = [f'{c}_sem' for c in cols]\n",
    "\n",
    "# pruning\n",
    "df_mean = results_pruning[cols].mean()\n",
    "df_sem = results_pruning[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_pruning = pd.concat([df_mean, df_sem])\n",
    "summary_pruning.name = 'pruning'\n",
    "\n",
    "# # lime\n",
    "# df_mean = results_lime[cols].mean()\n",
    "# df_sem = results_lime[cols].sem()\n",
    "# df_mean.columns = mean_cols\n",
    "# df_sem.columns = sem_cols\n",
    "# summary_lime = pd.concat([df_mean, df_sem])\n",
    "# summary_lime.name = 'lime'\n",
    "\n",
    "# weights\n",
    "df_mean = results_weights[cols].mean()\n",
    "df_sem = results_weights[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_weights = pd.concat([df_mean, df_sem])\n",
    "summary_weights.name = 'weights'\n",
    "\n",
    "# psi\n",
    "df_mean = results_psi[cols].mean()\n",
    "df_sem = results_psi[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_psi = pd.concat([df_mean, df_sem])\n",
    "summary_psi.name = 'psi'\n",
    "\n",
    "# tree\n",
    "df_mean = results_tree[cols].mean()\n",
    "df_sem = results_tree[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_tree = pd.concat([df_mean, df_sem])\n",
    "summary_tree.name = 'tree'\n",
    "\n",
    "summary = pd.concat([summary_pruning, \n",
    "#                      summary_lime, \n",
    "                     summary_weights, summary_psi, summary_tree], axis=1).T\n",
    "summary.columns = mean_cols + sem_cols\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_csv(os.path.join(results_dir, 'summary.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
