{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\gabri/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "'../data/MNIST_EVEN_ODD/'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import deep_logic as dl\n",
    "from deep_logic.models.relu_nn import XReluNN\n",
    "from deep_logic.models.psi_nn import PsiNetwork\n",
    "from deep_logic.models.tree import XDecisionTreeClassifier\n",
    "from deep_logic.models.brl import XBRLClassifier\n",
    "from deep_logic.models.logistic_regression import XLogisticRegressionClassifier\n",
    "from deep_logic.utils.base import set_seed, ClassifierNotTrainedError, IncompatibleClassifierError\n",
    "from deep_logic.utils.metrics import Accuracy\n",
    "from deep_logic.models.general_nn import XGeneralNN\n",
    "from deep_logic.utils.datasets import ConceptToTaskDataset\n",
    "from deep_logic.utils.data import get_splits_train_val_test\n",
    "from deep_logic.logic.base import test_explanation\n",
    "from data import MNIST\n",
    "from experiments.MNIST.concept_extractor_mnist import concept_extractor_mnist\n",
    "\n",
    "results_dir = 'results/mnist'\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "dataset_root = \"../data/MNIST_EVEN_ODD/\"\n",
    "dataset_root"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define loss, metrics and saved metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "metric = Accuracy()\n",
    "method_list = ['General', 'Psi', 'LogisticRegression', 'BRL', 'DTree', 'Relu']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading MNIST data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts already extracted\n",
      "Concept names ['Zero' 'One' 'Two' 'Three' 'Four' 'Five' 'Six' 'Seven' 'Eight' 'Nine']\n",
      "Number of features 10\n",
      "Class names ['Even', 'Odd']\n",
      "Number of classes 2\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(os.path.join(dataset_root, f\"{MNIST}_predictions.npy\")):\n",
    "    concept_extractor_mnist(dataset_root)\n",
    "else:\n",
    "    print(\"Concepts already extracted\")\n",
    "dataset = ConceptToTaskDataset(dataset_root, dataset_name=MNIST, predictions=True)\n",
    "concept_names = dataset.attribute_names\n",
    "print(\"Concept names\", concept_names)\n",
    "n_features = dataset.n_attributes\n",
    "print(\"Number of features\", n_features)\n",
    "class_names = dataset.classes\n",
    "print(\"Class names\", class_names)\n",
    "n_classes = dataset.n_classes\n",
    "print(\"Number of classes\", n_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "l_r = 1e-3\n",
    "lr_scheduler = False\n",
    "top_k_explanations = 1\n",
    "simplify = True\n",
    "seeds = [*range(10)]\n",
    "print(\"Seeds\", seeds)\n",
    "device = torch.device(\"cpu\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device\", device)\n",
    "\n",
    "for method in method_list:\n",
    "\n",
    "    methods = []\n",
    "    splits = []\n",
    "    explanations = []\n",
    "    model_accuracies = []\n",
    "    explanation_accuracies = []\n",
    "    elapsed_times = []\n",
    "    explanation_fidelities = []\n",
    "    explanation_complexities = []\n",
    "\n",
    "    for seed in seeds:\n",
    "        set_seed(seed)\n",
    "        name = os.path.join(results_dir, f\"{method}_{seed}\")\n",
    "\n",
    "        train_data, val_data, test_data = get_splits_train_val_test(dataset, load=False)\n",
    "        x_val = torch.tensor(dataset.attributes[val_data.indices])\n",
    "        y_val = torch.tensor(dataset.targets[val_data.indices])\n",
    "        x_test = torch.tensor(dataset.attributes[test_data.indices])\n",
    "        y_test = torch.tensor(dataset.targets[test_data.indices])\n",
    "        print(train_data.indices)\n",
    "\n",
    "        # Setting device\n",
    "        print(f\"Training {name} Classifier...\")\n",
    "\n",
    "        if method == 'BRL':\n",
    "            model = XBRLClassifier(name=name, n_classes=n_classes, n_features=n_features,\n",
    "                                   feature_names=concept_names, class_names=dataset.classes, discretize=True)\n",
    "            try:\n",
    "                model.load(device)\n",
    "                print(f\"Model {name} already trained\")\n",
    "            except (ClassifierNotTrainedError, IncompatibleClassifierError):\n",
    "                results = model.fit(val_data, metric=metric, save=True, verbose=False)\n",
    "            accuracy = model.evaluate(test_data, metric=metric)\n",
    "            print(\"Test model accuracy\", accuracy)\n",
    "            formulas, times, exp_accuracies, exp_complexities = [], [], [], []\n",
    "            for i, class_to_explain in enumerate(dataset.classes):\n",
    "                formula, elapsed_time = model.get_global_explanation(i, concept_names,\n",
    "                                                                     return_time=True)\n",
    "                exp_accuracy = accuracy\n",
    "                explanation_complexity = dl.logic.complexity(formula)\n",
    "                formulas.append(formula), times.append(elapsed_time)\n",
    "                exp_accuracies.append(exp_accuracy), exp_complexities.append(explanation_complexity)\n",
    "                print(f\"{class_to_explain} <-> {formula}\")\n",
    "                print(\"Elapsed time\", elapsed_time)\n",
    "                print(\"Explanation accuracy\", exp_accuracy)\n",
    "                print(\"Explanation complexity\", explanation_complexity)\n",
    "\n",
    "        elif method == 'DTree':\n",
    "            model = XDecisionTreeClassifier(name=name, n_classes=n_classes, n_features=n_features)\n",
    "            try:\n",
    "                model.load(device)\n",
    "                print(f\"Model {name} already trained\")\n",
    "            except (ClassifierNotTrainedError, IncompatibleClassifierError):\n",
    "                results = model.fit(train_data, val_data, metric=metric, save=True)\n",
    "            accuracy = model.evaluate(test_data, metric=metric)\n",
    "            print(\"Test model accuracy\", accuracy)\n",
    "            formulas, times, exp_accuracies, exp_complexities = [], [], [], []\n",
    "            for i, class_to_explain in enumerate(dataset.classes):\n",
    "                formula, elapsed_time = model.get_global_explanation(i, concept_names,\n",
    "                                                                     return_time=True)\n",
    "                exp_accuracy = accuracy\n",
    "                explanation_complexity = dl.logic.complexity(formula)\n",
    "                formulas.append(formula), times.append(elapsed_time)\n",
    "                exp_accuracies.append(exp_accuracy), exp_complexities.append(explanation_complexity)\n",
    "                print(f\"{class_to_explain} <-> {formula}\")\n",
    "                print(\"Elapsed time\", elapsed_time)\n",
    "                print(\"Explanation accuracy\", exp_accuracy)\n",
    "                print(\"Explanation complexity\", explanation_complexity)\n",
    "\n",
    "        elif method == 'Psi':\n",
    "            # Network structures\n",
    "            l1_weight = 1e-2\n",
    "            print(\"l1 weight\", l1_weight)\n",
    "            hidden_neurons = []\n",
    "            fan_in = 5\n",
    "            lr_psi = 1e-3\n",
    "            model = PsiNetwork(n_classes, n_features, hidden_neurons, loss,\n",
    "                               l1_weight, name=name, fan_in=fan_in)\n",
    "            try:\n",
    "                model.load(device)\n",
    "                print(f\"Model {name} already trained\")\n",
    "            except (ClassifierNotTrainedError, IncompatibleClassifierError):\n",
    "                results = model.fit(train_data, val_data, epochs=epochs, l_r=lr_psi, verbose=True,\n",
    "                                    metric=metric, lr_scheduler=lr_scheduler, device=device, save=True)\n",
    "            accuracy = model.evaluate(test_data, metric=metric)\n",
    "            print(\"Test model accuracy\", accuracy)\n",
    "            formulas, times, exp_accuracies, exp_complexities = [], [], [], []\n",
    "            for i, class_to_explain in enumerate(dataset.classes):\n",
    "                formula, elapsed_time = model.get_global_explanation(i, concept_names,\n",
    "                                                                     simplify=simplify, return_time=True)\n",
    "                exp_accuracy, _ = test_explanation(formula, i, x_test, y_test,\n",
    "                                                   metric=metric, concept_names=concept_names)\n",
    "                explanation_complexity = dl.logic.complexity(formula)\n",
    "                formulas.append(formula), times.append(elapsed_time), exp_accuracies.append(exp_accuracy)\n",
    "                exp_complexities.append(explanation_complexity)\n",
    "                print(f\"{class_to_explain} <-> {formula}\")\n",
    "                print(\"Elapsed time\", elapsed_time)\n",
    "                print(\"Explanation accuracy\", exp_accuracy)\n",
    "                print(\"Explanation complexity\", explanation_complexity)\n",
    "\n",
    "        elif method == 'Relu':\n",
    "            # Network structures\n",
    "            l1_weight = 1e-2\n",
    "            hidden_neurons = [100, 50, 30]\n",
    "            model = XReluNN(n_classes=1, n_features=n_features, name=name,\n",
    "                            hidden_neurons=hidden_neurons, loss=torch.nn.BCEWithLogitsLoss(), l1_weight=l1_weight)\n",
    "            try:\n",
    "                model.load(device)\n",
    "                print(f\"Model {name} already trained\")\n",
    "            except (ClassifierNotTrainedError, IncompatibleClassifierError):\n",
    "                results = model.fit(train_data, val_data, epochs=epochs, l_r=l_r, verbose=True,\n",
    "                                    metric=metric, lr_scheduler=lr_scheduler, device=device, save=True)\n",
    "            accuracy = model.evaluate(test_data, metric=metric)\n",
    "            print(\"Test model accuracy\", accuracy)\n",
    "            formulas, times, exp_accuracies, exp_complexities = [], [], [], []\n",
    "            for i, class_to_explain in enumerate(dataset.classes):\n",
    "                formula, elapsed_time = model.get_global_explanation(x_val, y_val, i,\n",
    "                                                                     topk_explanations=top_k_explanations,\n",
    "                                                                     concept_names=concept_names,\n",
    "                                                                     simplify=simplify, return_time=True)\n",
    "                exp_accuracy, _ = test_explanation(formula, i, x_test, y_test,\n",
    "                                                   metric=metric, concept_names=concept_names)\n",
    "                explanation_complexity = dl.logic.complexity(formula)\n",
    "                formulas.append(formula), times.append(elapsed_time), exp_accuracies.append(exp_accuracy)\n",
    "                exp_complexities.append(explanation_complexity)\n",
    "                print(f\"{class_to_explain} <-> {formula}\")\n",
    "                print(\"Elapsed time\", elapsed_time)\n",
    "                print(\"Explanation accuracy\", exp_accuracy)\n",
    "                print(\"Explanation complexity\", explanation_complexity)\n",
    "\n",
    "        elif method == 'General':\n",
    "            # Network structures\n",
    "            l1_weight = 1e0\n",
    "            fan_in = None\n",
    "            hidden_neurons = [100, 50, 30]\n",
    "            model = XGeneralNN(n_classes=2, n_features=n_features, hidden_neurons=hidden_neurons,\n",
    "                               loss=torch.nn.BCEWithLogitsLoss(), name=name, l1_weight=l1_weight, fan_in=fan_in)\n",
    "            try:\n",
    "                model.load(device)\n",
    "                print(f\"Model {name} already trained\")\n",
    "            except (ClassifierNotTrainedError, IncompatibleClassifierError):\n",
    "                results = model.fit(train_data, val_data, epochs=epochs, l_r=l_r, metric=metric,\n",
    "                                    lr_scheduler=lr_scheduler, device=device, save=True, verbose=True)\n",
    "            accuracy = model.evaluate(test_data, metric=metric)\n",
    "            print(\"Test model accuracy\", accuracy)\n",
    "            formulas, times, exp_accuracies, exp_complexities = [], [], [], []\n",
    "            for i, class_to_explain in enumerate(dataset.classes):\n",
    "                formula, elapsed_time = model.get_global_explanation(x_val, y_val, i, simplify=simplify,\n",
    "                                                                     topk_explanations=top_k_explanations,\n",
    "                                                                     concept_names=concept_names, return_time=True)\n",
    "                exp_accuracy, _ = test_explanation(formula, i, x_test, y_test,\n",
    "                                                   metric=metric, concept_names=concept_names)\n",
    "                explanation_complexity = dl.logic.complexity(formula)\n",
    "                formulas.append(formula), times.append(elapsed_time), exp_accuracies.append(exp_accuracy)\n",
    "                exp_complexities.append(explanation_complexity)\n",
    "                print(f\"{class_to_explain} <-> {formula}\")\n",
    "                print(\"Elapsed time\", elapsed_time)\n",
    "                print(\"Explanation accuracy\", exp_accuracy)\n",
    "                print(\"Explanation complexity\", explanation_complexity)\n",
    "\n",
    "        elif method == 'LogisticRegression':\n",
    "            l_r_lr = 1e-1\n",
    "            set_seed(seed)\n",
    "            model = XLogisticRegressionClassifier(name=name, n_classes=1, n_features=n_features,\n",
    "                                                  loss=torch.nn.BCEWithLogitsLoss())\n",
    "            try:\n",
    "                model.load(device)\n",
    "                print(f\"Model {name} already trained\")\n",
    "            except (ClassifierNotTrainedError, IncompatibleClassifierError):\n",
    "                results = model.fit(train_data, val_data, epochs=epochs, l_r=l_r_lr, metric=metric,\n",
    "                                    lr_scheduler=lr_scheduler, device=device, save=True, verbose=True)\n",
    "            accuracy = model.evaluate(test_data, metric=metric)\n",
    "            print(\"Test model accuracy\", accuracy)\n",
    "            formulas, times, exp_accuracies, exp_complexities = [\"\"], [0], [0], [0]\n",
    "        else:\n",
    "            raise NotImplementedError(f\"{method} not implemented\")\n",
    "\n",
    "        methods.append(method)\n",
    "        splits.append(seed)\n",
    "        explanations.append(formulas[0])\n",
    "        model_accuracies.append(accuracy)\n",
    "        explanation_accuracies.append(np.mean(exp_accuracies))\n",
    "        elapsed_times.append(np.mean(times))\n",
    "        explanation_complexities.append(np.mean(exp_complexities))\n",
    "\n",
    "    explanation_consistency = dl.logic.formula_consistency(explanations)\n",
    "    print(f'Consistency of explanations: {explanation_consistency:.4f}')\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        'method': methods,\n",
    "        'split': splits,\n",
    "        'explanation': explanations,\n",
    "        'model_accuracy': model_accuracies,\n",
    "        'explanation_accuracy': explanation_accuracies,\n",
    "        'explanation_complexity': explanation_complexities,\n",
    "        'explanation_consistency': explanation_consistency,\n",
    "        'elapsed_time': elapsed_times,\n",
    "    })\n",
    "    results.to_csv(os.path.join(results_dir, f'results_{method}.csv'))\n",
    "    print(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Summary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    model_accuracy_mean  explanation_accuracy_mean  \\\n",
      "General                       99.797500                  99.662083   \n",
      "Psi                           99.810000                  76.030000   \n",
      "LogisticRegression            99.835833                   0.000000   \n",
      "BRL                           99.734167                  99.734167   \n",
      "DTree                         99.995833                  99.995833   \n",
      "Relu                          99.782500                  95.170000   \n",
      "\n",
      "                    explanation_complexity_mean  elapsed_time_mean  \\\n",
      "General                                   18.50          11.158586   \n",
      "Psi                                       19.60           0.134629   \n",
      "LogisticRegression                         0.00           0.000000   \n",
      "BRL                                       22.95           0.225282   \n",
      "DTree                                    639.95           0.001230   \n",
      "Relu                                      44.05          21.510664   \n",
      "\n",
      "                    explanation_consistency_mean  model_accuracy_sem  \\\n",
      "General                                 0.550000            0.010690   \n",
      "Psi                                     0.500000            0.005666   \n",
      "LogisticRegression                      1.000000            0.011253   \n",
      "BRL                                     0.820000            0.013858   \n",
      "DTree                                   0.492952            0.002561   \n",
      "Relu                                    1.000000            0.010719   \n",
      "\n",
      "                    explanation_accuracy_sem  explanation_complexity_sem  \\\n",
      "General                             0.010891                    3.500000   \n",
      "Psi                                 0.621260                    0.788106   \n",
      "LogisticRegression                  0.000000                    0.000000   \n",
      "BRL                                 0.013858                    2.983706   \n",
      "DTree                               0.002561                    6.169571   \n",
      "Relu                                2.351517                    2.973447   \n",
      "\n",
      "                    elapsed_time_sem  explanation_consistency_sem  \n",
      "General                     0.176911                 3.700743e-17  \n",
      "Psi                         0.011121                 0.000000e+00  \n",
      "LogisticRegression          0.000000                 0.000000e+00  \n",
      "BRL                         0.092766                 3.700743e-17  \n",
      "DTree                       0.000059                 0.000000e+00  \n",
      "Relu                        1.155729                 0.000000e+00  \n"
     ]
    }
   ],
   "source": [
    "cols = ['model_accuracy', 'explanation_accuracy', 'explanation_complexity', 'elapsed_time',\n",
    "        'explanation_consistency']\n",
    "mean_cols = [f'{c}_mean' for c in cols]\n",
    "sem_cols = [f'{c}_sem' for c in cols]\n",
    "\n",
    "results = {}\n",
    "summaries = {}\n",
    "for method in method_list:\n",
    "    results[method] = pd.read_csv(os.path.join(results_dir, f\"results_{method}.csv\"))\n",
    "    df_mean = results[method][cols].mean()\n",
    "    df_sem = results[method][cols].sem()\n",
    "    df_mean.columns = mean_cols\n",
    "    df_sem.columns = sem_cols\n",
    "    summaries[method] = pd.concat([df_mean, df_sem])\n",
    "    summaries[method].name = method\n",
    "\n",
    "results = pd.concat([results[method] for method in method_list], axis=1).T\n",
    "results.to_csv(os.path.join(results_dir, f'results.csv'))\n",
    "\n",
    "summary = pd.concat([summaries[method] for method in method_list], axis=1).T\n",
    "summary.columns = mean_cols + sem_cols\n",
    "summary.to_csv(os.path.join(results_dir, 'summary.csv'))\n",
    "print(summary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}