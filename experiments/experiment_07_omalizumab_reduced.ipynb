{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sympy import simplify_logic\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.tree import _tree, export_text\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from deep_logic.utils.base import validate_network, set_seed, tree_to_formula\n",
    "from deep_logic.utils.relu_nn import get_reduced_model, prune_features\n",
    "from deep_logic.utils.psi_nn import prune_equal_fanin\n",
    "from deep_logic import logic\n",
    "\n",
    "results_dir = 'results/omalizumab'\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "seed = 42\n",
    "n_rep = 10\n",
    "tot_epochs = 6001\n",
    "prune_epochs = 3001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.32000</td>\n",
       "      <td>6.941536</td>\n",
       "      <td>6.590419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.232978</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.32000</td>\n",
       "      <td>7.279548</td>\n",
       "      <td>6.476784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.200609</td>\n",
       "      <td>3.32000</td>\n",
       "      <td>7.741600</td>\n",
       "      <td>4.643134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.32000</td>\n",
       "      <td>7.276600</td>\n",
       "      <td>5.953452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.32000</td>\n",
       "      <td>7.224628</td>\n",
       "      <td>6.555227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.32000</td>\n",
       "      <td>7.660182</td>\n",
       "      <td>6.128603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.700430</td>\n",
       "      <td>3.45131</td>\n",
       "      <td>7.809826</td>\n",
       "      <td>6.153968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.32000</td>\n",
       "      <td>7.580588</td>\n",
       "      <td>6.134398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>4.174319</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.32000</td>\n",
       "      <td>7.016004</td>\n",
       "      <td>7.124143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>3.699251</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.32000</td>\n",
       "      <td>7.568044</td>\n",
       "      <td>6.236546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1        2         3         4\n",
       "0   3.320000  3.320000  3.32000  6.941536  6.590419\n",
       "1   4.232978  3.320000  3.32000  7.279548  6.476784\n",
       "2   3.320000  4.200609  3.32000  7.741600  4.643134\n",
       "3   3.320000  3.320000  3.32000  7.276600  5.953452\n",
       "4   3.320000  3.320000  3.32000  7.224628  6.555227\n",
       "..       ...       ...      ...       ...       ...\n",
       "56  3.320000  3.320000  3.32000  7.660182  6.128603\n",
       "57  3.320000  3.700430  3.45131  7.809826  6.153968\n",
       "58  3.320000  3.320000  3.32000  7.580588  6.134398\n",
       "59  4.174319  3.320000  3.32000  7.016004  7.124143\n",
       "60  3.699251  3.320000  3.32000  7.568044  6.236546\n",
       "\n",
       "[61 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_expression_matrix = pd.read_csv('data/omalizumab/reduced_w_1/data.csv', index_col=None, header=None)\n",
    "labels = pd.read_csv('data/omalizumab/reduced_w_1/tempLabels_W-1.csv', index_col=None, header=None)\n",
    "genes = pd.read_csv('data/omalizumab/reduced_w_1/features.csv', index_col=None, header=None)\n",
    "gene_expression_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 5])\n",
      "torch.Size([40])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pietr\\anaconda3\\envs\\deep-logic\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "labels_encoded = encoder.fit_transform(labels.values)\n",
    "labels_encoded_noncontrols = labels_encoded[labels_encoded!=0] - 1\n",
    "\n",
    "data_controls = gene_expression_matrix[labels_encoded==0]\n",
    "data = gene_expression_matrix[labels_encoded!=0]\n",
    "\n",
    "gene_signature = data_controls.mean(axis=0)\n",
    "data_scaled = data - gene_signature\n",
    "\n",
    "scaler = MinMaxScaler((0, 1))\n",
    "scaler.fit(data_scaled)\n",
    "data_normalized = scaler.transform(data_scaled)\n",
    "\n",
    "x = torch.FloatTensor(data_normalized)\n",
    "y = torch.FloatTensor(labels_encoded_noncontrols)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ILMN_3286286',\n",
       " 'ILMN_1775520',\n",
       " 'ILMN_1656849',\n",
       " 'ILMN_1781198',\n",
       " 'ILMN_1665457']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concepts = list(genes.values.squeeze())\n",
    "concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(x_train, y_train, need_pruning, seed, device, relu=False, verbose=False):\n",
    "    set_seed(seed)\n",
    "    x_train = x_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    layers = [\n",
    "        torch.nn.Linear(x_train.size(1), 10),\n",
    "        torch.nn.ReLU() if relu else torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(10, 3),\n",
    "        torch.nn.ReLU() if relu else torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(3, 1),\n",
    "        torch.nn.Sigmoid(),\n",
    "    ]\n",
    "    model = torch.nn.Sequential(*layers).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "    loss_form = torch.nn.BCELoss()\n",
    "    model.train()\n",
    "    for epoch in range(tot_epochs):\n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_train).squeeze()\n",
    "        # Compute Loss\n",
    "        loss = loss_form(y_pred, y_train)\n",
    "\n",
    "        for module in model.children():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                loss += 0.001 * torch.norm(module.weight, 1)\n",
    "                loss += 0.001 * torch.norm(module.bias, 1)\n",
    "                break\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch > prune_epochs and need_pruning:\n",
    "            prune_features(model, n_classes=1, device=device)\n",
    "            need_pruning = False\n",
    "            \n",
    "        # compute accuracy\n",
    "        if epoch % 500 == 0 and verbose:\n",
    "            y_pred_d = y_pred > 0.5\n",
    "            accuracy = y_pred_d.eq(y_train).sum().item() / y_train.size(0)\n",
    "            print(f'\\t Epoch {epoch}: train accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_psi_nn(x_train, y_train, need_pruning, seed, device, verbose=False):\n",
    "    set_seed(seed)\n",
    "    x_train = x_train.to(device)\n",
    "    y_train = y_train.to(device).to(torch.float)\n",
    "    layers = [\n",
    "        torch.nn.Linear(x_train.size(1), 10),\n",
    "        torch.nn.Sigmoid(),\n",
    "        torch.nn.Linear(10, 4),\n",
    "        torch.nn.Sigmoid(),\n",
    "        torch.nn.Linear(4, 1),\n",
    "        torch.nn.Sigmoid(),\n",
    "    ]\n",
    "    model = torch.nn.Sequential(*layers).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_form = torch.nn.BCELoss()\n",
    "    model.train()\n",
    "    for epoch in range(tot_epochs):\n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_train).squeeze()\n",
    "        # Compute Loss\n",
    "        loss = loss_form(y_pred, y_train)\n",
    "\n",
    "        for module in model.children():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                loss += 0.00001 * torch.norm(module.weight, 1)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch > prune_epochs and need_pruning:\n",
    "            model = prune_equal_fanin(model, 2, validate=True, device=device)\n",
    "            need_pruning = False\n",
    "            \n",
    "        # compute accuracy\n",
    "        if epoch % 500 == 0 and verbose:\n",
    "            y_pred_d = y_pred > 0.5\n",
    "            accuracy = y_pred_d.eq(y_train).sum().item() / y_train.size(0)\n",
    "            print(f'\\t Epoch {epoch}: train accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_to_y(method, need_pruning, relu, verbose=False):\n",
    "    methods = []\n",
    "    splits = []\n",
    "    explanations = []\n",
    "    explanations_inv = []\n",
    "    model_accuracies = []\n",
    "    explanation_accuracies = []\n",
    "    explanation_accuracies_inv = []\n",
    "    elapsed_times = []\n",
    "    elapsed_times_inv = []\n",
    "    for split, (train_index, test_index) in enumerate(skf.split(x.cpu().detach().numpy(), y.cpu().detach().numpy())):\n",
    "        print(f'Split [{split+1}/{n_splits}]')\n",
    "        x_train, x_test = torch.FloatTensor(x[train_index]), torch.FloatTensor(x[test_index])\n",
    "        y_train, y_test = torch.FloatTensor(y[train_index]), torch.FloatTensor(y[test_index])\n",
    "    \n",
    "        explanation, explanation_inv = '', ''\n",
    "        explanation_accuracy, explanation_accuracy_inv = 0, 0\n",
    "        \n",
    "        if method == 'tree':\n",
    "            classifier = DecisionTreeClassifier(random_state=seed)\n",
    "            classifier.fit(x_train.detach().numpy(), y_train.detach().numpy())\n",
    "            y_preds = classifier.predict(x_test.detach().numpy())\n",
    "            model_accuracy = accuracy_score(y_test.detach().numpy(), y_preds)\n",
    "\n",
    "            target_class = 1\n",
    "            start = time.time()\n",
    "            explanation = tree_to_formula(classifier, concepts, target_class)\n",
    "            elapsed_time = time.time() - start\n",
    "\n",
    "            target_class_inv = 0\n",
    "            start = time.time()\n",
    "            explanation_inv = tree_to_formula(classifier, concepts, target_class_inv)\n",
    "            elapsed_time = time.time() - start\n",
    "        \n",
    "        else:\n",
    "            if method == 'psi':\n",
    "                # positive class\n",
    "                target_class = 1\n",
    "                model = train_psi_nn(x_train, y_train.eq(target_class), need_pruning, seed, device, verbose)\n",
    "                y_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "                model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds>0.5)\n",
    "                \n",
    "            else:\n",
    "                model = train_nn(x_train, y_train, need_pruning, seed, device, relu, verbose)\n",
    "                y_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "                model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds>0.5)\n",
    "\n",
    "            # positive class\n",
    "            target_class = 1\n",
    "            start = time.time()\n",
    "            if method == 'psi':\n",
    "                global_explanation = logic.generate_fol_explanations(model, device)[0]\n",
    "            else:\n",
    "                global_explanation, _, _ = logic.relu_nn.combine_local_explanations(model, \n",
    "                                                                                   x_train.to(device), y_train.to(device), \n",
    "                                                                                   target_class=target_class,\n",
    "                                                                                   method=method, device=device)\n",
    "            elapsed_time = time.time() - start\n",
    "            \n",
    "            if global_explanation:\n",
    "                explanation_accuracy, _ = logic.base.test_explanation(global_explanation, target_class, x_test, y_test)\n",
    "                explanation = logic.base.replace_names(global_explanation, concepts)\n",
    "\n",
    "            # negative class\n",
    "            target_class_inv = 0\n",
    "            if method == 'psi':\n",
    "                model = train_psi_nn(x_train, y_train.eq(target_class_inv), need_pruning, seed, device, verbose)\n",
    "            \n",
    "            start = time.time()\n",
    "            if method == 'psi':\n",
    "                global_explanation_inv = logic.generate_fol_explanations(model, device)[0]\n",
    "            else:\n",
    "                global_explanation_inv, _, _ = logic.relu_nn.combine_local_explanations(model, \n",
    "                                                                                       x_train.to(device), \n",
    "                                                                                       y_train.to(device), \n",
    "                                                                                       target_class=target_class_inv,\n",
    "                                                                                       method=method, device=device)\n",
    "            elapsed_time_inv = time.time() - start\n",
    "            if global_explanation_inv:\n",
    "                explanation_accuracy_inv, _ = logic.base.test_explanation(global_explanation_inv, \n",
    "                                                                          target_class_inv, x_test, y_test)\n",
    "                explanation_inv = logic.base.replace_names(global_explanation_inv, concepts)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "            print(f'\\t Class {target_class} - Global explanation: \"{explanation}\" - Accuracy: {explanation_accuracy:.4f}')\n",
    "            print(f'\\t Elapsed time {elapsed_time}')\n",
    "            print(f'\\t Class {target_class_inv} - Global explanation: \"{explanation_inv}\" - Accuracy: {explanation_accuracy_inv:.4f}')\n",
    "            print(f'\\t Elapsed time {elapsed_time_inv}')\n",
    "\n",
    "        methods.append(method)\n",
    "        splits.append(split)\n",
    "        explanations.append(explanation)\n",
    "        explanations_inv.append(explanation_inv)\n",
    "        model_accuracies.append(model_accuracy)\n",
    "        explanation_accuracies.append(explanation_accuracy)\n",
    "        explanation_accuracies_inv.append(explanation_accuracy_inv)\n",
    "        elapsed_times.append(elapsed_time)\n",
    "        elapsed_times_inv.append(elapsed_time_inv)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'method': methods,\n",
    "        'split': splits,\n",
    "        'explanation': explanations,\n",
    "        'explanation_inv': explanations_inv,\n",
    "        'model_accuracy': model_accuracies,\n",
    "        'explanation_accuracy': explanation_accuracies,\n",
    "        'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "        'elapsed_time': elapsed_times,\n",
    "        'elapsed_time_inv': elapsed_times_inv,\n",
    "    })\n",
    "    results.to_csv(os.path.join(results_dir, f'results_{method}.csv'))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 0: train accuracy: 0.7500\n",
      "\t Epoch 500: train accuracy: 1.0000\n",
      "\t Epoch 1000: train accuracy: 1.0000\n",
      "\t Epoch 1500: train accuracy: 1.0000\n",
      "\t Epoch 2000: train accuracy: 1.0000\n",
      "\t Epoch 2500: train accuracy: 1.0000\n",
      "\t Epoch 3000: train accuracy: 1.0000\n",
      "\t Epoch 3500: train accuracy: 1.0000\n",
      "\t Epoch 4000: train accuracy: 1.0000\n",
      "\t Epoch 4500: train accuracy: 1.0000\n",
      "\t Epoch 5000: train accuracy: 1.0000\n",
      "\t Epoch 5500: train accuracy: 1.0000\n",
      "\t Epoch 6000: train accuracy: 1.0000\n",
      "\t Model's accuracy: 1.0000\n",
      "\t Class 1 - Global explanation: \"(~ILMN_3286286 & ~ILMN_1775520 & ~ILMN_1656849) | (~ILMN_3286286 & ~ILMN_1656849 & ~ILMN_1781198) | (~ILMN_1775520 & ~ILMN_1656849 & ~ILMN_1781198)\" - Accuracy: 97.5000\n",
      "\t Elapsed time 0.04890179634094238\n"
     ]
    }
   ],
   "source": [
    "model = train_nn(x, y, need_pruning=True, seed=seed, device=device, relu=False, verbose=True)\n",
    "y_preds = model(x.to(device)).cpu().detach().numpy()\n",
    "model_accuracy = accuracy_score(y.cpu().detach().numpy(), y>0.5)\n",
    "\n",
    "# positive class\n",
    "target_class = 1\n",
    "start = time.time()\n",
    "global_explanation, _, _ = logic.relu_nn.combine_local_explanations(model, \n",
    "                                                                    x.to(device), y.to(device), \n",
    "                                                                    target_class=target_class,\n",
    "                                                                    topk_explanations=10,\n",
    "                                                                    method='pruning', device=device)\n",
    "elapsed_time = time.time() - start\n",
    "\n",
    "if global_explanation:\n",
    "    explanation_accuracy, _ = logic.base.test_explanation(global_explanation, target_class, x, y)\n",
    "    explanation = logic.base.replace_names(global_explanation, concepts)\n",
    "\n",
    "print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "print(f'\\t Class {target_class} - Global explanation: \"{explanation}\" - Accuracy: {explanation_accuracy:.4f}')\n",
    "print(f'\\t Elapsed time {elapsed_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split [1/10]\n",
      "Split [2/10]\n",
      "Split [3/10]\n",
      "Split [4/10]\n",
      "Split [5/10]\n",
      "Split [6/10]\n",
      "Split [7/10]\n",
      "Split [8/10]\n",
      "Split [9/10]\n",
      "Split [10/10]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>explanation_inv</th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_accuracy_inv</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>elapsed_time_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pruning</td>\n",
       "      <td>0</td>\n",
       "      <td>~ILMN_3286286 &amp; ~ILMN_1656849 &amp; ~ILMN_1781198</td>\n",
       "      <td>(ILMN_1656849 &amp; ILMN_1781198 &amp; ILMN_1665457 &amp; ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.055851</td>\n",
       "      <td>0.048870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pruning</td>\n",
       "      <td>1</td>\n",
       "      <td>~ILMN_3286286 &amp; ~ILMN_1656849 &amp; ~ILMN_1781198</td>\n",
       "      <td>(ILMN_3286286 &amp; ILMN_1781198 &amp; ~ILMN_1656849 &amp;...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.052821</td>\n",
       "      <td>0.042885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pruning</td>\n",
       "      <td>2</td>\n",
       "      <td>~ILMN_3286286 &amp; ~ILMN_1775520 &amp; ~ILMN_1656849</td>\n",
       "      <td>(ILMN_1775520 &amp; ILMN_1781198 &amp; ~ILMN_3286286 &amp;...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.048869</td>\n",
       "      <td>0.064827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pruning</td>\n",
       "      <td>3</td>\n",
       "      <td>~ILMN_3286286 &amp; ~ILMN_1656849 &amp; ~ILMN_1781198</td>\n",
       "      <td>(ILMN_3286286 &amp; ILMN_1781198 &amp; ~ILMN_1656849 &amp;...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.059353</td>\n",
       "      <td>0.053855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pruning</td>\n",
       "      <td>4</td>\n",
       "      <td>~ILMN_3286286 &amp; ~ILMN_1656849 &amp; ~ILMN_1781198</td>\n",
       "      <td>(ILMN_3286286 &amp; ILMN_1781198 &amp; ~ILMN_1656849 &amp;...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.051861</td>\n",
       "      <td>0.081782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pruning</td>\n",
       "      <td>5</td>\n",
       "      <td>~ILMN_3286286 &amp; ~ILMN_1775520 &amp; ~ILMN_1656849 ...</td>\n",
       "      <td>ILMN_1656849 &amp; ILMN_1781198 &amp; ~ILMN_3286286 &amp; ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.070779</td>\n",
       "      <td>0.072300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pruning</td>\n",
       "      <td>6</td>\n",
       "      <td>~ILMN_3286286 &amp; ~ILMN_1775520 &amp; ~ILMN_1656849</td>\n",
       "      <td>(ILMN_1775520 &amp; ILMN_1781198 &amp; ~ILMN_3286286 &amp;...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.083778</td>\n",
       "      <td>0.070807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pruning</td>\n",
       "      <td>7</td>\n",
       "      <td>~ILMN_3286286 &amp; ~ILMN_1656849 &amp; ~ILMN_1781198</td>\n",
       "      <td>(ILMN_3286286 &amp; ILMN_1781198 &amp; ~ILMN_1656849 &amp;...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.063799</td>\n",
       "      <td>0.051859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pruning</td>\n",
       "      <td>8</td>\n",
       "      <td>~ILMN_3286286 &amp; ~ILMN_1775520 &amp; ~ILMN_1656849</td>\n",
       "      <td>(ILMN_1775520 &amp; ILMN_1781198 &amp; ~ILMN_3286286 &amp;...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.051926</td>\n",
       "      <td>0.054788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pruning</td>\n",
       "      <td>9</td>\n",
       "      <td>~ILMN_3286286 &amp; ~ILMN_1775520 &amp; ~ILMN_1656849 ...</td>\n",
       "      <td>ILMN_1656849 &amp; ILMN_1781198 &amp; ~ILMN_3286286 &amp; ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.065828</td>\n",
       "      <td>0.075335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    method  split                                        explanation  \\\n",
       "0  pruning      0      ~ILMN_3286286 & ~ILMN_1656849 & ~ILMN_1781198   \n",
       "1  pruning      1      ~ILMN_3286286 & ~ILMN_1656849 & ~ILMN_1781198   \n",
       "2  pruning      2      ~ILMN_3286286 & ~ILMN_1775520 & ~ILMN_1656849   \n",
       "3  pruning      3      ~ILMN_3286286 & ~ILMN_1656849 & ~ILMN_1781198   \n",
       "4  pruning      4      ~ILMN_3286286 & ~ILMN_1656849 & ~ILMN_1781198   \n",
       "5  pruning      5  ~ILMN_3286286 & ~ILMN_1775520 & ~ILMN_1656849 ...   \n",
       "6  pruning      6      ~ILMN_3286286 & ~ILMN_1775520 & ~ILMN_1656849   \n",
       "7  pruning      7      ~ILMN_3286286 & ~ILMN_1656849 & ~ILMN_1781198   \n",
       "8  pruning      8      ~ILMN_3286286 & ~ILMN_1775520 & ~ILMN_1656849   \n",
       "9  pruning      9  ~ILMN_3286286 & ~ILMN_1775520 & ~ILMN_1656849 ...   \n",
       "\n",
       "                                     explanation_inv  model_accuracy  \\\n",
       "0  (ILMN_1656849 & ILMN_1781198 & ILMN_1665457 & ...             1.0   \n",
       "1  (ILMN_3286286 & ILMN_1781198 & ~ILMN_1656849 &...             1.0   \n",
       "2  (ILMN_1775520 & ILMN_1781198 & ~ILMN_3286286 &...             1.0   \n",
       "3  (ILMN_3286286 & ILMN_1781198 & ~ILMN_1656849 &...             1.0   \n",
       "4  (ILMN_3286286 & ILMN_1781198 & ~ILMN_1656849 &...             1.0   \n",
       "5  ILMN_1656849 & ILMN_1781198 & ~ILMN_3286286 & ...             1.0   \n",
       "6  (ILMN_1775520 & ILMN_1781198 & ~ILMN_3286286 &...             1.0   \n",
       "7  (ILMN_3286286 & ILMN_1781198 & ~ILMN_1656849 &...             1.0   \n",
       "8  (ILMN_1775520 & ILMN_1781198 & ~ILMN_3286286 &...             1.0   \n",
       "9  ILMN_1656849 & ILMN_1781198 & ~ILMN_3286286 & ...             1.0   \n",
       "\n",
       "   explanation_accuracy  explanation_accuracy_inv  elapsed_time  \\\n",
       "0                  50.0                      75.0      0.055851   \n",
       "1                  50.0                      75.0      0.052821   \n",
       "2                 100.0                      75.0      0.048869   \n",
       "3                  50.0                      75.0      0.059353   \n",
       "4                  50.0                     100.0      0.051861   \n",
       "5                  25.0                      75.0      0.070779   \n",
       "6                 100.0                      75.0      0.083778   \n",
       "7                  50.0                      75.0      0.063799   \n",
       "8                 100.0                      75.0      0.051926   \n",
       "9                  75.0                      75.0      0.065828   \n",
       "\n",
       "   elapsed_time_inv  \n",
       "0          0.048870  \n",
       "1          0.042885  \n",
       "2          0.064827  \n",
       "3          0.053855  \n",
       "4          0.081782  \n",
       "5          0.072300  \n",
       "6          0.070807  \n",
       "7          0.051859  \n",
       "8          0.054788  \n",
       "9          0.075335  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = 'pruning'\n",
    "need_pruning = True\n",
    "relu = False\n",
    "results_pruning = c_to_y(method, need_pruning, relu, verbose=False)\n",
    "results_pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'lime'\n",
    "need_pruning = False\n",
    "relu = False\n",
    "results_lime = c_to_y(method, need_pruning, relu, False)\n",
    "results_lime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'weights'\n",
    "need_pruning = False\n",
    "relu = True\n",
    "results_weights = c_to_y(method, need_pruning, relu, False)\n",
    "results_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Psi network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'psi'\n",
    "need_pruning = True\n",
    "relu = False\n",
    "results_psi = c_to_y(method, need_pruning, relu, verbose=False)\n",
    "results_psi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'tree'\n",
    "need_pruning = False\n",
    "relu = False\n",
    "results_tree = c_to_y(method, need_pruning, relu, verbose=False)\n",
    "results_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_accuracy_mean</th>\n",
       "      <th>explanation_accuracy_mean</th>\n",
       "      <th>explanation_accuracy_inv_mean</th>\n",
       "      <th>elapsed_time_mean</th>\n",
       "      <th>elapsed_time_inv_mean</th>\n",
       "      <th>model_accuracy_sem</th>\n",
       "      <th>explanation_accuracy_sem</th>\n",
       "      <th>explanation_accuracy_inv_sem</th>\n",
       "      <th>elapsed_time_sem</th>\n",
       "      <th>elapsed_time_inv_sem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pruning</th>\n",
       "      <td>0.975</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.068861</td>\n",
       "      <td>0.041138</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.098953</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>0.003383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lime</th>\n",
       "      <td>0.850</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>24.077748</td>\n",
       "      <td>10.371542</td>\n",
       "      <td>0.040825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115518</td>\n",
       "      <td>0.075365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weights</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.109159</td>\n",
       "      <td>0.050979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091287</td>\n",
       "      <td>0.078617</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>0.003413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psi</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.035007</td>\n",
       "      <td>0.029819</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.040825</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.002218</td>\n",
       "      <td>0.003012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055902</td>\n",
       "      <td>0.055902</td>\n",
       "      <td>0.055902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model_accuracy_mean  explanation_accuracy_mean  \\\n",
       "pruning                0.975                      0.675   \n",
       "lime                   0.850                      1.000   \n",
       "weights                1.000                      0.750   \n",
       "psi                    0.800                      0.900   \n",
       "tree                   0.875                      0.875   \n",
       "\n",
       "         explanation_accuracy_inv_mean  elapsed_time_mean  \\\n",
       "pruning                          0.800           0.068861   \n",
       "lime                             0.250          24.077748   \n",
       "weights                          0.775           0.109159   \n",
       "psi                              0.800           0.035007   \n",
       "tree                             0.875           0.000000   \n",
       "\n",
       "         elapsed_time_inv_mean  model_accuracy_sem  explanation_accuracy_sem  \\\n",
       "pruning               0.041138            0.025000                  0.098953   \n",
       "lime                 10.371542            0.040825                  0.000000   \n",
       "weights               0.050979            0.000000                  0.091287   \n",
       "psi                   0.029819            0.033333                  0.040825   \n",
       "tree                  0.000000            0.055902                  0.055902   \n",
       "\n",
       "         explanation_accuracy_inv_sem  elapsed_time_sem  elapsed_time_inv_sem  \n",
       "pruning                      0.050000          0.004212              0.003383  \n",
       "lime                         0.000000          0.115518              0.075365  \n",
       "weights                      0.078617          0.003653              0.003413  \n",
       "psi                          0.033333          0.002218              0.003012  \n",
       "tree                         0.055902          0.000000              0.000000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['model_accuracy', 'explanation_accuracy', 'explanation_accuracy_inv', 'elapsed_time', 'elapsed_time_inv']\n",
    "mean_cols = [f'{c}_mean' for c in cols]\n",
    "sem_cols = [f'{c}_sem' for c in cols]\n",
    "\n",
    "# pruning\n",
    "df_mean = results_pruning[cols].mean()\n",
    "df_sem = results_pruning[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_pruning = pd.concat([df_mean, df_sem])\n",
    "summary_pruning.name = 'pruning'\n",
    "\n",
    "# lime\n",
    "df_mean = results_lime[cols].mean()\n",
    "df_sem = results_lime[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_lime = pd.concat([df_mean, df_sem])\n",
    "summary_lime.name = 'lime'\n",
    "\n",
    "# weights\n",
    "df_mean = results_weights[cols].mean()\n",
    "df_sem = results_weights[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_weights = pd.concat([df_mean, df_sem])\n",
    "summary_weights.name = 'weights'\n",
    "\n",
    "# psi\n",
    "df_mean = results_psi[cols].mean()\n",
    "df_sem = results_psi[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_psi = pd.concat([df_mean, df_sem])\n",
    "summary_psi.name = 'psi'\n",
    "\n",
    "# tree\n",
    "df_mean = results_tree[cols].mean()\n",
    "df_sem = results_tree[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_tree = pd.concat([df_mean, df_sem])\n",
    "summary_tree.name = 'tree'\n",
    "\n",
    "summary = pd.concat([summary_pruning, \n",
    "                     summary_lime, \n",
    "                     summary_weights, \n",
    "                     summary_psi, \n",
    "                     summary_tree], axis=1).T\n",
    "summary.columns = mean_cols + sem_cols\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_csv(os.path.join(results_dir, 'summary.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
