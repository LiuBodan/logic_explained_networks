{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "compound-desert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1776, 90])\n",
      "torch.Size([1776])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, KBinsDiscretizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sympy import simplify_logic\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from lens.utils.base import validate_network, set_seed, tree_to_formula\n",
    "from lens.utils.relu_nn import get_reduced_model, prune_features\n",
    "from lens.utils.psi_nn import prune_equal_fanin\n",
    "from lens import logic\n",
    "import lens\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "#%%\n",
    "\n",
    "data = pd.read_csv('data/mimic-ii/full_cohort_data.csv')\n",
    "# data.drop('hgb_first')\n",
    "fs = [\n",
    "    'aline_flg',\n",
    "    'gender_num',\n",
    "    # 'hosp_exp_flg',\n",
    "    # 'icu_exp_flg',\n",
    "    # 'day_28_flg',\n",
    "    # 'censor_flg',\n",
    "    'sepsis_flg', 'chf_flg', 'afib_flg',\n",
    "    'renal_flg', 'liver_flg', 'copd_flg', 'cad_flg', 'stroke_flg',\n",
    "    'mal_flg', 'resp_flg',\n",
    "]\n",
    "features = fs\n",
    "data1 = data[fs].values\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "data1 = imp_mean.fit_transform(data1)\n",
    "\n",
    "f2 = fs.copy()\n",
    "f2.append('day_icu_intime')\n",
    "f2.append('service_unit')\n",
    "f2.append('day_28_flg')\n",
    "f2.append('hospital_los_day')\n",
    "f2.append('icu_exp_flg')\n",
    "f2.append('hosp_exp_flg')\n",
    "f2.append('censor_flg')\n",
    "f2.append('mort_day_censored')\n",
    "f2 = data.columns.difference(f2)\n",
    "data2 = data[f2].values\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "data2 = imp_mean.fit_transform(data2)\n",
    "scaler = MinMaxScaler((0, 1))\n",
    "data2 = scaler.fit_transform(data2)\n",
    "features = features + list(f2)\n",
    "est = KBinsDiscretizer(n_bins=3, encode='onehot-dense', strategy='uniform')\n",
    "data2d = est.fit_transform(data2)\n",
    "f2d = []\n",
    "for feature in f2:\n",
    "    #f2d.append(feature + '_VLOW')\n",
    "    f2d.append(feature + '_LOW')\n",
    "    f2d.append(feature + '_NORMAL')\n",
    "    f2d.append(feature + '_HIGH')\n",
    "    #f2d.append(feature + '_VHIGH')\n",
    "features = fs + f2d\n",
    "\n",
    "datax = np.hstack((data1, data2d))\n",
    "datay = data['day_28_flg'].values\n",
    "\n",
    "x = torch.FloatTensor(datax)\n",
    "y = torch.LongTensor(datay)\n",
    "print(x.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "front-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = 'results/mimic'\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# concepts = [f'c{i:03}' for i in range(x.shape[1])]\n",
    "concepts =  features\n",
    "n_rep = 10\n",
    "tot_epochs = 5001\n",
    "prune_epochs = 2001\n",
    "seed = 42\n",
    "\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "chinese-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(x_train, y_train, need_pruning, seed, device, l1=0.001, lr=0.001, relu=False, verbose=False):\n",
    "    set_seed(seed)\n",
    "    x_train = x_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    layers = [\n",
    "        torch.nn.Linear(x_train.size(1), 100),\n",
    "        torch.nn.ReLU() if relu else torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(100, 10),\n",
    "        torch.nn.ReLU() if relu else torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(10, 2),\n",
    "        torch.nn.Softmax(dim=1),\n",
    "    ]\n",
    "    model = torch.nn.Sequential(*layers).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    loss_form = torch.nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    for epoch in range(tot_epochs):\n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_train)\n",
    "        # Compute Loss\n",
    "        loss = loss_form(y_pred, y_train)\n",
    "\n",
    "        for module in model.children():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                loss += l1 * torch.norm(module.weight, 1)\n",
    "                loss += l1 * torch.norm(module.bias, 1)\n",
    "                break\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch > prune_epochs and need_pruning and epoch % 1000 == 1:\n",
    "            prune_features(model, n_classes=1, device=device)\n",
    "            need_pruning = True\n",
    "            \n",
    "        # compute accuracy\n",
    "        if epoch % 500 == 0 and verbose:\n",
    "            y_pred_d = torch.argmax(y_pred, dim=1)\n",
    "            accuracy = y_pred_d.eq(y_train).sum().item() / y_train.size(0)\n",
    "            print(f'\\t Epoch {epoch}: train accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "worldwide-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_psi_nn(x_train, y_train, need_pruning, seed, device, verbose=False):\n",
    "    set_seed(seed)\n",
    "    x_train = x_train.to(device)\n",
    "    y_train = y_train.to(device).to(torch.float)\n",
    "    layers = [\n",
    "        torch.nn.Linear(x_train.size(1), 10),\n",
    "        torch.nn.Sigmoid(),\n",
    "        torch.nn.Linear(10, 4),\n",
    "        torch.nn.Sigmoid(),\n",
    "        torch.nn.Linear(4, 1),\n",
    "        torch.nn.Sigmoid(),\n",
    "    ]\n",
    "    model = torch.nn.Sequential(*layers).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_form = torch.nn.BCELoss()\n",
    "    model.train()\n",
    "    for epoch in range(tot_epochs):\n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_train).squeeze()\n",
    "        # Compute Loss\n",
    "        loss = loss_form(y_pred, y_train)\n",
    "\n",
    "        for module in model.children():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                loss += 0.00001 * torch.norm(module.weight, 1)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch > prune_epochs and need_pruning:\n",
    "            model = prune_equal_fanin(model, 2, validate=True, device=device)\n",
    "            need_pruning = False\n",
    "            \n",
    "        # compute accuracy\n",
    "        if epoch % 500 == 0 and verbose:\n",
    "            y_pred_d = y_pred > 0.5\n",
    "            accuracy = y_pred_d.eq(y_train).sum().item() / y_train.size(0)\n",
    "            print(f'\\t Epoch {epoch}: train accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "unlike-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_to_y(method, need_pruning, l1=0.001, lr=0.001, relu=False, verbose=False):\n",
    "    methods = []\n",
    "    splits = []\n",
    "    explanations = []\n",
    "    explanations_inv = []\n",
    "    model_accuracies = []\n",
    "    explanation_accuracies = []\n",
    "    explanation_accuracies_inv = []\n",
    "    elapsed_times = []\n",
    "    elapsed_times_inv = []\n",
    "    explanation_fidelities = []\n",
    "    explanation_complexities = []\n",
    "    for split, (trainval_index, test_index) in enumerate(skf.split(x.cpu().detach().numpy(), y.cpu().detach().numpy())):\n",
    "        print(f'Split [{split+1}/{n_splits}]')\n",
    "        x_trainval, x_test = torch.FloatTensor(x[trainval_index]), torch.FloatTensor(x[test_index])\n",
    "        y_trainval, y_test = torch.LongTensor(y[trainval_index]), torch.LongTensor(y[test_index])\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x_trainval, y_trainval, test_size=0.3, random_state=42)\n",
    "    \n",
    "        explanation, explanation_inv = '', ''\n",
    "        explanation_accuracy, explanation_accuracy_inv = 0, 0\n",
    "        \n",
    "        if method == 'tree':\n",
    "            classifier = DecisionTreeClassifier(random_state=seed)\n",
    "            classifier.fit(x_trainval.cpu().detach().numpy(), y_trainval.cpu().detach().numpy())\n",
    "            y_preds = classifier.predict(x_test.cpu().detach().numpy())\n",
    "            model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds)\n",
    "\n",
    "            target_class = 1\n",
    "            start = time.time()\n",
    "            explanation = tree_to_formula(classifier, concepts, target_class)\n",
    "            elapsed_time = time.time() - start\n",
    "            explanation_accuracy = model_accuracy\n",
    "            explanation_fidelity = 1.\n",
    "            explanation_complexity = lens.logic.complexity(explanation)\n",
    "\n",
    "            target_class_inv = 0\n",
    "            start = time.time()\n",
    "            explanation_inv = tree_to_formula(classifier, concepts, target_class_inv)\n",
    "            elapsed_time_inv = time.time() - start\n",
    "            explanation_accuracy_inv = model_accuracy\n",
    "        \n",
    "        else:\n",
    "            if method == 'psi':\n",
    "                # positive class\n",
    "                target_class = 1\n",
    "                model = train_psi_nn(x_trainval, y_trainval.eq(target_class), need_pruning, seed, device, verbose)\n",
    "                y_preds = model(x_test.to(device)).cpu().detach().numpy()>0.5\n",
    "                model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds)\n",
    "                \n",
    "            else:\n",
    "                model = train_nn(x_trainval, y_trainval, need_pruning, seed, device, l1, lr, relu, verbose)\n",
    "                y_preds = model(x_test.to(device)).cpu().detach().numpy().argmax(axis=1)\n",
    "                model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds)\n",
    "\n",
    "            # positive class\n",
    "            target_class = 1\n",
    "            start = time.time()\n",
    "            if method == 'psi':\n",
    "                global_explanation = logic.generate_fol_explanations(model, device)[0]\n",
    "            else:\n",
    "                global_explanation, _, _ = logic.relu_nn.combine_local_explanations(model, \n",
    "                                                                                   x_val.to(device), \n",
    "                                                                                   y_val.to(device), \n",
    "                                                                                   topk_explanations=3,\n",
    "                                                                                   target_class=target_class,\n",
    "                                                                                   method=method, device=device)\n",
    "            elapsed_time = time.time() - start\n",
    "            \n",
    "            if global_explanation:\n",
    "#                 explanation_accuracy, _ = logic.base.test_explanation(global_explanation, target_class, x_test, y_test)\n",
    "                explanation = logic.base.replace_names(global_explanation, concepts)\n",
    "                explanation_accuracy, y_formula = logic.base.test_explanation(global_explanation, \n",
    "                                                                              target_class, \n",
    "                                                                              x=x_test, y=y_test,\n",
    "                                                                              metric=accuracy_score)\n",
    "                explanation_fidelity = lens.logic.fidelity(y_formula, y_preds)\n",
    "                explanation_complexity = lens.logic.complexity(global_explanation)\n",
    "\n",
    "#             # negative class\n",
    "#             target_class_inv = 0\n",
    "#             if method == 'psi':\n",
    "#                 model = train_psi_nn(x_trainval, y_trainval.eq(target_class_inv), need_pruning, seed, device, verbose)\n",
    "            \n",
    "#             start = time.time()\n",
    "#             if method == 'psi':\n",
    "#                 global_explanation_inv = logic.generate_fol_explanations(model, device)[0]\n",
    "#             else:\n",
    "#                 global_explanation_inv, _, _ = logic.relu_nn.combine_local_explanations(model, \n",
    "#                                                                                        x_val.to(device), \n",
    "#                                                                                        y_val.to(device), \n",
    "#                                                                                        topk_explanations=2,\n",
    "#                                                                                        target_class=target_class_inv,\n",
    "#                                                                                        method=method, device=device)\n",
    "#             elapsed_time_inv = time.time() - start\n",
    "#             if global_explanation_inv:\n",
    "#                 explanation_accuracy_inv, _ = logic.base.test_explanation(global_explanation_inv, \n",
    "#                                                                           target_class_inv, x_test, y_test)\n",
    "#                 explanation_inv = logic.base.replace_names(global_explanation_inv, concepts)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "            print(f'\\t Class {target_class} - Global explanation: \"{explanation}\" - Accuracy: {explanation_accuracy:.4f}')\n",
    "            print(f'\\t Elapsed time {elapsed_time}')\n",
    "            print(f'\\t Fidelity: \"{explanation_fidelity:.4f}\" - Complexity: \"{explanation_complexity}\"')\n",
    "#             print(f'\\t Class {target_class_inv} - Global explanation: \"{explanation_inv}\" - Accuracy: {explanation_accuracy_inv:.4f}')\n",
    "#             print(f'\\t Elapsed time {elapsed_time_inv}')\n",
    "\n",
    "        methods.append(method)\n",
    "        splits.append(split)\n",
    "        explanations.append(explanation)\n",
    "#         explanations_inv.append(explanation_inv)\n",
    "        model_accuracies.append(model_accuracy)\n",
    "        explanation_accuracies.append(explanation_accuracy)\n",
    "#         explanation_accuracies_inv.append(explanation_accuracy_inv)\n",
    "        elapsed_times.append(elapsed_time)\n",
    "#         elapsed_times_inv.append(elapsed_time_inv)\n",
    "        explanation_fidelities.append(explanation_fidelity)\n",
    "        explanation_complexities.append(explanation_complexity)\n",
    "    \n",
    "    explanation_consistency = lens.logic.formula_consistency(explanations)\n",
    "    print(f'Consistency of explanations: {explanation_consistency:.4f}')\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'method': methods,\n",
    "        'split': splits,\n",
    "        'explanation': explanations,\n",
    "#         'explanation_inv': explanations_inv,\n",
    "        'model_accuracy': model_accuracies,\n",
    "        'explanation_accuracy': explanation_accuracies,\n",
    "        'explanation_fidelity': explanation_fidelities,\n",
    "        'explanation_complexity': explanation_complexities,\n",
    "        'explanation_consistency': explanation_consistency,\n",
    "#         'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "        'elapsed_time': elapsed_times,\n",
    "#         'elapsed_time_inv': elapsed_times_inv,\n",
    "    })\n",
    "    results.to_csv(os.path.join(results_dir, f'results_{method}.csv'))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-glossary",
   "metadata": {},
   "source": [
    "# General pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "intended-rolling",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split [1/10]\n",
      "Split [2/10]\n",
      "Split [3/10]\n",
      "Split [4/10]\n",
      "Split [5/10]\n",
      "Split [6/10]\n",
      "Split [7/10]\n",
      "Split [8/10]\n",
      "Split [9/10]\n",
      "Split [10/10]\n",
      "Consistency of explanations: 0.3222\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_fidelity</th>\n",
       "      <th>explanation_complexity</th>\n",
       "      <th>explanation_consistency</th>\n",
       "      <th>elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pruning</td>\n",
       "      <td>0</td>\n",
       "      <td>stroke_flg</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.043916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pruning</td>\n",
       "      <td>1</td>\n",
       "      <td>(stroke_flg &amp; bun_first_LOW &amp; ~sapsi_first_LOW...</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.988764</td>\n",
       "      <td>7</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.077024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pruning</td>\n",
       "      <td>2</td>\n",
       "      <td>stroke_flg</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.040891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pruning</td>\n",
       "      <td>3</td>\n",
       "      <td>stroke_flg &amp; age_HIGH</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.072806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pruning</td>\n",
       "      <td>4</td>\n",
       "      <td>(stroke_flg &amp; age_HIGH &amp; ~liver_flg) | (age_HI...</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.090760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pruning</td>\n",
       "      <td>5</td>\n",
       "      <td>(stroke_flg &amp; age_HIGH &amp; bun_first_LOW) | (age...</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.994382</td>\n",
       "      <td>7</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.053856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pruning</td>\n",
       "      <td>6</td>\n",
       "      <td>(stroke_flg &amp; age_HIGH) | (age_HIGH &amp; ~bun_fir...</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.058986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pruning</td>\n",
       "      <td>7</td>\n",
       "      <td>(stroke_flg &amp; age_HIGH) | (age_HIGH &amp; ~bun_fir...</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.049867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pruning</td>\n",
       "      <td>8</td>\n",
       "      <td>(stroke_flg &amp; abg_count_LOW &amp; bun_first_LOW &amp; ...</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.994350</td>\n",
       "      <td>9</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.115722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pruning</td>\n",
       "      <td>9</td>\n",
       "      <td>stroke_flg &amp; ~sapsi_first_LOW</td>\n",
       "      <td>0.875706</td>\n",
       "      <td>0.875706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.051389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    method  split                                        explanation  \\\n",
       "0  pruning      0                                         stroke_flg   \n",
       "1  pruning      1  (stroke_flg & bun_first_LOW & ~sapsi_first_LOW...   \n",
       "2  pruning      2                                         stroke_flg   \n",
       "3  pruning      3                              stroke_flg & age_HIGH   \n",
       "4  pruning      4  (stroke_flg & age_HIGH & ~liver_flg) | (age_HI...   \n",
       "5  pruning      5  (stroke_flg & age_HIGH & bun_first_LOW) | (age...   \n",
       "6  pruning      6  (stroke_flg & age_HIGH) | (age_HIGH & ~bun_fir...   \n",
       "7  pruning      7  (stroke_flg & age_HIGH) | (age_HIGH & ~bun_fir...   \n",
       "8  pruning      8  (stroke_flg & abg_count_LOW & bun_first_LOW & ...   \n",
       "9  pruning      9                      stroke_flg & ~sapsi_first_LOW   \n",
       "\n",
       "   model_accuracy  explanation_accuracy  explanation_fidelity  \\\n",
       "0        0.842697              0.842697              1.000000   \n",
       "1        0.837079              0.837079              0.988764   \n",
       "2        0.853933              0.853933              1.000000   \n",
       "3        0.865169              0.865169              1.000000   \n",
       "4        0.865169              0.865169              1.000000   \n",
       "5        0.859551              0.865169              0.994382   \n",
       "6        0.847458              0.847458              1.000000   \n",
       "7        0.864407              0.864407              1.000000   \n",
       "8        0.830508              0.824859              0.994350   \n",
       "9        0.875706              0.875706              1.000000   \n",
       "\n",
       "   explanation_complexity  explanation_consistency  elapsed_time  \n",
       "0                       1                 0.322222      0.043916  \n",
       "1                       7                 0.322222      0.077024  \n",
       "2                       1                 0.322222      0.040891  \n",
       "3                       2                 0.322222      0.072806  \n",
       "4                       6                 0.322222      0.090760  \n",
       "5                       7                 0.322222      0.053856  \n",
       "6                       4                 0.322222      0.058986  \n",
       "7                       4                 0.322222      0.049867  \n",
       "8                       9                 0.322222      0.115722  \n",
       "9                       2                 0.322222      0.051389  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = 'pruning'\n",
    "need_pruning = True\n",
    "relu = False\n",
    "results_pruning = c_to_y(method, need_pruning, relu=relu)\n",
    "results_pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-flooring",
   "metadata": {},
   "source": [
    "# ReLUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "verified-sport",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split [1/10]\n",
      "\t Epoch 0: train accuracy: 0.1589\n",
      "\t Epoch 500: train accuracy: 0.8411\n",
      "\t Epoch 1000: train accuracy: 0.8411\n",
      "\t Epoch 1500: train accuracy: 0.8411\n",
      "\t Epoch 2000: train accuracy: 0.8411\n",
      "\t Epoch 2500: train accuracy: 0.8411\n",
      "\t Epoch 3000: train accuracy: 0.8411\n",
      "\t Epoch 3500: train accuracy: 0.8411\n",
      "\t Epoch 4000: train accuracy: 0.8780\n",
      "\t Epoch 4500: train accuracy: 0.8842\n",
      "\t Epoch 5000: train accuracy: 0.8936\n",
      "\t Model's accuracy: 0.8596\n",
      "\t Class 1 - Global explanation: \"(tco2_first_NORMAL & ~renal_flg) | (age_HIGH & ~stroke_flg & ~weight_first_NORMAL)\" - Accuracy: 0.3483\n",
      "\t Elapsed time 0.25098729133605957\n",
      "\t Fidelity: \"0.2753\" - Complexity: \"5\"\n",
      "Split [2/10]\n",
      "\t Epoch 0: train accuracy: 0.1589\n",
      "\t Epoch 500: train accuracy: 0.8411\n",
      "\t Epoch 1000: train accuracy: 0.8411\n",
      "\t Epoch 1500: train accuracy: 0.8411\n",
      "\t Epoch 2000: train accuracy: 0.8411\n",
      "\t Epoch 2500: train accuracy: 0.8411\n",
      "\t Epoch 3000: train accuracy: 0.8411\n",
      "\t Epoch 3500: train accuracy: 0.8411\n",
      "\t Epoch 4000: train accuracy: 0.8411\n",
      "\t Epoch 4500: train accuracy: 0.8411\n",
      "\t Epoch 5000: train accuracy: 0.8411\n",
      "\t Model's accuracy: 0.8371\n",
      "\t Class 1 - Global explanation: \"\" - Accuracy: 0.0000\n",
      "\t Elapsed time 0.0019922256469726562\n",
      "\t Fidelity: \"0.2753\" - Complexity: \"5\"\n",
      "Split [3/10]\n",
      "\t Epoch 0: train accuracy: 0.1589\n",
      "\t Epoch 500: train accuracy: 0.8411\n",
      "\t Epoch 1000: train accuracy: 0.8411\n",
      "\t Epoch 1500: train accuracy: 0.8411\n",
      "\t Epoch 2000: train accuracy: 0.8411\n",
      "\t Epoch 2500: train accuracy: 0.8411\n",
      "\t Epoch 3000: train accuracy: 0.8411\n",
      "\t Epoch 3500: train accuracy: 0.8411\n",
      "\t Epoch 4000: train accuracy: 0.8411\n",
      "\t Epoch 4500: train accuracy: 0.8855\n",
      "\t Epoch 5000: train accuracy: 0.9011\n",
      "\t Model's accuracy: 0.8596\n",
      "\t Class 1 - Global explanation: \"age_HIGH | (bun_first_LOW & ~mal_flg & ~age_LOW & ~sapsi_first_LOW & ~weight_first_NORMAL)\" - Accuracy: 0.6573\n",
      "\t Elapsed time 0.27993297576904297\n",
      "\t Fidelity: \"0.6742\" - Complexity: \"6\"\n",
      "Split [4/10]\n",
      "\t Epoch 0: train accuracy: 0.1596\n",
      "\t Epoch 500: train accuracy: 0.8404\n",
      "\t Epoch 1000: train accuracy: 0.8404\n",
      "\t Epoch 1500: train accuracy: 0.8404\n",
      "\t Epoch 2000: train accuracy: 0.8404\n",
      "\t Epoch 2500: train accuracy: 0.8404\n",
      "\t Epoch 3000: train accuracy: 0.8404\n",
      "\t Epoch 3500: train accuracy: 0.8404\n",
      "\t Epoch 4000: train accuracy: 0.8404\n",
      "\t Epoch 4500: train accuracy: 0.8404\n",
      "\t Epoch 5000: train accuracy: 0.8404\n",
      "\t Model's accuracy: 0.8427\n",
      "\t Class 1 - Global explanation: \"\" - Accuracy: 0.0000\n",
      "\t Elapsed time 0.001994609832763672\n",
      "\t Fidelity: \"0.6742\" - Complexity: \"6\"\n",
      "Split [5/10]\n",
      "\t Epoch 0: train accuracy: 0.1596\n",
      "\t Epoch 500: train accuracy: 0.8404\n",
      "\t Epoch 1000: train accuracy: 0.8404\n",
      "\t Epoch 1500: train accuracy: 0.8404\n",
      "\t Epoch 2000: train accuracy: 0.8404\n",
      "\t Epoch 2500: train accuracy: 0.8404\n",
      "\t Epoch 3000: train accuracy: 0.8404\n",
      "\t Epoch 3500: train accuracy: 0.8404\n",
      "\t Epoch 4000: train accuracy: 0.8404\n",
      "\t Epoch 4500: train accuracy: 0.8404\n",
      "\t Epoch 5000: train accuracy: 0.8404\n",
      "\t Model's accuracy: 0.8427\n",
      "\t Class 1 - Global explanation: \"\" - Accuracy: 0.0000\n",
      "\t Elapsed time 0.0015027523040771484\n",
      "\t Fidelity: \"0.6742\" - Complexity: \"6\"\n",
      "Split [6/10]\n",
      "\t Epoch 0: train accuracy: 0.1596\n",
      "\t Epoch 500: train accuracy: 0.8404\n",
      "\t Epoch 1000: train accuracy: 0.8404\n",
      "\t Epoch 1500: train accuracy: 0.8404\n",
      "\t Epoch 2000: train accuracy: 0.8404\n",
      "\t Epoch 2500: train accuracy: 0.8404\n",
      "\t Epoch 3000: train accuracy: 0.8404\n",
      "\t Epoch 3500: train accuracy: 0.8404\n",
      "\t Epoch 4000: train accuracy: 0.8867\n",
      "\t Epoch 4500: train accuracy: 0.8949\n",
      "\t Epoch 5000: train accuracy: 0.8999\n",
      "\t Model's accuracy: 0.8596\n",
      "\t Class 1 - Global explanation: \"~stroke_flg | ~sofa_first_LOW | (bun_first_LOW & ~sapsi_first_LOW & ~weight_first_NORMAL)\" - Accuracy: 0.1685\n",
      "\t Elapsed time 0.09474658966064453\n",
      "\t Fidelity: \"0.1404\" - Complexity: \"5\"\n",
      "Split [7/10]\n",
      "\t Epoch 0: train accuracy: 0.1595\n",
      "\t Epoch 500: train accuracy: 0.8405\n",
      "\t Epoch 1000: train accuracy: 0.8405\n",
      "\t Epoch 1500: train accuracy: 0.8405\n",
      "\t Epoch 2000: train accuracy: 0.8405\n",
      "\t Epoch 2500: train accuracy: 0.8405\n",
      "\t Epoch 3000: train accuracy: 0.8405\n",
      "\t Epoch 3500: train accuracy: 0.8405\n",
      "\t Epoch 4000: train accuracy: 0.8405\n",
      "\t Epoch 4500: train accuracy: 0.8405\n",
      "\t Epoch 5000: train accuracy: 0.8405\n",
      "\t Model's accuracy: 0.8418\n",
      "\t Class 1 - Global explanation: \"\" - Accuracy: 0.0000\n",
      "\t Elapsed time 0.0019948482513427734\n",
      "\t Fidelity: \"0.1404\" - Complexity: \"5\"\n",
      "Split [8/10]\n",
      "\t Epoch 0: train accuracy: 0.1595\n",
      "\t Epoch 500: train accuracy: 0.8405\n",
      "\t Epoch 1000: train accuracy: 0.8405\n",
      "\t Epoch 1500: train accuracy: 0.8405\n",
      "\t Epoch 2000: train accuracy: 0.8405\n",
      "\t Epoch 2500: train accuracy: 0.8405\n",
      "\t Epoch 3000: train accuracy: 0.8405\n",
      "\t Epoch 3500: train accuracy: 0.8405\n",
      "\t Epoch 4000: train accuracy: 0.8405\n",
      "\t Epoch 4500: train accuracy: 0.8487\n",
      "\t Epoch 5000: train accuracy: 0.8799\n",
      "\t Model's accuracy: 0.8814\n",
      "\t Class 1 - Global explanation: \"age_HIGH | (stroke_flg & hgb_first_HIGH & sofa_first_NORMAL & ~age_NORMAL & ~hgb_first_NORMAL & ~hr_1st_LOW & ~icu_los_day_NORMAL)\" - Accuracy: 0.7740\n",
      "\t Elapsed time 0.7427308559417725\n",
      "\t Fidelity: \"0.7797\" - Complexity: \"8\"\n",
      "Split [9/10]\n",
      "\t Epoch 0: train accuracy: 0.1595\n",
      "\t Epoch 500: train accuracy: 0.8405\n",
      "\t Epoch 1000: train accuracy: 0.8405\n",
      "\t Epoch 1500: train accuracy: 0.8405\n",
      "\t Epoch 2000: train accuracy: 0.8405\n",
      "\t Epoch 2500: train accuracy: 0.8405\n",
      "\t Epoch 3000: train accuracy: 0.8405\n",
      "\t Epoch 3500: train accuracy: 0.8405\n",
      "\t Epoch 4000: train accuracy: 0.8893\n",
      "\t Epoch 4500: train accuracy: 0.8949\n",
      "\t Epoch 5000: train accuracy: 0.8974\n",
      "\t Model's accuracy: 0.8418\n",
      "\t Class 1 - Global explanation: \"(bun_first_LOW & sofa_first_NORMAL) | (hour_icu_intime_LOW & sofa_first_NORMAL) | (age_HIGH & ~stroke_flg)\" - Accuracy: 0.4633\n",
      "\t Elapsed time 0.14229702949523926\n",
      "\t Fidelity: \"0.4407\" - Complexity: \"6\"\n",
      "Split [10/10]\n",
      "\t Epoch 0: train accuracy: 0.1595\n",
      "\t Epoch 500: train accuracy: 0.8405\n",
      "\t Epoch 1000: train accuracy: 0.8405\n",
      "\t Epoch 1500: train accuracy: 0.8405\n",
      "\t Epoch 2000: train accuracy: 0.8405\n",
      "\t Epoch 2500: train accuracy: 0.8405\n",
      "\t Epoch 3000: train accuracy: 0.8405\n",
      "\t Epoch 3500: train accuracy: 0.8737\n",
      "\t Epoch 4000: train accuracy: 0.8843\n",
      "\t Epoch 4500: train accuracy: 0.8887\n",
      "\t Epoch 5000: train accuracy: 0.8918\n",
      "\t Model's accuracy: 0.8757\n",
      "\t Class 1 - Global explanation: \"bun_first_LOW | ~stroke_flg\" - Accuracy: 0.1582\n",
      "\t Elapsed time 0.22486662864685059\n",
      "\t Fidelity: \"0.1130\" - Complexity: \"2\"\n",
      "Consistency of explanations: 0.1944\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_fidelity</th>\n",
       "      <th>explanation_complexity</th>\n",
       "      <th>explanation_consistency</th>\n",
       "      <th>elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weights</td>\n",
       "      <td>0</td>\n",
       "      <td>(tco2_first_NORMAL &amp; ~renal_flg) | (age_HIGH &amp;...</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.348315</td>\n",
       "      <td>0.275281</td>\n",
       "      <td>5</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.250987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weights</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.275281</td>\n",
       "      <td>5</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.001992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weights</td>\n",
       "      <td>2</td>\n",
       "      <td>age_HIGH | (bun_first_LOW &amp; ~mal_flg &amp; ~age_LO...</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.657303</td>\n",
       "      <td>0.674157</td>\n",
       "      <td>6</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.279933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weights</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.674157</td>\n",
       "      <td>6</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.001995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weights</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.674157</td>\n",
       "      <td>6</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.001503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weights</td>\n",
       "      <td>5</td>\n",
       "      <td>~stroke_flg | ~sofa_first_LOW | (bun_first_LOW...</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.168539</td>\n",
       "      <td>0.140449</td>\n",
       "      <td>5</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.094747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weights</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140449</td>\n",
       "      <td>5</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.001995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weights</td>\n",
       "      <td>7</td>\n",
       "      <td>age_HIGH | (stroke_flg &amp; hgb_first_HIGH &amp; sofa...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.774011</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>8</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.742731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weights</td>\n",
       "      <td>8</td>\n",
       "      <td>(bun_first_LOW &amp; sofa_first_NORMAL) | (hour_ic...</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.463277</td>\n",
       "      <td>0.440678</td>\n",
       "      <td>6</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.142297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>weights</td>\n",
       "      <td>9</td>\n",
       "      <td>bun_first_LOW | ~stroke_flg</td>\n",
       "      <td>0.875706</td>\n",
       "      <td>0.158192</td>\n",
       "      <td>0.112994</td>\n",
       "      <td>2</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.224867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    method  split                                        explanation  \\\n",
       "0  weights      0  (tco2_first_NORMAL & ~renal_flg) | (age_HIGH &...   \n",
       "1  weights      1                                                      \n",
       "2  weights      2  age_HIGH | (bun_first_LOW & ~mal_flg & ~age_LO...   \n",
       "3  weights      3                                                      \n",
       "4  weights      4                                                      \n",
       "5  weights      5  ~stroke_flg | ~sofa_first_LOW | (bun_first_LOW...   \n",
       "6  weights      6                                                      \n",
       "7  weights      7  age_HIGH | (stroke_flg & hgb_first_HIGH & sofa...   \n",
       "8  weights      8  (bun_first_LOW & sofa_first_NORMAL) | (hour_ic...   \n",
       "9  weights      9                        bun_first_LOW | ~stroke_flg   \n",
       "\n",
       "   model_accuracy  explanation_accuracy  explanation_fidelity  \\\n",
       "0        0.859551              0.348315              0.275281   \n",
       "1        0.837079              0.000000              0.275281   \n",
       "2        0.859551              0.657303              0.674157   \n",
       "3        0.842697              0.000000              0.674157   \n",
       "4        0.842697              0.000000              0.674157   \n",
       "5        0.859551              0.168539              0.140449   \n",
       "6        0.841808              0.000000              0.140449   \n",
       "7        0.881356              0.774011              0.779661   \n",
       "8        0.841808              0.463277              0.440678   \n",
       "9        0.875706              0.158192              0.112994   \n",
       "\n",
       "   explanation_complexity  explanation_consistency  elapsed_time  \n",
       "0                       5                 0.194444      0.250987  \n",
       "1                       5                 0.194444      0.001992  \n",
       "2                       6                 0.194444      0.279933  \n",
       "3                       6                 0.194444      0.001995  \n",
       "4                       6                 0.194444      0.001503  \n",
       "5                       5                 0.194444      0.094747  \n",
       "6                       5                 0.194444      0.001995  \n",
       "7                       8                 0.194444      0.742731  \n",
       "8                       6                 0.194444      0.142297  \n",
       "9                       2                 0.194444      0.224867  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = 'weights'\n",
    "need_pruning = False\n",
    "relu = True\n",
    "results_weights = c_to_y(method, need_pruning, 0.008, lr=0.0005, relu=relu, verbose=True)\n",
    "results_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-beijing",
   "metadata": {},
   "source": [
    "# Psi network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "split-forestry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split [1/10]\n",
      "Split [2/10]\n",
      "Split [3/10]\n",
      "Split [4/10]\n",
      "Split [5/10]\n",
      "Split [6/10]\n",
      "Split [7/10]\n",
      "Split [8/10]\n",
      "Split [9/10]\n",
      "Split [10/10]\n",
      "Consistency of explanations: 0.3714\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_fidelity</th>\n",
       "      <th>explanation_complexity</th>\n",
       "      <th>explanation_consistency</th>\n",
       "      <th>elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>psi</td>\n",
       "      <td>0</td>\n",
       "      <td>(stroke_flg | bun_first_NORMAL | sapsi_first_H...</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>3</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.030917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>psi</td>\n",
       "      <td>1</td>\n",
       "      <td>(stroke_flg | abg_count_NORMAL)</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>2</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.026901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>psi</td>\n",
       "      <td>2</td>\n",
       "      <td>(stroke_flg | abg_count_HIGH | sapsi_first_HIGH)</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>3</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.030916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>psi</td>\n",
       "      <td>3</td>\n",
       "      <td>(stroke_flg | sapsi_first_HIGH)</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>2</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.023905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>psi</td>\n",
       "      <td>4</td>\n",
       "      <td>(stroke_flg | bun_first_NORMAL)</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>2</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.025898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>psi</td>\n",
       "      <td>5</td>\n",
       "      <td>(stroke_flg | bun_first_HIGH | chloride_first_...</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>3</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.031914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>psi</td>\n",
       "      <td>6</td>\n",
       "      <td>(stroke_flg | bun_first_HIGH | chloride_first_...</td>\n",
       "      <td>0.836158</td>\n",
       "      <td>0.790960</td>\n",
       "      <td>0.819209</td>\n",
       "      <td>3</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.029914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>psi</td>\n",
       "      <td>7</td>\n",
       "      <td>(stroke_flg | bun_first_NORMAL | bun_first_HIGH)</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>3</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.048869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>psi</td>\n",
       "      <td>8</td>\n",
       "      <td>(stroke_flg | bun_first_NORMAL)</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.807910</td>\n",
       "      <td>0.819209</td>\n",
       "      <td>2</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.027926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>psi</td>\n",
       "      <td>9</td>\n",
       "      <td>(stroke_flg | chloride_first_HIGH | sapsi_firs...</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>3</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.040890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  split                                        explanation  \\\n",
       "0    psi      0  (stroke_flg | bun_first_NORMAL | sapsi_first_H...   \n",
       "1    psi      1                    (stroke_flg | abg_count_NORMAL)   \n",
       "2    psi      2   (stroke_flg | abg_count_HIGH | sapsi_first_HIGH)   \n",
       "3    psi      3                    (stroke_flg | sapsi_first_HIGH)   \n",
       "4    psi      4                    (stroke_flg | bun_first_NORMAL)   \n",
       "5    psi      5  (stroke_flg | bun_first_HIGH | chloride_first_...   \n",
       "6    psi      6  (stroke_flg | bun_first_HIGH | chloride_first_...   \n",
       "7    psi      7   (stroke_flg | bun_first_NORMAL | bun_first_HIGH)   \n",
       "8    psi      8                    (stroke_flg | bun_first_NORMAL)   \n",
       "9    psi      9  (stroke_flg | chloride_first_HIGH | sapsi_firs...   \n",
       "\n",
       "   model_accuracy  explanation_accuracy  explanation_fidelity  \\\n",
       "0        0.837079              0.831461              0.848315   \n",
       "1        0.837079              0.814607              0.853933   \n",
       "2        0.837079              0.842697              0.837079   \n",
       "3        0.842697              0.842697              0.876404   \n",
       "4        0.842697              0.831461              0.842697   \n",
       "5        0.842697              0.814607              0.825843   \n",
       "6        0.836158              0.790960              0.819209   \n",
       "7        0.841808              0.847458              0.870056   \n",
       "8        0.841808              0.807910              0.819209   \n",
       "9        0.841808              0.858757              0.870056   \n",
       "\n",
       "   explanation_complexity  explanation_consistency  elapsed_time  \n",
       "0                       3                 0.371429      0.030917  \n",
       "1                       2                 0.371429      0.026901  \n",
       "2                       3                 0.371429      0.030916  \n",
       "3                       2                 0.371429      0.023905  \n",
       "4                       2                 0.371429      0.025898  \n",
       "5                       3                 0.371429      0.031914  \n",
       "6                       3                 0.371429      0.029914  \n",
       "7                       3                 0.371429      0.048869  \n",
       "8                       2                 0.371429      0.027926  \n",
       "9                       3                 0.371429      0.040890  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = 'psi'\n",
    "need_pruning = True\n",
    "relu = False\n",
    "results_psi = c_to_y(method, need_pruning, relu, verbose=False)\n",
    "results_psi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-powell",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "driven-archives",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split [1/10]\n",
      "Split [2/10]\n",
      "Split [3/10]\n",
      "Split [4/10]\n",
      "Split [5/10]\n",
      "Split [6/10]\n",
      "Split [7/10]\n",
      "Split [8/10]\n",
      "Split [9/10]\n",
      "Split [10/10]\n",
      "Consistency of explanations: 0.8150\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_fidelity</th>\n",
       "      <th>explanation_complexity</th>\n",
       "      <th>explanation_consistency</th>\n",
       "      <th>elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tree</td>\n",
       "      <td>0</td>\n",
       "      <td>(stroke_flg &lt;= 0.50 &amp; age_HIGH &lt;= 0.50 &amp; resp_...</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1363</td>\n",
       "      <td>0.815033</td>\n",
       "      <td>0.002984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>(stroke_flg &lt;= 0.50 &amp; age_HIGH &lt;= 0.50 &amp; sapsi...</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1424</td>\n",
       "      <td>0.815033</td>\n",
       "      <td>0.002992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>(age_HIGH &lt;= 0.50 &amp; stroke_flg &lt;= 0.50 &amp; age_N...</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1345</td>\n",
       "      <td>0.815033</td>\n",
       "      <td>0.002992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>(age_HIGH &lt;= 0.50 &amp; stroke_flg &lt;= 0.50 &amp; age_N...</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1391</td>\n",
       "      <td>0.815033</td>\n",
       "      <td>0.002992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>(age_HIGH &lt;= 0.50 &amp; stroke_flg &lt;= 0.50 &amp; sapsi...</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1387</td>\n",
       "      <td>0.815033</td>\n",
       "      <td>0.003986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>(age_HIGH &lt;= 0.50 &amp; stroke_flg &lt;= 0.50 &amp; resp_...</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1319</td>\n",
       "      <td>0.815033</td>\n",
       "      <td>0.003986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tree</td>\n",
       "      <td>6</td>\n",
       "      <td>(age_HIGH &lt;= 0.50 &amp; stroke_flg &lt;= 0.50 &amp; resp_...</td>\n",
       "      <td>0.762712</td>\n",
       "      <td>0.762712</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1271</td>\n",
       "      <td>0.815033</td>\n",
       "      <td>0.002988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tree</td>\n",
       "      <td>7</td>\n",
       "      <td>(age_HIGH &lt;= 0.50 &amp; stroke_flg &lt;= 0.50 &amp; resp_...</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1321</td>\n",
       "      <td>0.815033</td>\n",
       "      <td>0.004001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tree</td>\n",
       "      <td>8</td>\n",
       "      <td>(age_HIGH &lt;= 0.50 &amp; stroke_flg &lt;= 0.50 &amp; resp_...</td>\n",
       "      <td>0.774011</td>\n",
       "      <td>0.774011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1353</td>\n",
       "      <td>0.815033</td>\n",
       "      <td>0.003003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tree</td>\n",
       "      <td>9</td>\n",
       "      <td>(age_HIGH &lt;= 0.50 &amp; stroke_flg &lt;= 0.50 &amp; sapsi...</td>\n",
       "      <td>0.774011</td>\n",
       "      <td>0.774011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1252</td>\n",
       "      <td>0.815033</td>\n",
       "      <td>0.004003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  split                                        explanation  \\\n",
       "0   tree      0  (stroke_flg <= 0.50 & age_HIGH <= 0.50 & resp_...   \n",
       "1   tree      1  (stroke_flg <= 0.50 & age_HIGH <= 0.50 & sapsi...   \n",
       "2   tree      2  (age_HIGH <= 0.50 & stroke_flg <= 0.50 & age_N...   \n",
       "3   tree      3  (age_HIGH <= 0.50 & stroke_flg <= 0.50 & age_N...   \n",
       "4   tree      4  (age_HIGH <= 0.50 & stroke_flg <= 0.50 & sapsi...   \n",
       "5   tree      5  (age_HIGH <= 0.50 & stroke_flg <= 0.50 & resp_...   \n",
       "6   tree      6  (age_HIGH <= 0.50 & stroke_flg <= 0.50 & resp_...   \n",
       "7   tree      7  (age_HIGH <= 0.50 & stroke_flg <= 0.50 & resp_...   \n",
       "8   tree      8  (age_HIGH <= 0.50 & stroke_flg <= 0.50 & resp_...   \n",
       "9   tree      9  (age_HIGH <= 0.50 & stroke_flg <= 0.50 & sapsi...   \n",
       "\n",
       "   model_accuracy  explanation_accuracy  explanation_fidelity  \\\n",
       "0        0.803371              0.803371                   1.0   \n",
       "1        0.803371              0.803371                   1.0   \n",
       "2        0.808989              0.808989                   1.0   \n",
       "3        0.780899              0.780899                   1.0   \n",
       "4        0.786517              0.786517                   1.0   \n",
       "5        0.848315              0.848315                   1.0   \n",
       "6        0.762712              0.762712                   1.0   \n",
       "7        0.813559              0.813559                   1.0   \n",
       "8        0.774011              0.774011                   1.0   \n",
       "9        0.774011              0.774011                   1.0   \n",
       "\n",
       "   explanation_complexity  explanation_consistency  elapsed_time  \n",
       "0                    1363                 0.815033      0.002984  \n",
       "1                    1424                 0.815033      0.002992  \n",
       "2                    1345                 0.815033      0.002992  \n",
       "3                    1391                 0.815033      0.002992  \n",
       "4                    1387                 0.815033      0.003986  \n",
       "5                    1319                 0.815033      0.003986  \n",
       "6                    1271                 0.815033      0.002988  \n",
       "7                    1321                 0.815033      0.004001  \n",
       "8                    1353                 0.815033      0.003003  \n",
       "9                    1252                 0.815033      0.004003  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = 'tree'\n",
    "need_pruning = False\n",
    "relu = False\n",
    "results_tree = c_to_y(method, need_pruning, relu)\n",
    "results_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-spray",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "random-margin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_accuracy_mean</th>\n",
       "      <th>explanation_accuracy_mean</th>\n",
       "      <th>explanation_fidelity_mean</th>\n",
       "      <th>explanation_complexity_mean</th>\n",
       "      <th>elapsed_time_mean</th>\n",
       "      <th>explanation_consistency_mean</th>\n",
       "      <th>model_accuracy_sem</th>\n",
       "      <th>explanation_accuracy_sem</th>\n",
       "      <th>explanation_fidelity_sem</th>\n",
       "      <th>explanation_complexity_sem</th>\n",
       "      <th>elapsed_time_sem</th>\n",
       "      <th>explanation_consistency_sem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pruning</th>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.854164</td>\n",
       "      <td>0.997750</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.065522</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.004556</td>\n",
       "      <td>0.005011</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>0.895048</td>\n",
       "      <td>0.007483</td>\n",
       "      <td>1.850372e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weights</th>\n",
       "      <td>0.854180</td>\n",
       "      <td>0.256964</td>\n",
       "      <td>0.418727</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.174305</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.004888</td>\n",
       "      <td>0.091907</td>\n",
       "      <td>0.082731</td>\n",
       "      <td>0.476095</td>\n",
       "      <td>0.072187</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psi</th>\n",
       "      <td>0.840091</td>\n",
       "      <td>0.828261</td>\n",
       "      <td>0.846280</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.031805</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.006595</td>\n",
       "      <td>0.006734</td>\n",
       "      <td>0.163299</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>0.795575</td>\n",
       "      <td>0.795575</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1342.6</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>0.815033</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.940550</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>3.700743e-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model_accuracy_mean  explanation_accuracy_mean  \\\n",
       "pruning             0.854167                   0.854164   \n",
       "weights             0.854180                   0.256964   \n",
       "psi                 0.840091                   0.828261   \n",
       "tree                0.795575                   0.795575   \n",
       "\n",
       "         explanation_fidelity_mean  explanation_complexity_mean  \\\n",
       "pruning                   0.997750                          4.3   \n",
       "weights                   0.418727                          5.4   \n",
       "psi                       0.846280                          2.6   \n",
       "tree                      1.000000                       1342.6   \n",
       "\n",
       "         elapsed_time_mean  explanation_consistency_mean  model_accuracy_sem  \\\n",
       "pruning           0.065522                      0.322222            0.004556   \n",
       "weights           0.174305                      0.194444            0.004888   \n",
       "psi               0.031805                      0.371429            0.000894   \n",
       "tree              0.003393                      0.815033            0.007968   \n",
       "\n",
       "         explanation_accuracy_sem  explanation_fidelity_sem  \\\n",
       "pruning                  0.005011                  0.001243   \n",
       "weights                  0.091907                  0.082731   \n",
       "psi                      0.006595                  0.006734   \n",
       "tree                     0.007968                  0.000000   \n",
       "\n",
       "         explanation_complexity_sem  elapsed_time_sem  \\\n",
       "pruning                    0.895048          0.007483   \n",
       "weights                    0.476095          0.072187   \n",
       "psi                        0.163299          0.002393   \n",
       "tree                      16.940550          0.000164   \n",
       "\n",
       "         explanation_consistency_sem  \n",
       "pruning                 1.850372e-17  \n",
       "weights                 0.000000e+00  \n",
       "psi                     0.000000e+00  \n",
       "tree                    3.700743e-17  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['model_accuracy', 'explanation_accuracy', 'explanation_fidelity', \n",
    "        'explanation_complexity', 'elapsed_time', 'explanation_consistency']\n",
    "mean_cols = [f'{c}_mean' for c in cols]\n",
    "sem_cols = [f'{c}_sem' for c in cols]\n",
    "\n",
    "# pruning\n",
    "df_mean = results_pruning[cols].mean()\n",
    "df_sem = results_pruning[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_pruning = pd.concat([df_mean, df_sem])\n",
    "summary_pruning.name = 'pruning'\n",
    "\n",
    "# # lime\n",
    "# df_mean = results_lime[cols].mean()\n",
    "# df_sem = results_lime[cols].sem()\n",
    "# df_mean.columns = mean_cols\n",
    "# df_sem.columns = sem_cols\n",
    "# summary_lime = pd.concat([df_mean, df_sem])\n",
    "# summary_lime.name = 'lime'\n",
    "\n",
    "# weights\n",
    "df_mean = results_weights[cols].mean()\n",
    "df_sem = results_weights[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_weights = pd.concat([df_mean, df_sem])\n",
    "summary_weights.name = 'weights'\n",
    "\n",
    "# psi\n",
    "df_mean = results_psi[cols].mean()\n",
    "df_sem = results_psi[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_psi = pd.concat([df_mean, df_sem])\n",
    "summary_psi.name = 'psi'\n",
    "\n",
    "# tree\n",
    "df_mean = results_tree[cols].mean()\n",
    "df_sem = results_tree[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_tree = pd.concat([df_mean, df_sem])\n",
    "summary_tree.name = 'tree'\n",
    "\n",
    "summary = pd.concat([summary_pruning, \n",
    "#                      summary_lime, \n",
    "                     summary_weights, \n",
    "                     summary_psi, \n",
    "                     summary_tree], axis=1).T\n",
    "summary.columns = mean_cols + sem_cols\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "smooth-alpha",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_csv(os.path.join(results_dir, 'summary.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
