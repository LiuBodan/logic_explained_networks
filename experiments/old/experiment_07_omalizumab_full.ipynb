{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sympy import simplify_logic\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.tree import _tree, export_text\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from lens.utils.base import validate_network, set_seed, tree_to_formula\n",
    "from lens.utils.relunn import get_reduced_model, prune_features\n",
    "from lens.utils.sigmoidnn import prune_equal_fanin\n",
    "from lens import logic\n",
    "\n",
    "results_dir = 'results/omalizumab_full'\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "n_rep = 10\n",
    "tot_epochs = 6001\n",
    "prune_epochs = 3001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>28392</th>\n",
       "      <th>28393</th>\n",
       "      <th>28394</th>\n",
       "      <th>28395</th>\n",
       "      <th>28396</th>\n",
       "      <th>28397</th>\n",
       "      <th>28398</th>\n",
       "      <th>28399</th>\n",
       "      <th>28400</th>\n",
       "      <th>28401</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.622486</td>\n",
       "      <td>11.162004</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>12.788433</td>\n",
       "      <td>6.143456</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.876620</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.885589</td>\n",
       "      <td>3.914260</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.465420</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.973620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.398743</td>\n",
       "      <td>11.000080</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>12.845914</td>\n",
       "      <td>6.147482</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.484223</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.575025</td>\n",
       "      <td>4.236519</td>\n",
       "      <td>4.047825</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.32</td>\n",
       "      <td>4.176269</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.553796</td>\n",
       "      <td>4.967418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.692079</td>\n",
       "      <td>11.100175</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.171535</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>12.712544</td>\n",
       "      <td>5.583210</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.478171</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.992331</td>\n",
       "      <td>4.865538</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.488281</td>\n",
       "      <td>3.406285</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>6.676063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.613382</td>\n",
       "      <td>11.023209</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>12.750496</td>\n",
       "      <td>5.688023</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.464426</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.855643</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.905350</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.32</td>\n",
       "      <td>4.158393</td>\n",
       "      <td>4.433457</td>\n",
       "      <td>3.874214</td>\n",
       "      <td>5.981160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.482065</td>\n",
       "      <td>10.989851</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.992726</td>\n",
       "      <td>4.574745</td>\n",
       "      <td>12.878702</td>\n",
       "      <td>6.195418</td>\n",
       "      <td>4.177962</td>\n",
       "      <td>3.872567</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.879493</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.32</td>\n",
       "      <td>4.571869</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.982136</td>\n",
       "      <td>6.145585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>14.565031</td>\n",
       "      <td>11.699843</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>12.789212</td>\n",
       "      <td>6.504027</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>6.182912</td>\n",
       "      <td>...</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.338456</td>\n",
       "      <td>3.771718</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>6.100644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>14.624502</td>\n",
       "      <td>11.918757</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.292406</td>\n",
       "      <td>3.430485</td>\n",
       "      <td>10.728709</td>\n",
       "      <td>6.197159</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.089918</td>\n",
       "      <td>5.201608</td>\n",
       "      <td>...</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.790134</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.32</td>\n",
       "      <td>4.985474</td>\n",
       "      <td>4.444057</td>\n",
       "      <td>3.580523</td>\n",
       "      <td>6.301926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>14.585190</td>\n",
       "      <td>11.090112</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.674768</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>12.877485</td>\n",
       "      <td>6.326960</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.547342</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.32</td>\n",
       "      <td>4.064473</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.254152</td>\n",
       "      <td>5.964505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>14.449554</td>\n",
       "      <td>10.805855</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>12.660038</td>\n",
       "      <td>6.261395</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.125096</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.784260</td>\n",
       "      <td>3.644823</td>\n",
       "      <td>4.546974</td>\n",
       "      <td>3.427441</td>\n",
       "      <td>3.32</td>\n",
       "      <td>4.666265</td>\n",
       "      <td>3.888525</td>\n",
       "      <td>3.765754</td>\n",
       "      <td>5.452018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>14.439020</td>\n",
       "      <td>11.080826</td>\n",
       "      <td>4.152651</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>12.187504</td>\n",
       "      <td>6.154358</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>4.247009</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.671102</td>\n",
       "      <td>3.519157</td>\n",
       "      <td>4.771458</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.32</td>\n",
       "      <td>5.115644</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>3.410361</td>\n",
       "      <td>6.449961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 28402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0          1         2         3         4          5         6      \\\n",
       "0   14.622486  11.162004  3.320000  3.320000  3.320000  12.788433  6.143456   \n",
       "1   14.398743  11.000080  3.320000  3.320000  3.320000  12.845914  6.147482   \n",
       "2   14.692079  11.100175  3.320000  4.171535  3.320000  12.712544  5.583210   \n",
       "3   14.613382  11.023209  3.320000  3.320000  3.320000  12.750496  5.688023   \n",
       "4   14.482065  10.989851  3.320000  3.992726  4.574745  12.878702  6.195418   \n",
       "..        ...        ...       ...       ...       ...        ...       ...   \n",
       "56  14.565031  11.699843  3.320000  3.320000  3.320000  12.789212  6.504027   \n",
       "57  14.624502  11.918757  3.320000  4.292406  3.430485  10.728709  6.197159   \n",
       "58  14.585190  11.090112  3.320000  3.674768  3.320000  12.877485  6.326960   \n",
       "59  14.449554  10.805855  3.320000  3.320000  3.320000  12.660038  6.261395   \n",
       "60  14.439020  11.080826  4.152651  3.320000  3.320000  12.187504  6.154358   \n",
       "\n",
       "       7         8         9      ...  28392     28393     28394     28395  \\\n",
       "0   3.320000  4.876620  3.320000  ...   3.32  3.320000  3.885589  3.914260   \n",
       "1   3.320000  4.484223  3.320000  ...   3.32  3.575025  4.236519  4.047825   \n",
       "2   3.320000  3.478171  3.320000  ...   3.32  3.320000  3.992331  4.865538   \n",
       "3   3.320000  4.464426  3.320000  ...   3.32  3.855643  3.320000  4.905350   \n",
       "4   4.177962  3.872567  3.320000  ...   3.32  3.320000  3.320000  4.879493   \n",
       "..       ...       ...       ...  ...    ...       ...       ...       ...   \n",
       "56  3.320000  3.320000  6.182912  ...   3.32  3.320000  3.320000  4.338456   \n",
       "57  3.320000  4.089918  5.201608  ...   3.32  3.320000  3.320000  4.790134   \n",
       "58  3.320000  3.320000  3.320000  ...   3.32  3.320000  3.320000  4.547342   \n",
       "59  3.320000  4.125096  3.320000  ...   3.32  3.784260  3.644823  4.546974   \n",
       "60  3.320000  4.247009  3.320000  ...   3.32  3.671102  3.519157  4.771458   \n",
       "\n",
       "       28396  28397     28398     28399     28400     28401  \n",
       "0   3.320000   3.32  3.320000  4.465420  3.320000  4.973620  \n",
       "1   3.320000   3.32  4.176269  3.320000  4.553796  4.967418  \n",
       "2   3.320000   3.32  3.488281  3.406285  3.320000  6.676063  \n",
       "3   3.320000   3.32  4.158393  4.433457  3.874214  5.981160  \n",
       "4   3.320000   3.32  4.571869  3.320000  4.982136  6.145585  \n",
       "..       ...    ...       ...       ...       ...       ...  \n",
       "56  3.771718   3.32  3.320000  3.320000  3.320000  6.100644  \n",
       "57  3.320000   3.32  4.985474  4.444057  3.580523  6.301926  \n",
       "58  3.320000   3.32  4.064473  3.320000  4.254152  5.964505  \n",
       "59  3.427441   3.32  4.666265  3.888525  3.765754  5.452018  \n",
       "60  3.320000   3.32  5.115644  3.320000  3.410361  6.449961  \n",
       "\n",
       "[61 rows x 28402 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_expression_matrix = pd.read_csv('data/omalizumab/w_1/data_0.csv', index_col=None, header=None)\n",
    "labels = pd.read_csv('data/omalizumab/w_1/tempLabels_W-1.csv', index_col=None, header=None)\n",
    "genes = pd.read_csv('data/omalizumab/w_1/features_0.csv', index_col=None, header=None)\n",
    "gene_expression_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pietr\\anaconda3\\envs\\deep-logic\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 28402])\n",
      "torch.Size([40])\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "labels_encoded = encoder.fit_transform(labels.values)\n",
    "labels_encoded_noncontrols = labels_encoded[labels_encoded!=0] - 1\n",
    "\n",
    "data_controls = gene_expression_matrix[labels_encoded==0]\n",
    "data = gene_expression_matrix[labels_encoded!=0]\n",
    "\n",
    "gene_signature = data_controls.mean(axis=0)\n",
    "data_scaled = data - gene_signature\n",
    "\n",
    "scaler = MinMaxScaler((0, 1))\n",
    "scaler.fit(data_scaled)\n",
    "data_normalized = scaler.transform(data_scaled)\n",
    "\n",
    "x = torch.FloatTensor(data_normalized)\n",
    "y = torch.LongTensor(labels_encoded_noncontrols)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ILMN_1343291',\n",
       " 'ILMN_1343295',\n",
       " 'ILMN_1651199',\n",
       " 'ILMN_1651209',\n",
       " 'ILMN_1651221',\n",
       " 'ILMN_1651228',\n",
       " 'ILMN_1651229',\n",
       " 'ILMN_1651230',\n",
       " 'ILMN_1651232',\n",
       " 'ILMN_1651237']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concepts = list(genes.values.squeeze())\n",
    "concepts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(x_train, y_train, need_pruning, seed, device, relu=False):\n",
    "    set_seed(seed)\n",
    "    x_train = x_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    layers = [\n",
    "        torch.nn.Linear(x_train.size(1), 50),\n",
    "        torch.nn.ReLU() if relu else torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(50, 20),\n",
    "        torch.nn.ReLU() if relu else torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(20, 5),\n",
    "        torch.nn.ReLU() if relu else torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(5, 2),\n",
    "        torch.nn.Softmax(dim=1),\n",
    "    ]\n",
    "    model = torch.nn.Sequential(*layers).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "    loss_form = torch.nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    for epoch in range(tot_epochs):\n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_train)\n",
    "        # Compute Loss\n",
    "        loss = loss_form(y_pred, y_train)\n",
    "\n",
    "        for module in model.children():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                loss += 0.0001 * torch.norm(module.weight, 1)\n",
    "                loss += 0.0001 * torch.norm(module.bias, 1)\n",
    "                break\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch > prune_epochs and need_pruning and epoch % 1000 == 1:\n",
    "            prune_features(model, n_classes=1, device=device)\n",
    "            need_pruning = True\n",
    "            \n",
    "        # compute accuracy\n",
    "        if epoch % 500 == 0:\n",
    "            y_pred_d = torch.argmax(y_pred, dim=1)\n",
    "            accuracy = y_pred_d.eq(y_train).sum().item() / y_train.size(0)\n",
    "            print(f'\\t Epoch {epoch}: train accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split [1/10]\n",
      "\t Epoch 0: train accuracy: 0.2500\n",
      "\t Epoch 500: train accuracy: 1.0000\n",
      "\t Epoch 1000: train accuracy: 1.0000\n",
      "\t Epoch 1500: train accuracy: 1.0000\n",
      "\t Epoch 2000: train accuracy: 1.0000\n",
      "\t Epoch 2500: train accuracy: 1.0000\n",
      "\t Epoch 3000: train accuracy: 1.0000\n",
      "\t Epoch 3500: train accuracy: 1.0000\n",
      "\t Epoch 4000: train accuracy: 1.0000\n",
      "\t Epoch 4500: train accuracy: 1.0000\n",
      "\t Epoch 5000: train accuracy: 1.0000\n",
      "\t Epoch 5500: train accuracy: 1.0000\n",
      "\t Epoch 6000: train accuracy: 1.0000\n",
      "\t Model's accuracy: 0.7500\n",
      "\t Class 1 - Global explanation: \"(ILMN_1777168 & ILMN_2127722 & ILMN_2293374 & ILMN_3207605 & ILMN_3228700 & ILMN_3237256 & ILMN_3243714 & ILMN_3248786 & ~ILMN_1708983 & ~ILMN_1775520 & ~ILMN_1893728 & ~ILMN_2102422 & ~ILMN_2104929 & ~ILMN_3186853 & ~ILMN_3282496 & ~ILMN_3310514) | (ILMN_1777168 & ILMN_2102422 & ILMN_3243714 & ILMN_3248786 & ILMN_3282496 & ~ILMN_1708983 & ~ILMN_1775520 & ~ILMN_1893728 & ~ILMN_2104929 & ~ILMN_2127722 & ~ILMN_2293374 & ~ILMN_3186853 & ~ILMN_3207605 & ~ILMN_3228700 & ~ILMN_3237256 & ~ILMN_3310514)\" - Accuracy: 0.2500\n",
      "\t Elapsed time 54.590567111968994\n",
      "\t Class 0 - Global explanation: \"(ILMN_1775520 & ILMN_2293374 & ILMN_3248786 & ILMN_3310514 & ~ILMN_1708983 & ~ILMN_1777168 & ~ILMN_1893728 & ~ILMN_2102422 & ~ILMN_2104929 & ~ILMN_2127722 & ~ILMN_3186853 & ~ILMN_3207605 & ~ILMN_3228700 & ~ILMN_3237256 & ~ILMN_3243714 & ~ILMN_3282496) | (ILMN_1893728 & ILMN_3248786 & ILMN_3310514 & ~ILMN_1708983 & ~ILMN_1775520 & ~ILMN_1777168 & ~ILMN_2102422 & ~ILMN_2104929 & ~ILMN_2127722 & ~ILMN_2293374 & ~ILMN_3186853 & ~ILMN_3207605 & ~ILMN_3228700 & ~ILMN_3237256 & ~ILMN_3243714 & ~ILMN_3282496)\" - Accuracy: 0.7500\n",
      "\t Elapsed time 52.65466928482056\n",
      "Split [2/10]\n",
      "\t Epoch 0: train accuracy: 0.2500\n",
      "\t Epoch 500: train accuracy: 0.2500\n",
      "\t Epoch 1000: train accuracy: 0.7500\n",
      "\t Epoch 1500: train accuracy: 0.7500\n",
      "\t Epoch 2000: train accuracy: 0.7500\n",
      "\t Epoch 2500: train accuracy: 0.9722\n",
      "\t Epoch 3000: train accuracy: 0.9722\n",
      "\t Epoch 3500: train accuracy: 1.0000\n",
      "\t Epoch 4000: train accuracy: 1.0000\n",
      "\t Epoch 4500: train accuracy: 0.9722\n",
      "\t Epoch 5000: train accuracy: 1.0000\n",
      "\t Epoch 5500: train accuracy: 1.0000\n",
      "\t Epoch 6000: train accuracy: 1.0000\n",
      "\t Model's accuracy: 0.7500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-34194ae958df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mtarget_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     global_explanation, _, counter = logic.relunn.combine_local_explanations(model, \n\u001b[0m\u001b[0;32m     30\u001b[0m                                                                        \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                                                                        \u001b[0mtarget_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_class\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Mega\\research\\coding\\neural_networks\\deep-logic\\deep_logic\\logic\\relunn.py\u001b[0m in \u001b[0;36mcombine_local_explanations\u001b[1;34m(model, x, y, target_class, method, simplify, topk_explanations, concept_names, device)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;31m# the global explanation is the disjunction of local explanations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[0mglobal_explanation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' | '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmost_common_explanations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m     \u001b[0mglobal_explanation_simplified\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msimplify_logic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobal_explanation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'dnf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m     \u001b[0mglobal_explanation_simplified_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobal_explanation_simplified\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pietr\\anaconda3\\envs\\deep-logic\\lib\\site-packages\\sympy\\logic\\boolalg.py\u001b[0m in \u001b[0;36msimplify_logic\u001b[1;34m(expr, form, deep, force)\u001b[0m\n\u001b[0;32m   2820\u001b[0m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2821\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mproduct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2822\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mexpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2823\u001b[0m             \u001b[0mtruthtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2824\u001b[0m     \u001b[0mbig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruthtable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pietr\\anaconda3\\envs\\deep-logic\\lib\\site-packages\\sympy\\core\\basic.py\u001b[0m in \u001b[0;36mxreplace\u001b[1;34m(self, rule)\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m         \"\"\"\n\u001b[1;32m-> 1138\u001b[1;33m         \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1139\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pietr\\anaconda3\\envs\\deep-logic\\lib\\site-packages\\sympy\\core\\basic.py\u001b[0m in \u001b[0;36m_xreplace\u001b[1;34m(self, rule)\u001b[0m\n\u001b[0;32m   1151\u001b[0m                 \u001b[0m_xreplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_xreplace'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0m_xreplace\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1153\u001b[1;33m                     \u001b[0ma_xr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_xreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1154\u001b[0m                     \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_xr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m                     \u001b[0mchanged\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0ma_xr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pietr\\anaconda3\\envs\\deep-logic\\lib\\site-packages\\sympy\\core\\basic.py\u001b[0m in \u001b[0;36m_xreplace\u001b[1;34m(self, rule)\u001b[0m\n\u001b[0;32m   1158\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mchanged\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1160\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1161\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pietr\\anaconda3\\envs\\deep-logic\\lib\\site-packages\\sympy\\core\\operations.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, *args, **options)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[1;31m# is done so short-circuiting can be done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m             \u001b[1;31m# without having to sympify all values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0m_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_args_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mShortCircuit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msympify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pietr\\anaconda3\\envs\\deep-logic\\lib\\site-packages\\sympy\\logic\\boolalg.py\u001b[0m in \u001b[0;36m_new_args_filter\u001b[1;34m(cls, args)\u001b[0m\n\u001b[0;32m    679\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_new_args_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBooleanFunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_check_and_simplify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLatticeOp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_args_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAnd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m         \u001b[0mnewargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pietr\\anaconda3\\envs\\deep-logic\\lib\\site-packages\\sympy\\logic\\boolalg.py\u001b[0m in \u001b[0;36mbinary_check_and_simplify\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    470\u001b[0m                             \u001b[0mreal\u001b[0m \u001b[0mvariable\u001b[0m \u001b[1;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0ms\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m                             ''' % (x, r)))\n\u001b[1;32m--> 472\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_nnf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimplify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pietr\\anaconda3\\envs\\deep-logic\\lib\\site-packages\\sympy\\logic\\boolalg.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    470\u001b[0m                             \u001b[0mreal\u001b[0m \u001b[0mvariable\u001b[0m \u001b[1;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0ms\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m                             ''' % (x, r)))\n\u001b[1;32m--> 472\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_nnf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimplify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pietr\\anaconda3\\envs\\deep-logic\\lib\\site-packages\\sympy\\core\\basic.py\u001b[0m in \u001b[0;36msubs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m         \"\"\"\n\u001b[1;32m--> 873\u001b[1;33m         \u001b[1;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompatibility\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_sort_key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    874\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontainers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymbol\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDummy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSymbol\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "need_pruning = True\n",
    "method = 'pruning'\n",
    "methods = []\n",
    "splits = []\n",
    "explanations = []\n",
    "explanations_inv = []\n",
    "model_accuracies = []\n",
    "explanation_accuracies = []\n",
    "explanation_accuracies_inv = []\n",
    "elapsed_times = []\n",
    "elapsed_times_inv = []\n",
    "\n",
    "for split, (train_index, test_index) in enumerate(skf.split(x.cpu().detach().numpy(), y.cpu().detach().numpy())):\n",
    "    print(f'Split [{split+1}/{n_splits}]')\n",
    "    x_train, x_test = torch.FloatTensor(x[train_index]), torch.FloatTensor(x[test_index])\n",
    "    y_train, y_test = torch.LongTensor(y[train_index]), torch.LongTensor(y[test_index])\n",
    "    \n",
    "#     if split not in [5]: continue\n",
    "    \n",
    "    model = train_nn(x_train, y_train, need_pruning, split, device)\n",
    "    \n",
    "    y_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "    model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds.argmax(axis=1))\n",
    "    print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "    \n",
    "    # positive class\n",
    "    target_class = 1\n",
    "    start = time.time()\n",
    "    global_explanation, _, counter = logic.relunn.combine_local_explanations(model, \n",
    "                                                                       x_train.to(device), y_train.to(device), \n",
    "                                                                       target_class=target_class,\n",
    "                                                                       topk_explanations=2,\n",
    "                                                                       method=method, device=device)\n",
    "    elapsed_time = time.time() - start\n",
    "    if global_explanation:\n",
    "        explanation_accuracy, _ = logic.base.test_explanation(global_explanation, target_class, x_test, y_test)\n",
    "        explanation = logic.base.replace_names(global_explanation, concepts)\n",
    "    print(f'\\t Class {target_class} - Global explanation: \"{explanation}\" - Accuracy: {explanation_accuracy:.4f}')\n",
    "    print(f'\\t Elapsed time {elapsed_time}')\n",
    "        \n",
    "    # negative class\n",
    "    target_class = 0\n",
    "    start = time.time()\n",
    "    global_explanation_inv, _, counter_inv = logic.relunn.combine_local_explanations(model, \n",
    "                                                                           x_train.to(device), y_train.to(device), \n",
    "                                                                           target_class=target_class,\n",
    "                                                                           topk_explanations=2,\n",
    "                                                                           method=method, device=device)\n",
    "    elapsed_time_inv = time.time() - start\n",
    "    if global_explanation_inv:\n",
    "        explanation_accuracy_inv, _ = logic.base.test_explanation(global_explanation_inv, target_class, x_test, y_test)\n",
    "        explanation_inv = logic.base.replace_names(global_explanation_inv, concepts)\n",
    "    print(f'\\t Class {target_class} - Global explanation: \"{explanation_inv}\" - Accuracy: {explanation_accuracy_inv:.4f}')\n",
    "    print(f'\\t Elapsed time {elapsed_time_inv}')\n",
    "    \n",
    "    methods.append(method)\n",
    "    splits.append(split)\n",
    "    explanations.append(explanation)\n",
    "    explanations_inv.append(explanation_inv)\n",
    "    model_accuracies.append(model_accuracy)\n",
    "    explanation_accuracies.append(explanation_accuracy)\n",
    "    explanation_accuracies_inv.append(explanation_accuracy_inv)\n",
    "    elapsed_times.append(elapsed_time)\n",
    "    elapsed_times_inv.append(elapsed_time_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pruning = pd.DataFrame({\n",
    "    'method': methods,\n",
    "    'split': splits,\n",
    "    'explanation': explanations,\n",
    "    'explanation_inv': explanations_inv,\n",
    "    'model_accuracy': model_accuracies,\n",
    "    'explanation_accuracy': explanation_accuracies,\n",
    "    'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "    'elapsed_time': elapsed_times,\n",
    "    'elapsed_time_inv': elapsed_times_inv,\n",
    "})\n",
    "results_pruning.to_csv(os.path.join(results_dir, 'results_pruning.csv'))\n",
    "results_pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "need_pruning = False\n",
    "method = 'lime'\n",
    "methods = []\n",
    "splits = []\n",
    "explanations = []\n",
    "explanations_inv = []\n",
    "model_accuracies = []\n",
    "explanation_accuracies = []\n",
    "explanation_accuracies_inv = []\n",
    "elapsed_times = []\n",
    "elapsed_times_inv = []\n",
    "for seed in range(n_rep):\n",
    "    print(f'Seed [{seed+1}/{n_rep}]')\n",
    "    \n",
    "    model = train_nn(x_train, y_train, need_pruning, seed, device)\n",
    "    \n",
    "    y_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "    model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds.argmax(axis=1))\n",
    "    print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "    \n",
    "    # positive class\n",
    "    target_class = 1\n",
    "    start = time.time()\n",
    "    global_explanation, _, _ = logic.relunn.combine_local_explanations(model, \n",
    "                                                                       x_train.to(device), y_train.to(device),\n",
    "                                                                       topk_explanations=2,\n",
    "                                                                       target_class=target_class,\n",
    "                                                                       method=method, device=device)\n",
    "    elapsed_time = time.time() - start\n",
    "    if global_explanation:\n",
    "        explanation_accuracy, _ = logic.base.test_explanation(global_explanation, target_class, x_test, y_test)\n",
    "        explanation = logic.base.replace_names(global_explanation, concepts)\n",
    "    print(f'\\t Class {target_class} - Global explanation: \"{explanation}\" - Accuracy: {explanation_accuracy:.4f}')\n",
    "    print(f'\\t Elapsed time {elapsed_time}')\n",
    "        \n",
    "    # negative class\n",
    "    target_class = 0\n",
    "    start = time.time()\n",
    "    global_explanation_inv, _, _ = logic.relunn.combine_local_explanations(model, \n",
    "                                                                           x_train.to(device), y_train.to(device), \n",
    "                                                                           topk_explanations=2,\n",
    "                                                                           target_class=target_class,\n",
    "                                                                           method=method, device=device)\n",
    "    elapsed_time_inv = time.time() - start\n",
    "    if global_explanation_inv:\n",
    "        explanation_accuracy_inv, _ = logic.base.test_explanation(global_explanation_inv, target_class, x_test, y_test)\n",
    "        explanation_inv = logic.base.replace_names(global_explanation_inv, concepts)\n",
    "    print(f'\\t Class {target_class} - Global explanation: \"{explanation_inv}\" - Accuracy: {explanation_accuracy_inv:.4f}')\n",
    "    print(f'\\t Elapsed time {elapsed_time_inv}')\n",
    "    \n",
    "    methods.append(method)\n",
    "    splits.append(seed)\n",
    "    explanations.append(explanation)\n",
    "    explanations_inv.append(explanation_inv)\n",
    "    model_accuracies.append(model_accuracy)\n",
    "    explanation_accuracies.append(explanation_accuracy)\n",
    "    explanation_accuracies_inv.append(explanation_accuracy_inv)\n",
    "    elapsed_times.append(elapsed_time)\n",
    "    elapsed_times_inv.append(elapsed_time_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lime = pd.DataFrame({\n",
    "    'method': methods,\n",
    "    'split': splits,\n",
    "    'explanation': explanations,\n",
    "    'explanation_inv': explanations_inv,\n",
    "    'model_accuracy': model_accuracies,\n",
    "    'explanation_accuracy': explanation_accuracies,\n",
    "    'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "    'elapsed_time': elapsed_times,\n",
    "    'elapsed_time_inv': elapsed_times_inv,\n",
    "})\n",
    "results_lime.to_csv(os.path.join(results_dir, 'results_lime.csv'))\n",
    "results_lime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "need_pruning = False\n",
    "method = 'weights'\n",
    "methods = []\n",
    "splits = []\n",
    "explanations = []\n",
    "explanations_inv = []\n",
    "model_accuracies = []\n",
    "explanation_accuracies = []\n",
    "explanation_accuracies_inv = []\n",
    "elapsed_times = []\n",
    "elapsed_times_inv = []\n",
    "\n",
    "for split, (train_index, test_index) in enumerate(skf.split(x.cpu().detach().numpy(), y.cpu().detach().numpy())):\n",
    "    print(f'Split [{split+1}/{n_splits}]')\n",
    "    x_train, x_test = torch.FloatTensor(x[train_index]), torch.FloatTensor(x[test_index])\n",
    "    y_train, y_test = torch.LongTensor(y[train_index]), torch.LongTensor(y[test_index])\n",
    "    \n",
    "    model = train_nn(x_train, y_train, need_pruning, split, device, relu=True)\n",
    "    \n",
    "    y_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "    model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds.argmax(axis=1))\n",
    "    print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "    \n",
    "    # positive class\n",
    "    target_class = 1\n",
    "    start = time.time()\n",
    "    global_explanation, _, _ = logic.relunn.combine_local_explanations(model, \n",
    "                                                                       x_train.to(device), y_train.to(device),\n",
    "                                                                       topk_explanations=2, \n",
    "                                                                       target_class=target_class,\n",
    "                                                                       method=method, device=device)\n",
    "    elapsed_time = time.time() - start\n",
    "    if global_explanation:\n",
    "        explanation_accuracy, _ = logic.base.test_explanation(global_explanation, target_class, x_test, y_test)\n",
    "        explanation = logic.base.replace_names(global_explanation, concepts)\n",
    "    print(f'\\t Class {target_class} - Global explanation: \"{explanation}\" - Accuracy: {explanation_accuracy:.4f}')\n",
    "    print(f'\\t Elapsed time {elapsed_time}')\n",
    "        \n",
    "    # negative class\n",
    "    target_class = 0\n",
    "    start = time.time()\n",
    "    global_explanation_inv, _, _ = logic.relunn.combine_local_explanations(model, \n",
    "                                                                           x_train.to(device), y_train.to(device), \n",
    "                                                                           topk_explanations=2, \n",
    "                                                                           target_class=target_class,\n",
    "                                                                           method=method, device=device)\n",
    "    elapsed_time_inv = time.time() - start\n",
    "    if global_explanation_inv:\n",
    "        explanation_accuracy_inv, _ = logic.base.test_explanation(global_explanation_inv, target_class, x_test, y_test)\n",
    "        explanation_inv = logic.base.replace_names(global_explanation_inv, concepts)\n",
    "    print(f'\\t Class {target_class} - Global explanation: \"{explanation_inv}\" - Accuracy: {explanation_accuracy_inv:.4f}')\n",
    "    print(f'\\t Elapsed time {elapsed_time_inv}')\n",
    "    \n",
    "    methods.append(method)\n",
    "    splits.append(split)\n",
    "    explanations.append(explanation)\n",
    "    explanations_inv.append(explanation_inv)\n",
    "    model_accuracies.append(model_accuracy)\n",
    "    explanation_accuracies.append(explanation_accuracy)\n",
    "    explanation_accuracies_inv.append(explanation_accuracy_inv)\n",
    "    elapsed_times.append(elapsed_time)\n",
    "    elapsed_times_inv.append(elapsed_time_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_weights = pd.DataFrame({\n",
    "    'method': methods,\n",
    "    'split': splits,\n",
    "    'explanation': explanations,\n",
    "    'explanation_inv': explanations_inv,\n",
    "    'model_accuracy': model_accuracies,\n",
    "    'explanation_accuracy': explanation_accuracies,\n",
    "    'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "    'elapsed_time': elapsed_times,\n",
    "    'elapsed_time_inv': elapsed_times_inv,\n",
    "})\n",
    "results_weights.to_csv(os.path.join(results_dir, 'results_weights.csv'))\n",
    "results_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Psi network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_psi_nn(x_train, y_train, need_pruning, seed, device):\n",
    "    set_seed(seed)\n",
    "    x_train = x_train.to(device)\n",
    "    y_train = y_train.to(device).to(torch.float)\n",
    "    layers = [\n",
    "        torch.nn.Linear(x_train.size(1), 10),\n",
    "        torch.nn.Sigmoid(),\n",
    "        torch.nn.Linear(10, 4),\n",
    "        torch.nn.Sigmoid(),\n",
    "        torch.nn.Linear(4, 1),\n",
    "        torch.nn.Sigmoid(),\n",
    "    ]\n",
    "    model = torch.nn.Sequential(*layers).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_form = torch.nn.BCELoss()\n",
    "    model.train()\n",
    "    for epoch in range(tot_epochs):\n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_train).squeeze()\n",
    "        # Compute Loss\n",
    "        loss = loss_form(y_pred, y_train)\n",
    "\n",
    "        for module in model.children():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                loss += 0.0001 * torch.norm(module.weight, 1)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch > 1500 and need_pruning:\n",
    "            model = prune_equal_fanin(model, 2, validate=True, device=device)\n",
    "            need_pruning = False\n",
    "            \n",
    "        # compute accuracy\n",
    "        if epoch % 500 == 0:\n",
    "            y_pred_d = y_pred > 0.5\n",
    "            accuracy = y_pred_d.eq(y_train).sum().item() / y_train.size(0)\n",
    "            print(f'\\t Epoch {epoch}: train accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "need_pruning = True\n",
    "method = 'psi'\n",
    "methods = []\n",
    "splits = []\n",
    "explanations = []\n",
    "explanations_inv = []\n",
    "model_accuracies = []\n",
    "explanation_accuracies = []\n",
    "explanation_accuracies_inv = []\n",
    "elapsed_times = []\n",
    "elapsed_times_inv = []\n",
    "for seed in range(n_rep):\n",
    "    print(f'Seed [{seed+1}/{n_rep}]')\n",
    "    \n",
    "    # positive class\n",
    "    target_class = 1\n",
    "    model = train_psi_nn(x_train, y_train, need_pruning, seed, device)\n",
    "    \n",
    "    y_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "    model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds > 0.5)\n",
    "    print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "    \n",
    "    start = time.time()\n",
    "    global_explanation = logic.generate_fol_explanations(model, device)[0]\n",
    "    elapsed_time = time.time() - start\n",
    "    explanation_accuracy, _ = logic.base.test_explanation(global_explanation, target_class, x_test, y_test)\n",
    "    explanation = logic.base.replace_names(global_explanation, concepts)\n",
    "    print(f'\\t Class {target_class} - Global explanation: \"{explanation}\" - Accuracy: {explanation_accuracy:.4f}')\n",
    "    print(f'\\t Elapsed time {elapsed_time}')\n",
    "        \n",
    "    # negative class\n",
    "    target_class = 0\n",
    "    model = train_psi_nn(x_train, y_train.eq(target_class), need_pruning, seed, device)\n",
    "    \n",
    "    y_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "    model_accuracy = accuracy_score(y_test.eq(target_class).cpu().detach().numpy(), y_preds > 0.5)\n",
    "    print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "    \n",
    "    start = time.time()\n",
    "    global_explanation_inv = logic.generate_fol_explanations(model, device)[0]\n",
    "    elapsed_time_inv = time.time() - start\n",
    "    explanation_accuracy_inv, _ = logic.base.test_explanation(global_explanation_inv, \n",
    "                                                              target_class, x_test, y_test)\n",
    "    explanation_inv = logic.base.replace_names(global_explanation_inv, concepts)\n",
    "    print(f'\\t Class {target_class} - Global explanation: \"{explanation_inv}\" - Accuracy: {explanation_accuracy_inv:.4f}')\n",
    "    print(f'\\t Elapsed time {elapsed_time_inv}')\n",
    "    \n",
    "    methods.append(method)\n",
    "    splits.append(seed)\n",
    "    explanations.append(explanation)\n",
    "    explanations_inv.append(explanation_inv)\n",
    "    model_accuracies.append(model_accuracy)\n",
    "    explanation_accuracies.append(explanation_accuracy)\n",
    "    explanation_accuracies_inv.append(explanation_accuracy_inv)\n",
    "    elapsed_times.append(elapsed_time)\n",
    "    elapsed_times_inv.append(elapsed_time_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_psi = pd.DataFrame({\n",
    "    'method': methods,\n",
    "    'split': splits,\n",
    "    'explanation': explanations,\n",
    "    'explanation_inv': explanations_inv,\n",
    "    'model_accuracy': model_accuracies,\n",
    "    'explanation_accuracy': explanation_accuracies,\n",
    "    'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "    'elapsed_time': elapsed_times,\n",
    "    'elapsed_time_inv': elapsed_times_inv,\n",
    "})\n",
    "results_psi.to_csv(os.path.join(results_dir, 'results_psi.csv'))\n",
    "results_psi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "need_pruning = False\n",
    "method = 'decision_tree'\n",
    "methods = []\n",
    "splits = []\n",
    "explanations = []\n",
    "explanations_inv = []\n",
    "model_accuracies = []\n",
    "explanation_accuracies = []\n",
    "explanation_accuracies_inv = []\n",
    "elapsed_times = []\n",
    "elapsed_times_inv = []\n",
    "\n",
    "for split, (train_index, test_index) in enumerate(skf.split(x.cpu().detach().numpy(), y.cpu().detach().numpy())):\n",
    "    print(f'Split [{split+1}/{n_splits}]')\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    classifier = DecisionTreeClassifier(random_state=split)\n",
    "    classifier.fit(x_train.cpu().detach().numpy(), y_train.cpu().detach().numpy())\n",
    "    y_preds = classifier.predict(x_test.cpu().detach().numpy())\n",
    "    model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds)\n",
    "    print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "    \n",
    "    target_class = 1\n",
    "    start = time.time()\n",
    "    explanation = tree_to_formula(classifier, concepts, target_class)\n",
    "    elapsed_time = time.time() - start\n",
    "    print(f'\\t Class {target_class} - Global explanation: {explanation}')\n",
    "    print(f'\\t Elapsed time {elapsed_time}')\n",
    "    \n",
    "    target_class = 0\n",
    "    start = time.time()\n",
    "    explanation_inv = tree_to_formula(classifier, concepts, target_class)\n",
    "    elapsed_time_inv = time.time() - start\n",
    "    print(f'\\t Class {target_class} - Global explanation: {explanation_inv}')\n",
    "    print(f'\\t Elapsed time {elapsed_time_inv}')\n",
    "    \n",
    "    methods.append(method)\n",
    "    splits.append(split)\n",
    "    explanations.append(explanation)\n",
    "    explanations_inv.append(explanation_inv)\n",
    "    model_accuracies.append(model_accuracy)\n",
    "    explanation_accuracies.append(model_accuracy)\n",
    "    explanation_accuracies_inv.append(model_accuracy)\n",
    "    elapsed_times.append(0)\n",
    "    elapsed_times_inv.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tree = pd.DataFrame({\n",
    "    'method': methods,\n",
    "    'split': splits,\n",
    "    'explanation': explanations,\n",
    "    'explanation_inv': explanations_inv,\n",
    "    'model_accuracy': model_accuracies,\n",
    "    'explanation_accuracy': explanation_accuracies,\n",
    "    'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "    'elapsed_time': elapsed_times,\n",
    "    'elapsed_time_inv': elapsed_times_inv,\n",
    "})\n",
    "results_tree.to_csv(os.path.join(results_dir, 'results_tree.csv'))\n",
    "results_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['model_accuracy', 'explanation_accuracy', 'explanation_accuracy_inv', 'elapsed_time', 'elapsed_time_inv']\n",
    "mean_cols = [f'{c}_mean' for c in cols]\n",
    "sem_cols = [f'{c}_sem' for c in cols]\n",
    "\n",
    "# pruning\n",
    "df_mean = results_pruning[cols].mean()\n",
    "df_sem = results_pruning[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_pruning = pd.concat([df_mean, df_sem])\n",
    "summary_pruning.name = 'pruning'\n",
    "\n",
    "# lime\n",
    "df_mean = results_lime[cols].mean()\n",
    "df_sem = results_lime[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_lime = pd.concat([df_mean, df_sem])\n",
    "summary_lime.name = 'lime'\n",
    "\n",
    "# weights\n",
    "df_mean = results_weights[cols].mean()\n",
    "df_sem = results_weights[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_weights = pd.concat([df_mean, df_sem])\n",
    "summary_weights.name = 'weights'\n",
    "\n",
    "# psi\n",
    "df_mean = results_psi[cols].mean()\n",
    "df_sem = results_psi[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_psi = pd.concat([df_mean, df_sem])\n",
    "summary_psi.name = 'psi'\n",
    "\n",
    "# tree\n",
    "df_mean = results_tree[cols].mean()\n",
    "df_sem = results_tree[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_tree = pd.concat([df_mean, df_sem])\n",
    "summary_tree.name = 'tree'\n",
    "\n",
    "summary = pd.concat([summary_pruning, \n",
    "                     summary_lime, \n",
    "                     summary_weights, \n",
    "                     summary_psi, \n",
    "                     summary_tree], axis=1).T\n",
    "summary.columns = mean_cols + sem_cols\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_csv(os.path.join(results_dir, 'summary.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
