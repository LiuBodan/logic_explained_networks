{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from deep_logic.models.relu_nn import XReluNN\n",
    "from deep_logic.models.psi_nn import PsiNetwork\n",
    "from deep_logic.models.tree import XDecisionTreeClassifier\n",
    "from deep_logic.utils.base import set_seed\n",
    "from deep_logic.utils.metrics import F1Score\n",
    "from deep_logic.models.general_nn import XGeneralNN\n",
    "from deep_logic.utils.datasets import ConceptToTaskDataset\n",
    "from deep_logic.utils.data import get_splits_train_val_test\n",
    "from deep_logic.logic.base import test_multi_class_explanation\n",
    "\n",
    "results_dir = 'results/cub'\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define loss, metrics and saved metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "metric = F1Score()\n",
    "\n",
    "methods = []\n",
    "splits = []\n",
    "explanations = []\n",
    "explanations_inv = []\n",
    "model_accuracies = []\n",
    "explanation_accuracies = []\n",
    "explanation_accuracies_inv = []\n",
    "elapsed_times = []\n",
    "elapsed_times_inv = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading CUB data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept names ['has_bill_shape_dagger' 'has_bill_shape_hooked_seabird'\n",
      " 'has_bill_shape_allpurpose' 'has_bill_shape_cone' 'has_wing_color_brown'\n",
      " 'has_wing_color_grey' 'has_wing_color_yellow' 'has_wing_color_black'\n",
      " 'has_wing_color_white' 'has_wing_color_buff' 'has_upperparts_color_brown'\n",
      " 'has_upperparts_color_grey' 'has_upperparts_color_yellow'\n",
      " 'has_upperparts_color_black' 'has_upperparts_color_white'\n",
      " 'has_upperparts_color_buff' 'has_underparts_color_brown'\n",
      " 'has_underparts_color_grey' 'has_underparts_color_yellow'\n",
      " 'has_underparts_color_black' 'has_underparts_color_white'\n",
      " 'has_underparts_color_buff' 'has_breast_pattern_solid'\n",
      " 'has_breast_pattern_striped' 'has_breast_pattern_multicolored'\n",
      " 'has_back_color_brown' 'has_back_color_grey' 'has_back_color_yellow'\n",
      " 'has_back_color_black' 'has_back_color_white' 'has_back_color_buff'\n",
      " 'has_tail_shape_notched_tail' 'has_upper_tail_color_brown'\n",
      " 'has_upper_tail_color_grey' 'has_upper_tail_color_black'\n",
      " 'has_upper_tail_color_white' 'has_upper_tail_color_buff'\n",
      " 'has_head_pattern_plain' 'has_head_pattern_capped'\n",
      " 'has_breast_color_brown' 'has_breast_color_grey'\n",
      " 'has_breast_color_yellow' 'has_breast_color_black'\n",
      " 'has_breast_color_white' 'has_breast_color_buff' 'has_throat_color_grey'\n",
      " 'has_throat_color_yellow' 'has_throat_color_black'\n",
      " 'has_throat_color_white' 'has_eye_color_black'\n",
      " 'has_bill_length_about_the_same_as_head'\n",
      " 'has_bill_length_shorter_than_head' 'has_forehead_color_blue'\n",
      " 'has_forehead_color_brown' 'has_forehead_color_grey'\n",
      " 'has_forehead_color_yellow' 'has_forehead_color_black'\n",
      " 'has_forehead_color_white' 'has_forehead_color_red'\n",
      " 'has_under_tail_color_brown' 'has_under_tail_color_grey'\n",
      " 'has_under_tail_color_yellow' 'has_under_tail_color_black'\n",
      " 'has_under_tail_color_white' 'has_under_tail_color_buff'\n",
      " 'has_nape_color_blue' 'has_nape_color_brown' 'has_nape_color_grey'\n",
      " 'has_nape_color_yellow' 'has_nape_color_black' 'has_nape_color_white'\n",
      " 'has_nape_color_buff' 'has_belly_color_grey' 'has_belly_color_yellow'\n",
      " 'has_belly_color_black' 'has_belly_color_white' 'has_belly_color_buff'\n",
      " 'has_wing_shape_roundedwings' 'has_size_small_5__9_in'\n",
      " 'has_size_medium_9__16_in' 'has_size_very_small_3__5_in'\n",
      " 'has_shape_perchinglike' 'has_back_pattern_solid'\n",
      " 'has_back_pattern_striped' 'has_back_pattern_multicolored'\n",
      " 'has_tail_pattern_solid' 'has_tail_pattern_multicolored'\n",
      " 'has_belly_pattern_solid' 'has_primary_color_brown'\n",
      " 'has_primary_color_grey' 'has_primary_color_yellow'\n",
      " 'has_primary_color_black' 'has_primary_color_white'\n",
      " 'has_primary_color_buff' 'has_leg_color_grey' 'has_leg_color_black'\n",
      " 'has_leg_color_buff' 'has_bill_color_grey' 'has_bill_color_black'\n",
      " 'has_crown_color_blue' 'has_crown_color_brown' 'has_crown_color_grey'\n",
      " 'has_crown_color_yellow' 'has_crown_color_black' 'has_crown_color_white'\n",
      " 'has_wing_pattern_solid' 'has_wing_pattern_striped'\n",
      " 'has_wing_pattern_multicolored']\n",
      "Number of features 108\n"
     ]
    }
   ],
   "source": [
    "dataset = ConceptToTaskDataset(\"../data/CUB_200_2011/\")\n",
    "concept_names = dataset.attribute_names\n",
    "print(\"Concept names\", concept_names)\n",
    "n_features = dataset.n_attributes\n",
    "print(\"Number of features\", n_features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeds [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "l_r = 0.001\n",
    "lr_scheduler = True\n",
    "top_k_explanations = 1\n",
    "simplify = True\n",
    "seeds = [*range(10)]\n",
    "print(\"Seeds\", seeds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 0\n",
      "[    0     2     3 ... 11784 11785 11787]\n",
      "Training Tree Classifier...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-5-2b556ff2c8b4>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     11\u001B[0m     \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mXDecisionTreeClassifier\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn_classes\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_classes\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_features\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mn_features\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 13\u001B[1;33m     \u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mval_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmetric\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmetric\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msave\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     14\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresults\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Scuola\\Dottorato\\Codice\\InterpretableReLU\\deep_logic\\models\\tree.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, train_set, val_set, metric, verbose, save, **kwargs)\u001B[0m\n\u001B[0;32m     84\u001B[0m         \u001B[0mtrain_loader\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataLoader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_set\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1024\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_workers\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m8\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     85\u001B[0m         \u001B[0mtrain_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_labels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 86\u001B[1;33m         \u001B[1;32mfor\u001B[0m \u001B[0mdata\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtrain_loader\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     87\u001B[0m             \u001B[0mtrain_data\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_labels\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     88\u001B[0m         \u001B[0mtrain_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_labels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_data\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_labels\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\fsc\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    350\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterator\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    351\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 352\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_iterator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    353\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    354\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\fsc\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_get_iterator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    292\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0m_SingleProcessDataLoaderIter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    293\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 294\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0m_MultiProcessingDataLoaderIter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    295\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    296\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\fsc\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, loader)\u001B[0m\n\u001B[0;32m    799\u001B[0m             \u001B[1;31m#     before it starts, and __del__ tries to join but will get:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    800\u001B[0m             \u001B[1;31m#     AssertionError: can only join a started process.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 801\u001B[1;33m             \u001B[0mw\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    802\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_index_queues\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex_queue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    803\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_workers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\fsc\\lib\\multiprocessing\\process.py\u001B[0m in \u001B[0;36mstart\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    110\u001B[0m                \u001B[1;34m'daemonic processes are not allowed to have children'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    111\u001B[0m         \u001B[0m_cleanup\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 112\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_popen\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    113\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sentinel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_popen\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msentinel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    114\u001B[0m         \u001B[1;31m# Avoid a refcycle if the target function holds an indirect\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\fsc\\lib\\multiprocessing\\context.py\u001B[0m in \u001B[0;36m_Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    221\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mstaticmethod\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    222\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 223\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0m_default_context\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mProcess\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    224\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    225\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mDefaultContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mBaseContext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\fsc\\lib\\multiprocessing\\context.py\u001B[0m in \u001B[0;36m_Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    320\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    321\u001B[0m             \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mpopen_spawn_win32\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mPopen\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 322\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mPopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    323\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    324\u001B[0m     \u001B[1;32mclass\u001B[0m \u001B[0mSpawnContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mBaseContext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\fsc\\lib\\multiprocessing\\popen_spawn_win32.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, process_obj)\u001B[0m\n\u001B[0;32m     87\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     88\u001B[0m                 \u001B[0mreduction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprep_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mto_child\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 89\u001B[1;33m                 \u001B[0mreduction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mto_child\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     90\u001B[0m             \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     91\u001B[0m                 \u001B[0mset_spawning_popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\fsc\\lib\\multiprocessing\\reduction.py\u001B[0m in \u001B[0;36mdump\u001B[1;34m(obj, file, protocol)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprotocol\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m     \u001B[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 60\u001B[1;33m     \u001B[0mForkingPickler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprotocol\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     61\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[1;31m#\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for seed in seeds:\n",
    "    print(\"Seed\", seed)\n",
    "    set_seed(seed)\n",
    "\n",
    "    train_data, val_data, test_data = get_splits_train_val_test(dataset)\n",
    "    print(train_data.indices)\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    print(\"Training Tree Classifier...\")\n",
    "    model = XDecisionTreeClassifier(n_classes=dataset.n_classes, n_features=n_features)\n",
    "\n",
    "    results = model.fit(train_data, val_data, metric=metric, save=False)\n",
    "    print(results)\n",
    "\n",
    "    accuracy = model.evaluate(test_data)\n",
    "    print(\"Test model accuracy\", accuracy)\n",
    "\n",
    "    formulas, times = [], []\n",
    "    for i, class_to_explain in enumerate(dataset.classes):\n",
    "        formula, elapsed_time = model.get_global_explanation(i, concept_names,\n",
    "                                                             return_time=True)\n",
    "        formulas.append(formula), times.append(elapsed_time)\n",
    "        print(f\"{class_to_explain} <-> {formula}\")\n",
    "        print(\"Elapsed time\", elapsed_time)\n",
    "\n",
    "    methods.append(\"Tree\")\n",
    "    splits.append(seed)\n",
    "    explanations.append(formulas[0])\n",
    "    explanations_inv.append(formulas[1])\n",
    "    model_accuracies.append(accuracy)\n",
    "    explanation_accuracies.append(accuracy)\n",
    "    explanation_accuracies_inv.append(accuracy)\n",
    "    elapsed_times.append(np.mean(times))\n",
    "    elapsed_times_inv.append(np.mean(times))\n",
    "\n",
    "results_tree = pd.DataFrame({\n",
    "    'method': methods,\n",
    "    'split': splits,\n",
    "    'explanation': explanations,\n",
    "    'explanation_inv': explanations_inv,\n",
    "    'model_accuracy': model_accuracies,\n",
    "    'explanation_accuracy': explanation_accuracies,\n",
    "    'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "    'elapsed_time': elapsed_times,\n",
    "    'elapsed_time_inv': elapsed_times_inv,\n",
    "})\n",
    "results_tree.to_csv(os.path.join(results_dir, 'results_tree.csv'))\n",
    "print(results_tree)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Relu NN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for seed in seeds:\n",
    "    print(\"Seed\", seed)\n",
    "    set_seed(seed)\n",
    "\n",
    "    train_data, val_data, test_data = get_splits_train_val_test(dataset)\n",
    "    print(train_data.indices)\n",
    "\n",
    "    x_val = torch.tensor(dataset.attributes[val_data.indices])\n",
    "    y_val = torch.tensor(dataset.targets[val_data.indices])\n",
    "    x_test = torch.tensor(dataset.attributes[test_data.indices])\n",
    "    y_test = torch.tensor(dataset.targets[test_data.indices])\n",
    "\n",
    "    # Network structures\n",
    "    l1_weight = 1e-5\n",
    "    hidden_neurons = [200, 100]\n",
    "\n",
    "    # Setting device\n",
    "    device = torch.device(\"cpu\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    set_seed(seed)\n",
    "    print(f\"Training Relu NN...\")\n",
    "    model = XReluNN(n_classes=dataset.n_classes, n_features=n_features,\n",
    "                    hidden_neurons=hidden_neurons, loss=loss, l1_weight=l1_weight)\n",
    "\n",
    "    results = model.fit(train_data, val_data, epochs=epochs, l_r=l_r, verbose=False,\n",
    "                        metric=metric, lr_scheduler=lr_scheduler, device=device, save=False)\n",
    "    print(results)\n",
    "    accuracy = model.evaluate(test_data)\n",
    "    print(\"Test Model accuracy\", accuracy)\n",
    "\n",
    "    formulas, times, exp_accuracies = [], [], []\n",
    "    for i, class_to_explain in enumerate(dataset.classes):\n",
    "        formula, elapsed_time = model.get_global_explanation(x_val, y_val, i,\n",
    "                                                             topk_explanations=top_k_explanations,\n",
    "                                                             concept_names=concept_names,\n",
    "                                                             simplify=True, return_time=True)\n",
    "        exp_accuracy, _ = test_multi_class_explanation(formula, i, x_test, y_test,\n",
    "                                                       metric=metric, concept_names=concept_names)\n",
    "        formulas.append(formula), times.append(elapsed_time), exp_accuracies.append(exp_accuracy)\n",
    "        print(f\"{class_to_explain} <-> {formula}\")\n",
    "        print(\"Elapsed time\", elapsed_time)\n",
    "        print(\"Explanation accuracy\", exp_accuracy)\n",
    "\n",
    "    methods.append(\"Relu\")\n",
    "    splits.append(seed)\n",
    "    explanations.append(formulas[0])\n",
    "    explanations_inv.append(formulas[1])\n",
    "    model_accuracies.append(accuracy)\n",
    "    explanation_accuracies.append(np.mean(exp_accuracies))\n",
    "    explanation_accuracies_inv.append(np.mean(exp_accuracies))\n",
    "    elapsed_times.append(np.mean(times))\n",
    "    elapsed_times_inv.append(np.mean(times))\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'method': methods,\n",
    "    'split': splits,\n",
    "    'explanation': explanations,\n",
    "    'explanation_inv': explanations_inv,\n",
    "    'model_accuracy': model_accuracies,\n",
    "    'explanation_accuracy': explanation_accuracies,\n",
    "    'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "    'elapsed_time': elapsed_times,\n",
    "    'elapsed_time_inv': elapsed_times_inv,\n",
    "})\n",
    "results_relu = results[results['method'] == \"Relu\"]\n",
    "results_relu.to_csv(os.path.join(results_dir, 'results_relu.csv'))\n",
    "print(results_relu)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PSI NN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for seed in seeds:\n",
    "    print(\"Seed\", seed)\n",
    "    set_seed(seed)\n",
    "\n",
    "    train_data, val_data, test_data = get_splits_train_val_test(dataset)\n",
    "    print(train_data.indices)\n",
    "\n",
    "    x_test = torch.tensor(dataset.attributes[test_data.indices])\n",
    "    y_test = torch.tensor(dataset.targets[test_data.indices])\n",
    "\n",
    "    # Network structures\n",
    "    l1_weight = 5e-6\n",
    "    hidden_neurons = [10, 5]\n",
    "    fan_in = 3\n",
    "    lr_psi = 0.01\n",
    "\n",
    "    # Setting device\n",
    "    device = torch.device(\"cpu\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    set_seed(seed)\n",
    "\n",
    "    print(\"Training Psi NN...\")\n",
    "    model = PsiNetwork(dataset.n_classes, n_features, hidden_neurons, loss,\n",
    "                       l1_weight, fan_in=fan_in)\n",
    "\n",
    "    results = model.fit(train_data, val_data, epochs=epochs, l_r=lr_psi, verbose=False,\n",
    "                        metric=metric, lr_scheduler=lr_scheduler, device=device, save=False)\n",
    "    print(results)\n",
    "    accuracy = model.evaluate(test_data, metric=metric)\n",
    "    print(\"Test model accuracy\", accuracy)\n",
    "\n",
    "    formulas, times, exp_accuracies = [], [], []\n",
    "    for i, class_to_explain in enumerate(dataset.classes):\n",
    "        formula, elapsed_time = model.get_global_explanation(i, concept_names,\n",
    "                                                             simplify=True, return_time=True)\n",
    "        exp_accuracy, _ = test_multi_class_explanation(formula, i, x_test, y_test,\n",
    "                                                       metric=metric, concept_names=concept_names)\n",
    "        formulas.append(formula), times.append(elapsed_time), exp_accuracies.append(exp_accuracy)\n",
    "        print(f\"{class_to_explain} <-> {formula}\")\n",
    "        print(\"Elapsed time\", elapsed_time)\n",
    "        print(\"Explanation accuracy\", exp_accuracy)\n",
    "\n",
    "    methods.append(\"Psi\")\n",
    "    splits.append(seed)\n",
    "    explanations.append(formulas[0])\n",
    "    explanations_inv.append(formulas[1])\n",
    "    model_accuracies.append(accuracy)\n",
    "    explanation_accuracies.append(np.mean(exp_accuracies))\n",
    "    explanation_accuracies_inv.append(np.mean(exp_accuracies))\n",
    "    elapsed_times.append(np.mean(times))\n",
    "    elapsed_times_inv.append(np.mean(times))\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'method': methods,\n",
    "    'split': splits,\n",
    "    'explanation': explanations,\n",
    "    'explanation_inv': explanations_inv,\n",
    "    'model_accuracy': model_accuracies,\n",
    "    'explanation_accuracy': explanation_accuracies,\n",
    "    'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "    'elapsed_time': elapsed_times,\n",
    "    'elapsed_time_inv': elapsed_times_inv,\n",
    "})\n",
    "results_psi = results[results['method'] == \"Psi\"]\n",
    "results_psi.to_csv(os.path.join(results_dir, 'results_psi.csv'))\n",
    "print(results_psi)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mu NN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for seed in seeds:\n",
    "    print(\"Seed\", seed)\n",
    "    set_seed(seed)\n",
    "\n",
    "    train_data, val_data, test_data = get_splits_train_val_test(dataset)\n",
    "    print(train_data.indices)\n",
    "\n",
    "    x_val = torch.tensor(dataset.attributes[val_data.indices])\n",
    "    y_val = torch.tensor(dataset.targets[val_data.indices])\n",
    "    x_test = torch.tensor(dataset.attributes[test_data.indices])\n",
    "    y_test = torch.tensor(dataset.targets[test_data.indices])\n",
    "\n",
    "    # Network structures\n",
    "    l1_weight = 1e-3\n",
    "    hidden_neurons = [10, 5]\n",
    "\n",
    "    # Setting device\n",
    "    device = torch.device(\"cpu\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    set_seed(seed)\n",
    "\n",
    "    print(\"Training General NN...\")\n",
    "    model = XGeneralNN(n_classes=dataset.n_classes, n_features=n_features, hidden_neurons=hidden_neurons,\n",
    "                       loss=loss, l1_weight=l1_weight)\n",
    "\n",
    "    results = model.fit(train_data, val_data, epochs=epochs, l_r=l_r, metric=metric,\n",
    "                        lr_scheduler=lr_scheduler, device=device, save=False, verbose=False)\n",
    "    print(results)\n",
    "    accuracy = model.evaluate(test_data, metric=metric)\n",
    "    print(\"Test model accuracy\", accuracy)\n",
    "\n",
    "    formulas, times, exp_accuracies = [], [], []\n",
    "    for i, class_to_explain in enumerate(dataset.classes):\n",
    "        formula, elapsed_time = model.get_global_explanation(x_val, y_val, i, simplify=True,\n",
    "                                                             topk_explanations=top_k_explanations,\n",
    "                                                             concept_names=concept_names, return_time=True)\n",
    "        exp_accuracy, _ = test_multi_class_explanation(formula, i, x_test, y_test,\n",
    "                                                       metric=metric, concept_names=concept_names)\n",
    "        formulas.append(formula), times.append(elapsed_time), exp_accuracies.append(exp_accuracy)\n",
    "        print(f\"{class_to_explain} <-> {formula}\")\n",
    "        print(\"Elapsed time\", elapsed_time)\n",
    "        print(\"Explanation accuracy\", exp_accuracy)\n",
    "\n",
    "    methods.append(\"General\")\n",
    "    splits.append(seed)\n",
    "    explanations.append(formulas[0])\n",
    "    explanations_inv.append(formulas[1])\n",
    "    model_accuracies.append(accuracy)\n",
    "    explanation_accuracies.append(np.mean(exp_accuracies))\n",
    "    explanation_accuracies_inv.append(np.mean(exp_accuracies))\n",
    "    elapsed_times.append(np.mean(times))\n",
    "    elapsed_times_inv.append(np.mean(times))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'method': methods,\n",
    "    'split': splits,\n",
    "    'explanation': explanations,\n",
    "    'explanation_inv': explanations_inv,\n",
    "    'model_accuracy': model_accuracies,\n",
    "    'explanation_accuracy': explanation_accuracies,\n",
    "    'explanation_accuracy_inv': explanation_accuracies_inv,\n",
    "    'elapsed_time': elapsed_times,\n",
    "    'elapsed_time_inv': elapsed_times_inv,\n",
    "})\n",
    "results_general = results[results['method'] == \"General\"]\n",
    "results_general.to_csv(os.path.join(results_dir, 'results_general.csv'))\n",
    "results.to_csv(os.path.join(results_dir, 'results.csv'))\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Summary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cols = ['model_accuracy', 'explanation_accuracy', 'explanation_accuracy_inv', 'elapsed_time', 'elapsed_time_inv']\n",
    "mean_cols = [f'{c}_mean' for c in cols]\n",
    "sem_cols = [f'{c}_sem' for c in cols]\n",
    "\n",
    "# general\n",
    "results_general = results[results['method'] == \"General\"]\n",
    "df_mean = results_general[cols].mean()\n",
    "df_sem = results_general[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_pruning = pd.concat([df_mean, df_sem])\n",
    "summary_pruning.name = 'general'\n",
    "\n",
    "# # lime\n",
    "# df_mean = results_lime[cols].mean()\n",
    "# df_sem = results_lime[cols].sem()\n",
    "# df_mean.columns = mean_cols\n",
    "# df_sem.columns = sem_cols\n",
    "# summary_lime = pd.concat([df_mean, df_sem])\n",
    "# summary_lime.name = 'lime'\n",
    "\n",
    "# relu\n",
    "results_relu = results[results['method'] == \"Relu\"]\n",
    "df_mean = results_relu[cols].mean()\n",
    "df_sem = results_relu[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_weights = pd.concat([df_mean, df_sem])\n",
    "summary_weights.name = 'relu'\n",
    "\n",
    "# psi\n",
    "results_psi = results[results['method'] == \"Psi\"]\n",
    "df_mean = results_psi[cols].mean()\n",
    "df_sem = results_psi[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_psi = pd.concat([df_mean, df_sem])\n",
    "summary_psi.name = 'psi'\n",
    "\n",
    "# tree\n",
    "results_tree = results[results['method'] == \"Tree\"]\n",
    "df_mean = results_tree[cols].mean()\n",
    "df_sem = results_tree[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_tree = pd.concat([df_mean, df_sem])\n",
    "summary_tree.name = 'tree'\n",
    "\n",
    "summary = pd.concat([summary_pruning,\n",
    "                     #                      summary_lime,\n",
    "                     summary_weights,\n",
    "                     summary_psi,\n",
    "                     summary_tree], axis=1).T\n",
    "summary.columns = mean_cols + sem_cols\n",
    "print(summary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "summary.to_csv(os.path.join(results_dir, 'summary.csv'))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}