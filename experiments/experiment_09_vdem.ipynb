{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exclusive-potato",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, KBinsDiscretizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sympy import simplify_logic\n",
    "import re\n",
    "\n",
    "import deep_logic as dl\n",
    "from deep_logic.utils.base import validate_network, set_seed, tree_to_formula\n",
    "from deep_logic.utils.relu_nn import get_reduced_model, prune_features\n",
    "from deep_logic.utils.psi_nn import prune_equal_fanin\n",
    "from deep_logic.models.brl import XBRLClassifier\n",
    "from deep_logic import logic\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "#%%\n",
    "\n",
    "data = pd.read_csv('data/vdem/V-Dem-CY-Core-v10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pressing-telescope",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   Mexico_1789\n",
       "1                   Mexico_1790\n",
       "2                   Mexico_1791\n",
       "3                   Mexico_1792\n",
       "4                   Mexico_1793\n",
       "                  ...          \n",
       "27008    Piedmont-Sardinia_1857\n",
       "27009    Piedmont-Sardinia_1858\n",
       "27010    Piedmont-Sardinia_1859\n",
       "27011    Piedmont-Sardinia_1860\n",
       "27012    Piedmont-Sardinia_1861\n",
       "Name: country_name_year, Length: 27013, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['country_name_year'] = data['country_name'] + '_' + data['year'].astype(str)\n",
    "data['country_name_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "operational-mercury",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v2x_polyarchy</th>\n",
       "      <th>v2x_polyarchy_codelow</th>\n",
       "      <th>v2x_polyarchy_codehigh</th>\n",
       "      <th>v2x_polyarchy_sd</th>\n",
       "      <th>v2x_delibdem</th>\n",
       "      <th>v2x_delibdem_codelow</th>\n",
       "      <th>v2x_delibdem_codehigh</th>\n",
       "      <th>v2x_delibdem_sd</th>\n",
       "      <th>v2x_egaldem</th>\n",
       "      <th>v2x_egaldem_codelow</th>\n",
       "      <th>...</th>\n",
       "      <th>v2xcl_slave_sd</th>\n",
       "      <th>v2xel_elecparl</th>\n",
       "      <th>v2xel_elecpres</th>\n",
       "      <th>v2xex_elecleg</th>\n",
       "      <th>v2xlg_leginter</th>\n",
       "      <th>v2xme_altinf</th>\n",
       "      <th>v2xme_altinf_codelow</th>\n",
       "      <th>v2xme_altinf_codehigh</th>\n",
       "      <th>v2xme_altinf_sd</th>\n",
       "      <th>v2x_divparctrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.698</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.653</td>\n",
       "      <td>1.616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.711</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.649</td>\n",
       "      <td>1.616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.715</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.649</td>\n",
       "      <td>1.616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.720</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.649</td>\n",
       "      <td>1.616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.720</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.649</td>\n",
       "      <td>1.616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25618</th>\n",
       "      <td>0.316</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.633</td>\n",
       "      <td>1.602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25619</th>\n",
       "      <td>0.267</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.633</td>\n",
       "      <td>-0.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25620</th>\n",
       "      <td>0.260</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.628</td>\n",
       "      <td>-0.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25621</th>\n",
       "      <td>0.262</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-0.586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25622</th>\n",
       "      <td>0.245</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.640</td>\n",
       "      <td>-0.586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3385 rows × 1052 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       v2x_polyarchy  v2x_polyarchy_codelow  v2x_polyarchy_codehigh  \\\n",
       "212            0.698                  0.632                   0.763   \n",
       "213            0.711                  0.667                   0.778   \n",
       "214            0.715                  0.668                   0.762   \n",
       "215            0.720                  0.668                   0.746   \n",
       "216            0.720                  0.668                   0.746   \n",
       "...              ...                    ...                     ...   \n",
       "25618          0.316                  0.283                   0.348   \n",
       "25619          0.267                  0.236                   0.286   \n",
       "25620          0.260                  0.236                   0.282   \n",
       "25621          0.262                  0.245                   0.284   \n",
       "25622          0.245                  0.209                   0.265   \n",
       "\n",
       "       v2x_polyarchy_sd  v2x_delibdem  v2x_delibdem_codelow  \\\n",
       "212               0.067         0.539                 0.467   \n",
       "213               0.055         0.543                 0.475   \n",
       "214               0.047         0.554                 0.497   \n",
       "215               0.039         0.566                 0.519   \n",
       "216               0.039         0.585                 0.522   \n",
       "...                 ...           ...                   ...   \n",
       "25618             0.035         0.215                 0.173   \n",
       "25619             0.028         0.194                 0.152   \n",
       "25620             0.025         0.168                 0.137   \n",
       "25621             0.020         0.213                 0.181   \n",
       "25622             0.029         0.183                 0.133   \n",
       "\n",
       "       v2x_delibdem_codehigh  v2x_delibdem_sd  v2x_egaldem  \\\n",
       "212                    0.626            0.080        0.411   \n",
       "213                    0.608            0.064        0.418   \n",
       "214                    0.606            0.053        0.418   \n",
       "215                    0.605            0.043        0.423   \n",
       "216                    0.615            0.047        0.423   \n",
       "...                      ...              ...          ...   \n",
       "25618                  0.278            0.052        0.255   \n",
       "25619                  0.233            0.041        0.234   \n",
       "25620                  0.208            0.034        0.213   \n",
       "25621                  0.264            0.041        0.214   \n",
       "25622                  0.224            0.044        0.187   \n",
       "\n",
       "       v2x_egaldem_codelow  ...  v2xcl_slave_sd  v2xel_elecparl  \\\n",
       "212                  0.349  ...           0.556               0   \n",
       "213                  0.359  ...           0.556               0   \n",
       "214                  0.378  ...           0.556               1   \n",
       "215                  0.386  ...           0.556               0   \n",
       "216                  0.386  ...           0.556               0   \n",
       "...                    ...  ...             ...             ...   \n",
       "25618                0.214  ...           0.592               1   \n",
       "25619                0.207  ...           0.592               1   \n",
       "25620                0.188  ...           0.599               0   \n",
       "25621                0.192  ...           0.608               0   \n",
       "25622                0.160  ...           0.609               0   \n",
       "\n",
       "       v2xel_elecpres  v2xex_elecleg  v2xlg_leginter  v2xme_altinf  \\\n",
       "212                 0           1.00             0.0         0.767   \n",
       "213                 0           1.00             0.0         0.808   \n",
       "214                 0           1.00             0.0         0.808   \n",
       "215                 0           1.00             0.0         0.808   \n",
       "216                 0           1.00             0.0         0.808   \n",
       "...               ...            ...             ...           ...   \n",
       "25618               1           0.85             0.0         0.516   \n",
       "25619               1           0.85             0.0         0.516   \n",
       "25620               0           0.85             0.0         0.437   \n",
       "25621               0           0.85             0.0         0.502   \n",
       "25622               0           0.85             0.0         0.525   \n",
       "\n",
       "       v2xme_altinf_codelow  v2xme_altinf_codehigh  v2xme_altinf_sd  \\\n",
       "212                   0.615                  0.855            0.653   \n",
       "213                   0.683                  0.887            0.649   \n",
       "214                   0.683                  0.887            0.649   \n",
       "215                   0.683                  0.887            0.649   \n",
       "216                   0.683                  0.887            0.649   \n",
       "...                     ...                    ...              ...   \n",
       "25618                 0.381                  0.627            0.633   \n",
       "25619                 0.381                  0.627            0.633   \n",
       "25620                 0.321                  0.579            0.628   \n",
       "25621                 0.374                  0.620            0.625   \n",
       "25622                 0.378                  0.663            0.640   \n",
       "\n",
       "       v2x_divparctrl  \n",
       "212             1.616  \n",
       "213             1.616  \n",
       "214             1.616  \n",
       "215             1.616  \n",
       "216             1.616  \n",
       "...               ...  \n",
       "25618           1.602  \n",
       "25619          -0.684  \n",
       "25620          -0.448  \n",
       "25621          -0.586  \n",
       "25622          -0.586  \n",
       "\n",
       "[3385 rows x 1052 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2000 = data[data['year']>2000].iloc[:, 12:-1].dropna(axis=1)\n",
    "data_2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "furnished-expense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main 3 - Area 14 - Raw 62\n"
     ]
    }
   ],
   "source": [
    "high_level_indicators = [\n",
    "    'v2x_polyarchy',\n",
    "    #'v2x_libdem',\n",
    "    #'v2x_partipdem',\n",
    "    'v2x_delibdem',\n",
    "    'v2x_egaldem'\n",
    "]\n",
    "mid_level_indicators = [\n",
    "    'v2x_api',\n",
    "    'v2x_mpi',\n",
    "    'v2x_freexp_altinf',\n",
    "    'v2x_frassoc_thick',\n",
    "    'v2x_suffr',\n",
    "    'v2xel_frefair',\n",
    "    'v2x_elecoff',\n",
    "    #'v2x_liberal',\n",
    "    'v2xcl_rol',\n",
    "    #'v2x_jucon',\n",
    "    #'v2xlg_legcon',\n",
    "    #'v2x_partip',\n",
    "    'v2x_cspart',\n",
    "    #'v2xdd_dd',\n",
    "    #'v2xel_locelec',\n",
    "    #'v2xel_regelec',\n",
    "    'v2xdl_delib',\n",
    "    'v2x_egal',\n",
    "    'v2xeg_eqprotec',\n",
    "    'v2xeg_eqaccess',\n",
    "    'v2xeg_eqdr',\n",
    "]\n",
    "\n",
    "drop_list = ['codelow', 'codehigh', 'sd', 'osp', 'nr', 'mean']\n",
    "low_level_indicators = []\n",
    "for f in data_2000.columns:\n",
    "    if f.endswith('_ord') and f not in high_level_indicators and f not in mid_level_indicators:\n",
    "        low_level_indicators.append(f)\n",
    "\n",
    "\n",
    "low_level_indicators_continuous = []\n",
    "for f in data_2000.columns:\n",
    "    if f.endswith('_codehigh') or f.endswith('_codelow') and f not in high_level_indicators and f not in mid_level_indicators:\n",
    "        low_level_indicators_continuous.append(f)\n",
    "\n",
    "print(f'Main {len(high_level_indicators)} - Area {len(mid_level_indicators)} - Raw {len(low_level_indicators)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "growing-hungary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3385, 464)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_low_continuous = data_2000[low_level_indicators_continuous]\n",
    "data_low_continuous.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "closing-synthetic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v2psbars_ord_0</th>\n",
       "      <th>v2psbars_ord_1</th>\n",
       "      <th>v2psbars_ord_2</th>\n",
       "      <th>v2psbars_ord_3</th>\n",
       "      <th>v2psparban_ord_0</th>\n",
       "      <th>v2psparban_ord_1</th>\n",
       "      <th>v2psparban_ord_2</th>\n",
       "      <th>v2psparban_ord_3</th>\n",
       "      <th>v2psorgs_ord_0</th>\n",
       "      <th>v2psorgs_ord_1</th>\n",
       "      <th>...</th>\n",
       "      <th>v2pepwrgen_ord_1</th>\n",
       "      <th>v2pepwrgen_ord_2</th>\n",
       "      <th>v2peedueq_ord_0</th>\n",
       "      <th>v2peedueq_ord_1</th>\n",
       "      <th>v2peedueq_ord_2</th>\n",
       "      <th>v2peedueq_ord_3</th>\n",
       "      <th>v2pehealth_ord_0</th>\n",
       "      <th>v2pehealth_ord_1</th>\n",
       "      <th>v2pehealth_ord_2</th>\n",
       "      <th>v2pehealth_ord_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3385.000000</td>\n",
       "      <td>3385.000000</td>\n",
       "      <td>3385.000000</td>\n",
       "      <td>3385.000000</td>\n",
       "      <td>3385.000000</td>\n",
       "      <td>3385.000000</td>\n",
       "      <td>3385.000000</td>\n",
       "      <td>3385.000000</td>\n",
       "      <td>3385.000000</td>\n",
       "      <td>3385.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3385.000000</td>\n",
       "      <td>3385.000000</td>\n",
       "      <td>3385.000000</td>\n",
       "      <td>3385.000000</td>\n",
       "      <td>3385.000000</td>\n",
       "      <td>3385.000000</td>\n",
       "      <td>3385.000000</td>\n",
       "      <td>3385.000000</td>\n",
       "      <td>3385.000000</td>\n",
       "      <td>3385.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.056425</td>\n",
       "      <td>0.037518</td>\n",
       "      <td>0.080059</td>\n",
       "      <td>0.825997</td>\n",
       "      <td>0.053471</td>\n",
       "      <td>0.029838</td>\n",
       "      <td>0.028951</td>\n",
       "      <td>0.887740</td>\n",
       "      <td>0.044018</td>\n",
       "      <td>0.150960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230133</td>\n",
       "      <td>0.730871</td>\n",
       "      <td>0.059970</td>\n",
       "      <td>0.312851</td>\n",
       "      <td>0.132939</td>\n",
       "      <td>0.494239</td>\n",
       "      <td>0.038109</td>\n",
       "      <td>0.322304</td>\n",
       "      <td>0.145643</td>\n",
       "      <td>0.493944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.230775</td>\n",
       "      <td>0.190057</td>\n",
       "      <td>0.271425</td>\n",
       "      <td>0.379168</td>\n",
       "      <td>0.225004</td>\n",
       "      <td>0.170164</td>\n",
       "      <td>0.167694</td>\n",
       "      <td>0.315733</td>\n",
       "      <td>0.205165</td>\n",
       "      <td>0.358063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.420980</td>\n",
       "      <td>0.443572</td>\n",
       "      <td>0.237467</td>\n",
       "      <td>0.463723</td>\n",
       "      <td>0.339559</td>\n",
       "      <td>0.500041</td>\n",
       "      <td>0.191488</td>\n",
       "      <td>0.467428</td>\n",
       "      <td>0.352800</td>\n",
       "      <td>0.500037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       v2psbars_ord_0  v2psbars_ord_1  v2psbars_ord_2  v2psbars_ord_3  \\\n",
       "count     3385.000000     3385.000000     3385.000000     3385.000000   \n",
       "mean         0.056425        0.037518        0.080059        0.825997   \n",
       "std          0.230775        0.190057        0.271425        0.379168   \n",
       "min          0.000000        0.000000        0.000000        0.000000   \n",
       "25%          0.000000        0.000000        0.000000        1.000000   \n",
       "50%          0.000000        0.000000        0.000000        1.000000   \n",
       "75%          0.000000        0.000000        0.000000        1.000000   \n",
       "max          1.000000        1.000000        1.000000        1.000000   \n",
       "\n",
       "       v2psparban_ord_0  v2psparban_ord_1  v2psparban_ord_2  v2psparban_ord_3  \\\n",
       "count       3385.000000       3385.000000       3385.000000       3385.000000   \n",
       "mean           0.053471          0.029838          0.028951          0.887740   \n",
       "std            0.225004          0.170164          0.167694          0.315733   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            0.000000          0.000000          0.000000          1.000000   \n",
       "50%            0.000000          0.000000          0.000000          1.000000   \n",
       "75%            0.000000          0.000000          0.000000          1.000000   \n",
       "max            1.000000          1.000000          1.000000          1.000000   \n",
       "\n",
       "       v2psorgs_ord_0  v2psorgs_ord_1  ...  v2pepwrgen_ord_1  \\\n",
       "count     3385.000000     3385.000000  ...       3385.000000   \n",
       "mean         0.044018        0.150960  ...          0.230133   \n",
       "std          0.205165        0.358063  ...          0.420980   \n",
       "min          0.000000        0.000000  ...          0.000000   \n",
       "25%          0.000000        0.000000  ...          0.000000   \n",
       "50%          0.000000        0.000000  ...          0.000000   \n",
       "75%          0.000000        0.000000  ...          0.000000   \n",
       "max          1.000000        1.000000  ...          1.000000   \n",
       "\n",
       "       v2pepwrgen_ord_2  v2peedueq_ord_0  v2peedueq_ord_1  v2peedueq_ord_2  \\\n",
       "count       3385.000000      3385.000000      3385.000000      3385.000000   \n",
       "mean           0.730871         0.059970         0.312851         0.132939   \n",
       "std            0.443572         0.237467         0.463723         0.339559   \n",
       "min            0.000000         0.000000         0.000000         0.000000   \n",
       "25%            0.000000         0.000000         0.000000         0.000000   \n",
       "50%            1.000000         0.000000         0.000000         0.000000   \n",
       "75%            1.000000         0.000000         1.000000         0.000000   \n",
       "max            1.000000         1.000000         1.000000         1.000000   \n",
       "\n",
       "       v2peedueq_ord_3  v2pehealth_ord_0  v2pehealth_ord_1  v2pehealth_ord_2  \\\n",
       "count      3385.000000       3385.000000       3385.000000       3385.000000   \n",
       "mean          0.494239          0.038109          0.322304          0.145643   \n",
       "std           0.500041          0.191488          0.467428          0.352800   \n",
       "min           0.000000          0.000000          0.000000          0.000000   \n",
       "25%           0.000000          0.000000          0.000000          0.000000   \n",
       "50%           0.000000          0.000000          0.000000          0.000000   \n",
       "75%           1.000000          0.000000          1.000000          0.000000   \n",
       "max           1.000000          1.000000          1.000000          1.000000   \n",
       "\n",
       "       v2pehealth_ord_3  \n",
       "count       3385.000000  \n",
       "mean           0.493944  \n",
       "std            0.500037  \n",
       "min            0.000000  \n",
       "25%            0.000000  \n",
       "50%            0.000000  \n",
       "75%            1.000000  \n",
       "max            1.000000  \n",
       "\n",
       "[8 rows x 241 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_low_raw = data_2000[low_level_indicators]\n",
    "one_hots = []\n",
    "for indicator in low_level_indicators:\n",
    "    c = data_low_raw[indicator].values\n",
    "    n_bins = int(c.max())\n",
    "    kbin = KBinsDiscretizer(n_bins=n_bins, encode='onehot-dense', strategy='uniform')\n",
    "    c1h = kbin.fit_transform(c.reshape(-1, 1))\n",
    "    one_hots.append(c1h)\n",
    "\n",
    "new_indicator_names = []\n",
    "for clist, cname in zip(one_hots, low_level_indicators):\n",
    "    if clist.shape[1] > 1:\n",
    "        for i in range(clist.shape[1]):\n",
    "            new_indicator_names.append(f'{cname}_{i}')\n",
    "    else:\n",
    "        new_indicator_names.append(f'{cname}')\n",
    "\n",
    "data_low = pd.DataFrame(np.hstack(one_hots), columns=new_indicator_names)\n",
    "data_low.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fifteen-concept",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v2x_api</th>\n",
       "      <th>v2x_mpi</th>\n",
       "      <th>v2x_freexp_altinf</th>\n",
       "      <th>v2x_frassoc_thick</th>\n",
       "      <th>v2x_suffr</th>\n",
       "      <th>v2xel_frefair</th>\n",
       "      <th>v2x_elecoff</th>\n",
       "      <th>v2xcl_rol</th>\n",
       "      <th>v2x_cspart</th>\n",
       "      <th>v2xdl_delib</th>\n",
       "      <th>v2x_egal</th>\n",
       "      <th>v2xeg_eqprotec</th>\n",
       "      <th>v2xeg_eqaccess</th>\n",
       "      <th>v2xeg_eqdr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3385</td>\n",
       "      <td>3385</td>\n",
       "      <td>3385</td>\n",
       "      <td>3385</td>\n",
       "      <td>3385</td>\n",
       "      <td>3385</td>\n",
       "      <td>3385</td>\n",
       "      <td>3385</td>\n",
       "      <td>3385</td>\n",
       "      <td>3385</td>\n",
       "      <td>3385</td>\n",
       "      <td>3385</td>\n",
       "      <td>3385</td>\n",
       "      <td>3385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2696</td>\n",
       "      <td>2196</td>\n",
       "      <td>2605</td>\n",
       "      <td>2622</td>\n",
       "      <td>3322</td>\n",
       "      <td>1909</td>\n",
       "      <td>2934</td>\n",
       "      <td>2607</td>\n",
       "      <td>2669</td>\n",
       "      <td>2464</td>\n",
       "      <td>2398</td>\n",
       "      <td>2527</td>\n",
       "      <td>2392</td>\n",
       "      <td>2073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       v2x_api v2x_mpi v2x_freexp_altinf v2x_frassoc_thick v2x_suffr  \\\n",
       "count     3385    3385              3385              3385      3385   \n",
       "unique       2       2                 2                 2         2   \n",
       "top       True   False              True              True      True   \n",
       "freq      2696    2196              2605              2622      3322   \n",
       "\n",
       "       v2xel_frefair v2x_elecoff v2xcl_rol v2x_cspart v2xdl_delib v2x_egal  \\\n",
       "count           3385        3385      3385       3385        3385     3385   \n",
       "unique             2           2         2          2           2        2   \n",
       "top             True        True      True       True        True     True   \n",
       "freq            1909        2934      2607       2669        2464     2398   \n",
       "\n",
       "       v2xeg_eqprotec v2xeg_eqaccess v2xeg_eqdr  \n",
       "count            3385           3385       3385  \n",
       "unique              2              2          2  \n",
       "top              True           True       True  \n",
       "freq             2527           2392       2073  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mid = data_2000[mid_level_indicators] > 0.5\n",
    "data_mid.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adverse-conditions",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     3385\n",
       "unique       2\n",
       "top       True\n",
       "freq      1799\n",
       "Name: v2x_polyarchy, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_high = data_2000[high_level_indicators].iloc[:, 0] > 0.5\n",
    "data_high.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "undefined-invention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3385, 464])\n",
      "torch.Size([3385, 241])\n",
      "torch.Size([3385, 14])\n",
      "torch.Size([3385])\n"
     ]
    }
   ],
   "source": [
    "c0c = torch.FloatTensor(data_low_continuous.values)\n",
    "c0 = torch.FloatTensor(data_low.values)\n",
    "c1 = torch.FloatTensor(data_mid.values)\n",
    "c2 = torch.FloatTensor(data_high.values)\n",
    "print(c0c.shape)\n",
    "print(c0.shape)\n",
    "print(c1.shape)\n",
    "print(c2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-immunology",
   "metadata": {},
   "source": [
    "# Low-to-mid level explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "front-strip",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['v2psbars_ord_0', 'v2psbars_ord_1', 'v2psbars_ord_2', 'v2psbars_ord_3', 'v2psparban_ord_0']\n",
      "['v2x_api', 'v2x_mpi', 'v2x_freexp_altinf', 'v2x_frassoc_thick', 'v2x_suffr']\n"
     ]
    }
   ],
   "source": [
    "results_dir = 'results/vdem_low2mid'\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "mid_concepts = list(data_mid.columns)\n",
    "low_concepts = list(data_low.columns)\n",
    "n_rep = 10\n",
    "tot_epochs = 6001\n",
    "prune_epochs = 3001\n",
    "\n",
    "n_splits = 10\n",
    "seed = 42\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "x = c0\n",
    "xh = c1\n",
    "y = c2\n",
    "\n",
    "print(low_concepts[:5])\n",
    "print(mid_concepts[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-glossary",
   "metadata": {},
   "source": [
    "## Train loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "massive-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(x_train, y_train, need_pruning, seed, device, level, relu=False, verbose=False):\n",
    "    set_seed(seed)\n",
    "    x_train = x_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    \n",
    "    if level == 'mid':\n",
    "        layers = [\n",
    "            torch.nn.Linear(x_train.size(1), 50),\n",
    "            torch.nn.ReLU() if relu else torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(50, 30),\n",
    "            torch.nn.ReLU() if relu else torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(30, y_train.size(1)),\n",
    "            torch.nn.Sigmoid(),\n",
    "        ]\n",
    "        loss_form = torch.nn.BCELoss()\n",
    "    else:\n",
    "        layers = [\n",
    "            torch.nn.Linear(x_train.size(1), 20),\n",
    "            torch.nn.ReLU() if relu else torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(20, 10),\n",
    "            torch.nn.ReLU() if relu else torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(10, 1),\n",
    "            torch.nn.Sigmoid(),\n",
    "        ]\n",
    "        loss_form = torch.nn.BCELoss()\n",
    "            \n",
    "    model = torch.nn.Sequential(*layers).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "    model.train()\n",
    "    for epoch in range(tot_epochs):\n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_train).squeeze()\n",
    "        # Compute Loss\n",
    "        loss = loss_form(y_pred, y_train)\n",
    "\n",
    "        for module in model.children():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "#                 if level == 'mid':\n",
    "#                     loss += 0.0001 * torch.norm(module.weight, 1)\n",
    "#                     loss += 0.0001 * torch.norm(module.bias, 1)\n",
    "                if level == 'high':\n",
    "                    loss += 0.0001 * torch.norm(module.weight, 1)\n",
    "                    loss += 0.0001 * torch.norm(module.bias, 1)\n",
    "                break\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch > prune_epochs and need_pruning and level == 'high':\n",
    "            prune_features(model, n_classes=1, device=device)\n",
    "            need_pruning = False\n",
    "            \n",
    "        # compute accuracy\n",
    "        if epoch % 500 == 0 and verbose:\n",
    "            if level == 'mid':\n",
    "                y_pred_d = y_pred > 0.5\n",
    "                accuracy = y_pred_d.eq(y_train).sum().item() / (y_train.size(0) * y_train.size(1))\n",
    "                print(f'\\t Epoch {epoch}: train accuracy: {accuracy:.4f}')\n",
    "            else:\n",
    "                y_pred_d = y_pred > 0.5\n",
    "                accuracy = y_pred_d.eq(y_train).sum().item() / y_train.size(0)\n",
    "                print(f'\\t Epoch {epoch}: train accuracy: {accuracy:.4f}')\n",
    "#             if level == 'mid':\n",
    "#                 y_pred_d = y_pred > 0.5\n",
    "#                 accuracy = y_pred_d.eq(y_train).sum().item() / (y_train.size(0) * y_train.size(1))\n",
    "#                 print(f'\\t Epoch {epoch}: train accuracy: {accuracy:.4f}')\n",
    "#             else:\n",
    "#                 y_pred_d = torch.argmax(y_pred, dim=1)\n",
    "#                 accuracy = y_pred_d.eq(y_train).sum().item() / y_train.size(0)\n",
    "#                 print(f'\\t Epoch {epoch}: train accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "systematic-forest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_psi_nn(x_train, y_train, need_pruning, seed, device, level, verbose=False):\n",
    "    set_seed(seed)\n",
    "    x_train = x_train.to(device)\n",
    "    y_train = y_train.to(device).to(torch.float)\n",
    "\n",
    "    if level == 'mid':\n",
    "        layers = [\n",
    "            torch.nn.Linear(x_train.size(1), 50),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.Linear(50, 30),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.Linear(30, y_train.size(1)),\n",
    "            torch.nn.Sigmoid(),\n",
    "        ]\n",
    "    else:\n",
    "        layers = [\n",
    "            torch.nn.Linear(x_train.size(1), 10),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.Linear(10, 4),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.Linear(4, 1),\n",
    "            torch.nn.Sigmoid(),\n",
    "        ]\n",
    "            \n",
    "    model = torch.nn.Sequential(*layers).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_form = torch.nn.BCELoss()\n",
    "    model.train()\n",
    "    for epoch in range(tot_epochs):\n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_train).squeeze()\n",
    "        # Compute Loss\n",
    "        loss = loss_form(y_pred, y_train)\n",
    "\n",
    "        for module in model.children():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                loss += 0.00001 * torch.norm(module.weight, 1)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch > prune_epochs and need_pruning:\n",
    "            model = prune_equal_fanin(model, 2, validate=True, device=device)\n",
    "            need_pruning = False\n",
    "            \n",
    "        # compute accuracy\n",
    "        if epoch % 500 == 0 and verbose:\n",
    "            if level == 'mid':\n",
    "                y_pred_d = y_pred > 0.5\n",
    "                accuracy = y_pred_d.eq(y_train).sum().item() / (y_train.size(0) * y_train.size(1))\n",
    "                print(f'\\t Epoch {epoch}: train accuracy: {accuracy:.4f}')\n",
    "            else:\n",
    "                y_pred_d = y_pred > 0.5\n",
    "                accuracy = y_pred_d.eq(y_train).sum().item() / y_train.size(0)\n",
    "                print(f'\\t Epoch {epoch}: train accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "assisted-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_to_y(method, need_pruning, relu, verbose=False):\n",
    "    methods = []\n",
    "    splits = []\n",
    "    explanations = []\n",
    "    explanations_inv = []\n",
    "    model_accuracies_mid = []\n",
    "    model_accuracies_top = []\n",
    "    explanation_accuracies = []\n",
    "    explanation_accuracies_inv = []\n",
    "    elapsed_times = []\n",
    "    elapsed_times_inv = []\n",
    "    explanation_fidelities = []\n",
    "    explanation_complexities = []\n",
    "    for split, (train_index, test_index) in enumerate(skf.split(x.cpu().detach().numpy(), y.cpu().detach().numpy())):\n",
    "        print(f'Split [{split+1}/{n_splits}]')\n",
    "        x_train, x_test = torch.FloatTensor(x[train_index]), torch.FloatTensor(x[test_index])\n",
    "        xh_train, xh_test = torch.FloatTensor(xh[train_index]), torch.FloatTensor(xh[test_index])\n",
    "        y_train, y_test = torch.FloatTensor(y[train_index]), torch.FloatTensor(y[test_index])\n",
    "    \n",
    "        explanation, explanation_inv = '', ''\n",
    "        explanation_accuracy, explanation_accuracy_inv = 0, 0\n",
    "        elapsed_time, elapsed_time_inv = 0, 0\n",
    "        \n",
    "        if method == 'tree':\n",
    "            classifier = DecisionTreeRegressor(random_state=seed)\n",
    "            classifier.fit(x_train.cpu().detach().numpy(), xh_train.cpu().detach().numpy())\n",
    "            xh_train_preds = classifier.predict(x_train.cpu().detach().numpy())\n",
    "            xh_test_preds = classifier.predict(x_test.cpu().detach().numpy())\n",
    "            \n",
    "            classifier_h = DecisionTreeClassifier(random_state=seed)\n",
    "            classifier_h.fit(xh_train_preds, y_train)\n",
    "            y_preds = classifier_h.predict(xh_test_preds)\n",
    "            \n",
    "            model_accuracy_mid = accuracy_score(xh_test.cpu().detach().numpy(), xh_test_preds>0.5)\n",
    "            model_accuracy_top = accuracy_score(y_test.cpu().detach().numpy(), y_preds)\n",
    "\n",
    "            target_class = 1\n",
    "            start = time.time()\n",
    "            explanation = tree_to_formula(classifier_h, mid_concepts, target_class)\n",
    "            elapsed_time = time.time() - start\n",
    "            explanation_accuracy = model_accuracy_top\n",
    "            explanation_fidelity = accuracy_score(y_test.cpu().detach().numpy(), y_preds)\n",
    "            explanation_complexity = dl.logic.complexity(explanation)\n",
    "        \n",
    "        elif method == 'brl':\n",
    "            level = 'mid'\n",
    "            model = train_nn(x_train, xh_train, need_pruning=False, seed=seed, device=device, \n",
    "                             level=level, relu=False, verbose=verbose)\n",
    "            xh_train_preds = model(x_train.to(device)).cpu().detach().numpy()\n",
    "            xh_test_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "            xh_train_preds = torch.FloatTensor(xh_train_preds)\n",
    "            xh_test_preds = torch.FloatTensor(xh_test_preds)\n",
    "\n",
    "            y_train2 = torch.zeros((y_train.shape[0], 2))\n",
    "            y_train2[:, 0] = 1-y_train\n",
    "            y_train2[:, 1] = y_train\n",
    "            train_dataset = TensorDataset(xh_train_preds, y_train2)\n",
    "            test_dataset = TensorDataset(xh_test_preds, y_test)\n",
    "            dummy_concepts = [f'feature{i:010}' for i in range(len(mid_concepts))]\n",
    "            model = XBRLClassifier(name=os.path.join(results_dir, f'{method}_{split}'), \n",
    "                                   n_classes=len(y_train.unique()), \n",
    "                                   n_features=x_train.shape[1], feature_names=dummy_concepts, \n",
    "                                   class_names=['~democrat', 'democrat'], discretize=True)\n",
    "            results = model.fit(train_dataset, metric=accuracy_score, save=True)\n",
    "            model_accuracy_mid = 0\n",
    "            model_accuracy_top = model.evaluate(test_dataset)\n",
    "            target_class = 1\n",
    "            global_explanation, elapsed_time = model.get_global_explanation(target_class, concepts=dummy_concepts, return_time=True)\n",
    "            explanation_fidelity = 0\n",
    "            explanation_complexity = 0\n",
    "            if global_explanation:\n",
    "                explanation = logic.base.replace_names(global_explanation, mid_concepts)\n",
    "                explanation_accuracy, y_formula = logic.base.test_explanation(global_explanation, \n",
    "                                                                              target_class, \n",
    "                                                                              x=xh_test, y=y_test,\n",
    "                                                                              metric=accuracy_score)\n",
    "                explanation_fidelity = dl.logic.fidelity(y_formula, y_test)\n",
    "                explanation_complexity = dl.logic.complexity(global_explanation)\n",
    "                \n",
    "        else:\n",
    "            if method == 'psi':\n",
    "                # positive class\n",
    "                target_class = 1\n",
    "                level = 'mid'\n",
    "                model = train_psi_nn(x_train, xh_train, need_pruning, split, device, level, verbose)\n",
    "                xh_train_preds = model(x_train.to(device)).cpu().detach().numpy()\n",
    "                xh_test_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "                xh_train_preds = torch.FloatTensor(xh_train_preds)\n",
    "                xh_test_preds = torch.FloatTensor(xh_test_preds)\n",
    "\n",
    "                level = 'high'\n",
    "                model_h = train_psi_nn(xh_train_preds, y_train, need_pruning, split, device, level, verbose)\n",
    "                y_train_preds = model_h(xh_train_preds.to(device)).cpu().detach().numpy()\n",
    "                y_test_preds = model_h(xh_test_preds.to(device)).cpu().detach().numpy()\n",
    "\n",
    "                model_accuracy_mid = accuracy_score(xh_test.cpu().detach().numpy(), xh_test_preds>0.5)\n",
    "                model_accuracy_top = accuracy_score(y_test.cpu().detach().numpy(), y_test_preds>0.5)\n",
    "\n",
    "            else:\n",
    "                level = 'mid'\n",
    "                model = train_nn(x_train, xh_train, need_pruning, seed, device, level, relu, verbose)\n",
    "                xh_train_preds = model(x_train.to(device)).cpu().detach().numpy()\n",
    "                xh_test_preds = model(x_test.to(device)).cpu().detach().numpy()\n",
    "                xh_train_preds = torch.FloatTensor(xh_train_preds)\n",
    "                xh_test_preds = torch.FloatTensor(xh_test_preds)\n",
    "\n",
    "                level = 'high'\n",
    "                model_h = train_nn(xh_train_preds, y_train, need_pruning, seed, device, level, relu, verbose)\n",
    "                y_train_preds = model_h(xh_train_preds.to(device)).cpu().detach().numpy()\n",
    "                y_test_preds = model_h(xh_test_preds.to(device)).cpu().detach().numpy()\n",
    "\n",
    "                model_accuracy_mid = accuracy_score(xh_test.cpu().detach().numpy(), xh_test_preds>0.5)\n",
    "                model_accuracy_top = accuracy_score(y_test.cpu().detach().numpy(), y_test_preds>0.5)\n",
    "\n",
    "            # positive class\n",
    "            target_class = 1\n",
    "            start = time.time()\n",
    "            if method == 'psi':\n",
    "                global_explanation = logic.generate_fol_explanations(model_h, device)[0]\n",
    "            else:\n",
    "                global_explanation, _, _ = logic.relu_nn.combine_local_explanations(model_h, \n",
    "                                                                                    xh_train.to(device), y_train.to(device), \n",
    "                                                                                    target_class=target_class,\n",
    "                                                                                    topk_explanations=2,\n",
    "                                                                                    method=method, device=device)\n",
    "            elapsed_time = time.time() - start\n",
    "\n",
    "            explanation_fidelity = 0\n",
    "            explanation_complexity = 0\n",
    "            if global_explanation:\n",
    "                explanation = logic.base.replace_names(global_explanation, mid_concepts)\n",
    "                explanation_accuracy, y_formula = logic.base.test_explanation(global_explanation, \n",
    "                                                                              target_class, \n",
    "                                                                              x=xh_test, y=y_test,\n",
    "                                                                              metric=accuracy_score)\n",
    "                explanation_fidelity = dl.logic.fidelity(y_formula, y_test)\n",
    "                explanation_complexity = dl.logic.complexity(global_explanation)\n",
    "\n",
    "        if verbose:\n",
    "            print(f'\\t Model\\'s accuracy (mid): {model_accuracy_mid:.4f} - Model\\'s accuracy (top): {model_accuracy_top:.4f}')\n",
    "            print(f'\\t Class {target_class} - Global explanation: \"{explanation}\" - Accuracy: {explanation_accuracy:.4f}')\n",
    "            print(f'\\t Elapsed time {elapsed_time}')\n",
    "            print(f'\\t Fidelity: \"{explanation_fidelity:.4f}\" - Complexity: \"{explanation_complexity}\"')\n",
    "\n",
    "        methods.append(method)\n",
    "        splits.append(split)\n",
    "        explanations.append(explanation)\n",
    "        model_accuracies_mid.append(model_accuracy_mid)\n",
    "        model_accuracies_top.append(model_accuracy_top)\n",
    "        explanation_accuracies.append(explanation_accuracy)\n",
    "        explanation_fidelities.append(explanation_fidelity)\n",
    "        explanation_complexities.append(explanation_complexity)\n",
    "        elapsed_times.append(elapsed_time)\n",
    "    \n",
    "    explanation_consistency = dl.logic.formula_consistency(explanations)\n",
    "    print(f'Consistency of explanations: {explanation_consistency:.4f}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'method': methods,\n",
    "        'split': splits,\n",
    "        'explanation': explanations,\n",
    "        'model_accuracy_mid': model_accuracies_mid,\n",
    "        'model_accuracy_top': model_accuracies_top,\n",
    "        'explanation_accuracy': explanation_accuracies,\n",
    "        'explanation_fidelity': explanation_fidelities,\n",
    "        'explanation_complexity': explanation_complexities,\n",
    "        'explanation_consistency': explanation_consistency,\n",
    "        'elapsed_time': elapsed_times,\n",
    "    })\n",
    "    results.to_csv(os.path.join(results_dir, f'results_{method}.csv'))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-absorption",
   "metadata": {},
   "source": [
    "## General pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "naughty-stevens",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split [1/10]\n",
      "\t Epoch 0: train accuracy: 0.5213\n",
      "\t Epoch 500: train accuracy: 0.9802\n",
      "\t Epoch 1000: train accuracy: 0.9908\n",
      "\t Epoch 1500: train accuracy: 0.9946\n",
      "\t Epoch 2000: train accuracy: 0.9962\n",
      "\t Epoch 2500: train accuracy: 0.9966\n",
      "\t Epoch 3000: train accuracy: 0.9968\n",
      "\t Epoch 3500: train accuracy: 0.9968\n",
      "\t Epoch 4000: train accuracy: 0.9968\n",
      "\t Epoch 4500: train accuracy: 0.9968\n",
      "\t Epoch 5000: train accuracy: 0.9968\n",
      "\t Epoch 5500: train accuracy: 0.9968\n",
      "\t Epoch 6000: train accuracy: 0.9968\n",
      "\t Epoch 0: train accuracy: 0.4685\n",
      "\t Epoch 500: train accuracy: 0.9471\n",
      "\t Epoch 1000: train accuracy: 0.9475\n",
      "\t Epoch 1500: train accuracy: 0.9475\n",
      "\t Epoch 2000: train accuracy: 0.9475\n",
      "\t Epoch 2500: train accuracy: 0.9481\n",
      "\t Epoch 3000: train accuracy: 0.9481\n",
      "\t Epoch 3500: train accuracy: 0.9471\n",
      "\t Epoch 4000: train accuracy: 0.9471\n",
      "\t Epoch 4500: train accuracy: 0.9471\n",
      "\t Epoch 5000: train accuracy: 0.9471\n",
      "\t Epoch 5500: train accuracy: 0.9471\n",
      "\t Epoch 6000: train accuracy: 0.9471\n",
      "\t Model's accuracy (mid): 0.7552 - Model's accuracy (top): 0.9263\n",
      "\t Class 1 - Global explanation: \"v2x_freexp_altinf & v2x_frassoc_thick & v2xel_frefair & v2x_elecoff & v2xcl_rol & v2x_egal & v2xeg_eqaccess\" - Accuracy: 0.9174\n",
      "\t Elapsed time 2.743628740310669\n",
      "\t Fidelity: \"0.9174\" - Complexity: \"7\"\n",
      "Split [2/10]\n",
      "\t Epoch 0: train accuracy: 0.5215\n",
      "\t Epoch 500: train accuracy: 0.9804\n",
      "\t Epoch 1000: train accuracy: 0.9912\n",
      "\t Epoch 1500: train accuracy: 0.9949\n",
      "\t Epoch 2000: train accuracy: 0.9965\n",
      "\t Epoch 2500: train accuracy: 0.9969\n",
      "\t Epoch 3000: train accuracy: 0.9970\n",
      "\t Epoch 3500: train accuracy: 0.9970\n",
      "\t Epoch 4000: train accuracy: 0.9970\n",
      "\t Epoch 4500: train accuracy: 0.9970\n",
      "\t Epoch 5000: train accuracy: 0.9970\n",
      "\t Epoch 5500: train accuracy: 0.9970\n",
      "\t Epoch 6000: train accuracy: 0.9970\n",
      "\t Epoch 0: train accuracy: 0.4685\n",
      "\t Epoch 500: train accuracy: 0.9455\n",
      "\t Epoch 1000: train accuracy: 0.9455\n",
      "\t Epoch 1500: train accuracy: 0.9455\n",
      "\t Epoch 2000: train accuracy: 0.9471\n",
      "\t Epoch 2500: train accuracy: 0.9478\n",
      "\t Epoch 3000: train accuracy: 0.9488\n",
      "\t Epoch 3500: train accuracy: 0.9468\n",
      "\t Epoch 4000: train accuracy: 0.9471\n",
      "\t Epoch 4500: train accuracy: 0.9471\n",
      "\t Epoch 5000: train accuracy: 0.9471\n",
      "\t Epoch 5500: train accuracy: 0.9471\n",
      "\t Epoch 6000: train accuracy: 0.9478\n",
      "\t Model's accuracy (mid): 0.7581 - Model's accuracy (top): 0.9440\n",
      "\t Class 1 - Global explanation: \"v2x_freexp_altinf & v2x_frassoc_thick & v2xel_frefair & v2x_elecoff & v2xcl_rol & v2x_cspart & v2xdl_delib & v2x_egal & v2xeg_eqaccess & v2xeg_eqdr\" - Accuracy: 0.8702\n",
      "\t Elapsed time 3.7140719890594482\n",
      "\t Fidelity: \"0.8702\" - Complexity: \"10\"\n",
      "Split [3/10]\n",
      "\t Epoch 0: train accuracy: 0.5211\n",
      "\t Epoch 500: train accuracy: 0.9803\n",
      "\t Epoch 1000: train accuracy: 0.9912\n",
      "\t Epoch 1500: train accuracy: 0.9951\n",
      "\t Epoch 2000: train accuracy: 0.9961\n",
      "\t Epoch 2500: train accuracy: 0.9967\n",
      "\t Epoch 3000: train accuracy: 0.9970\n",
      "\t Epoch 3500: train accuracy: 0.9970\n",
      "\t Epoch 4000: train accuracy: 0.9970\n",
      "\t Epoch 4500: train accuracy: 0.9970\n",
      "\t Epoch 5000: train accuracy: 0.9970\n",
      "\t Epoch 5500: train accuracy: 0.9971\n",
      "\t Epoch 6000: train accuracy: 0.9971\n",
      "\t Epoch 0: train accuracy: 0.4685\n",
      "\t Epoch 500: train accuracy: 0.9478\n",
      "\t Epoch 1000: train accuracy: 0.9485\n",
      "\t Epoch 1500: train accuracy: 0.9485\n",
      "\t Epoch 2000: train accuracy: 0.9485\n",
      "\t Epoch 2500: train accuracy: 0.9491\n",
      "\t Epoch 3000: train accuracy: 0.9498\n",
      "\t Epoch 3500: train accuracy: 0.8802\n",
      "\t Epoch 4000: train accuracy: 0.8795\n",
      "\t Epoch 4500: train accuracy: 0.8795\n",
      "\t Epoch 5000: train accuracy: 0.8795\n",
      "\t Epoch 5500: train accuracy: 0.8798\n",
      "\t Epoch 6000: train accuracy: 0.8798\n",
      "\t Model's accuracy (mid): 0.7493 - Model's accuracy (top): 0.8673\n",
      "\t Class 1 - Global explanation: \"(v2x_mpi & v2x_freexp_altinf & v2x_frassoc_thick & v2x_elecoff & v2xcl_rol & v2xeg_eqdr) | (v2x_freexp_altinf & v2x_frassoc_thick & v2x_elecoff & v2xcl_rol & ~v2x_mpi & ~v2xeg_eqdr)\" - Accuracy: 0.8171\n",
      "\t Elapsed time 2.5072710514068604\n",
      "\t Fidelity: \"0.8171\" - Complexity: \"12\"\n",
      "Split [4/10]\n",
      "\t Epoch 0: train accuracy: 0.5210\n",
      "\t Epoch 500: train accuracy: 0.9804\n",
      "\t Epoch 1000: train accuracy: 0.9910\n",
      "\t Epoch 1500: train accuracy: 0.9948\n",
      "\t Epoch 2000: train accuracy: 0.9964\n",
      "\t Epoch 2500: train accuracy: 0.9968\n",
      "\t Epoch 3000: train accuracy: 0.9968\n",
      "\t Epoch 3500: train accuracy: 0.9969\n",
      "\t Epoch 4000: train accuracy: 0.9969\n",
      "\t Epoch 4500: train accuracy: 0.9969\n",
      "\t Epoch 5000: train accuracy: 0.9969\n",
      "\t Epoch 5500: train accuracy: 0.9969\n",
      "\t Epoch 6000: train accuracy: 0.9969\n",
      "\t Epoch 0: train accuracy: 0.4685\n",
      "\t Epoch 500: train accuracy: 0.9478\n",
      "\t Epoch 1000: train accuracy: 0.9468\n",
      "\t Epoch 1500: train accuracy: 0.9478\n",
      "\t Epoch 2000: train accuracy: 0.9488\n",
      "\t Epoch 2500: train accuracy: 0.9498\n",
      "\t Epoch 3000: train accuracy: 0.9498\n",
      "\t Epoch 3500: train accuracy: 0.9485\n",
      "\t Epoch 4000: train accuracy: 0.9478\n",
      "\t Epoch 4500: train accuracy: 0.9481\n",
      "\t Epoch 5000: train accuracy: 0.9481\n",
      "\t Epoch 5500: train accuracy: 0.9481\n",
      "\t Epoch 6000: train accuracy: 0.9488\n",
      "\t Model's accuracy (mid): 0.7434 - Model's accuracy (top): 0.9086\n",
      "\t Class 1 - Global explanation: \"v2x_freexp_altinf & v2x_frassoc_thick & v2xel_frefair & v2x_elecoff & v2xcl_rol & v2xdl_delib & v2x_egal & v2xeg_eqdr\" - Accuracy: 0.8319\n",
      "\t Elapsed time 2.9152486324310303\n",
      "\t Fidelity: \"0.8319\" - Complexity: \"8\"\n",
      "Split [5/10]\n",
      "\t Epoch 0: train accuracy: 0.5208\n",
      "\t Epoch 500: train accuracy: 0.9809\n",
      "\t Epoch 1000: train accuracy: 0.9912\n",
      "\t Epoch 1500: train accuracy: 0.9950\n",
      "\t Epoch 2000: train accuracy: 0.9963\n",
      "\t Epoch 2500: train accuracy: 0.9968\n",
      "\t Epoch 3000: train accuracy: 0.9970\n",
      "\t Epoch 3500: train accuracy: 0.9970\n",
      "\t Epoch 4000: train accuracy: 0.9970\n",
      "\t Epoch 4500: train accuracy: 0.9970\n",
      "\t Epoch 5000: train accuracy: 0.9970\n",
      "\t Epoch 5500: train accuracy: 0.9970\n",
      "\t Epoch 6000: train accuracy: 0.9970\n",
      "\t Epoch 0: train accuracy: 0.4685\n",
      "\t Epoch 500: train accuracy: 0.9462\n",
      "\t Epoch 1000: train accuracy: 0.9478\n",
      "\t Epoch 1500: train accuracy: 0.9475\n",
      "\t Epoch 2000: train accuracy: 0.9485\n",
      "\t Epoch 2500: train accuracy: 0.9481\n",
      "\t Epoch 3000: train accuracy: 0.9494\n",
      "\t Epoch 3500: train accuracy: 0.9452\n",
      "\t Epoch 4000: train accuracy: 0.9452\n",
      "\t Epoch 4500: train accuracy: 0.9455\n",
      "\t Epoch 5000: train accuracy: 0.9455\n",
      "\t Epoch 5500: train accuracy: 0.9455\n",
      "\t Epoch 6000: train accuracy: 0.9455\n",
      "\t Model's accuracy (mid): 0.7463 - Model's accuracy (top): 0.9381\n",
      "\t Class 1 - Global explanation: \"v2x_freexp_altinf & v2x_frassoc_thick & v2xel_frefair & v2x_elecoff & v2xcl_rol & v2xdl_delib & v2xeg_eqaccess\" - Accuracy: 0.9351\n",
      "\t Elapsed time 2.7137863636016846\n",
      "\t Fidelity: \"0.9351\" - Complexity: \"7\"\n",
      "Split [6/10]\n",
      "\t Epoch 0: train accuracy: 0.5217\n",
      "\t Epoch 500: train accuracy: 0.9812\n",
      "\t Epoch 1000: train accuracy: 0.9915\n",
      "\t Epoch 1500: train accuracy: 0.9952\n",
      "\t Epoch 2000: train accuracy: 0.9962\n",
      "\t Epoch 2500: train accuracy: 0.9967\n",
      "\t Epoch 3000: train accuracy: 0.9968\n",
      "\t Epoch 3500: train accuracy: 0.9968\n",
      "\t Epoch 4000: train accuracy: 0.9968\n",
      "\t Epoch 4500: train accuracy: 0.9968\n",
      "\t Epoch 5000: train accuracy: 0.9968\n",
      "\t Epoch 5500: train accuracy: 0.9968\n",
      "\t Epoch 6000: train accuracy: 0.9968\n",
      "\t Epoch 0: train accuracy: 0.4687\n",
      "\t Epoch 500: train accuracy: 0.9472\n",
      "\t Epoch 1000: train accuracy: 0.9478\n",
      "\t Epoch 1500: train accuracy: 0.9485\n",
      "\t Epoch 2000: train accuracy: 0.9488\n",
      "\t Epoch 2500: train accuracy: 0.9488\n",
      "\t Epoch 3000: train accuracy: 0.9501\n",
      "\t Epoch 3500: train accuracy: 0.9491\n",
      "\t Epoch 4000: train accuracy: 0.9491\n",
      "\t Epoch 4500: train accuracy: 0.9498\n",
      "\t Epoch 5000: train accuracy: 0.9501\n",
      "\t Epoch 5500: train accuracy: 0.9501\n",
      "\t Epoch 6000: train accuracy: 0.9501\n",
      "\t Model's accuracy (mid): 0.7160 - Model's accuracy (top): 0.9142\n",
      "\t Class 1 - Global explanation: \"v2x_freexp_altinf & v2x_frassoc_thick & v2xel_frefair & v2x_elecoff & v2xcl_rol & v2xdl_delib & v2x_egal & v2xeg_eqprotec & v2xeg_eqaccess & v2xeg_eqdr\" - Accuracy: 0.8343\n",
      "\t Elapsed time 3.899576187133789\n",
      "\t Fidelity: \"0.8343\" - Complexity: \"10\"\n",
      "Split [7/10]\n",
      "\t Epoch 0: train accuracy: 0.5214\n",
      "\t Epoch 500: train accuracy: 0.9798\n",
      "\t Epoch 1000: train accuracy: 0.9912\n",
      "\t Epoch 1500: train accuracy: 0.9948\n",
      "\t Epoch 2000: train accuracy: 0.9961\n",
      "\t Epoch 2500: train accuracy: 0.9966\n",
      "\t Epoch 3000: train accuracy: 0.9968\n",
      "\t Epoch 3500: train accuracy: 0.9969\n",
      "\t Epoch 4000: train accuracy: 0.9969\n",
      "\t Epoch 4500: train accuracy: 0.9969\n",
      "\t Epoch 5000: train accuracy: 0.9969\n",
      "\t Epoch 5500: train accuracy: 0.9969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 6000: train accuracy: 0.9969\n",
      "\t Epoch 0: train accuracy: 0.4687\n",
      "\t Epoch 500: train accuracy: 0.9475\n",
      "\t Epoch 1000: train accuracy: 0.9465\n",
      "\t Epoch 1500: train accuracy: 0.9475\n",
      "\t Epoch 2000: train accuracy: 0.9485\n",
      "\t Epoch 2500: train accuracy: 0.9498\n",
      "\t Epoch 3000: train accuracy: 0.9498\n",
      "\t Epoch 3500: train accuracy: 0.8595\n",
      "\t Epoch 4000: train accuracy: 0.8595\n",
      "\t Epoch 4500: train accuracy: 0.8595\n",
      "\t Epoch 5000: train accuracy: 0.8599\n",
      "\t Epoch 5500: train accuracy: 0.8602\n",
      "\t Epoch 6000: train accuracy: 0.8625\n",
      "\t Model's accuracy (mid): 0.7278 - Model's accuracy (top): 0.8521\n",
      "\t Class 1 - Global explanation: \"(v2x_mpi & v2x_freexp_altinf & v2x_elecoff & v2xcl_rol & v2xeg_eqdr) | (v2x_freexp_altinf & v2x_elecoff & v2xcl_rol & ~v2x_mpi & ~v2xeg_eqdr)\" - Accuracy: 0.7988\n",
      "\t Elapsed time 2.4165401458740234\n",
      "\t Fidelity: \"0.7988\" - Complexity: \"10\"\n",
      "Split [8/10]\n",
      "\t Epoch 0: train accuracy: 0.5217\n",
      "\t Epoch 500: train accuracy: 0.9808\n",
      "\t Epoch 1000: train accuracy: 0.9917\n",
      "\t Epoch 1500: train accuracy: 0.9953\n",
      "\t Epoch 2000: train accuracy: 0.9965\n",
      "\t Epoch 2500: train accuracy: 0.9969\n",
      "\t Epoch 3000: train accuracy: 0.9970\n",
      "\t Epoch 3500: train accuracy: 0.9970\n",
      "\t Epoch 4000: train accuracy: 0.9970\n",
      "\t Epoch 4500: train accuracy: 0.9971\n",
      "\t Epoch 5000: train accuracy: 0.9971\n",
      "\t Epoch 5500: train accuracy: 0.9971\n",
      "\t Epoch 6000: train accuracy: 0.9971\n",
      "\t Epoch 0: train accuracy: 0.4687\n",
      "\t Epoch 500: train accuracy: 0.9455\n",
      "\t Epoch 1000: train accuracy: 0.9462\n",
      "\t Epoch 1500: train accuracy: 0.9462\n",
      "\t Epoch 2000: train accuracy: 0.9465\n",
      "\t Epoch 2500: train accuracy: 0.9468\n",
      "\t Epoch 3000: train accuracy: 0.9475\n",
      "\t Epoch 3500: train accuracy: 0.9458\n",
      "\t Epoch 4000: train accuracy: 0.9452\n",
      "\t Epoch 4500: train accuracy: 0.9458\n",
      "\t Epoch 5000: train accuracy: 0.9465\n",
      "\t Epoch 5500: train accuracy: 0.9465\n",
      "\t Epoch 6000: train accuracy: 0.9468\n",
      "\t Model's accuracy (mid): 0.7337 - Model's accuracy (top): 0.9231\n",
      "\t Class 1 - Global explanation: \"v2x_freexp_altinf & v2x_frassoc_thick & v2xel_frefair & v2x_elecoff & v2xcl_rol & v2x_egal & v2xeg_eqdr\" - Accuracy: 0.8432\n",
      "\t Elapsed time 2.666849136352539\n",
      "\t Fidelity: \"0.8432\" - Complexity: \"7\"\n",
      "Split [9/10]\n",
      "\t Epoch 0: train accuracy: 0.5207\n",
      "\t Epoch 500: train accuracy: 0.9803\n",
      "\t Epoch 1000: train accuracy: 0.9911\n",
      "\t Epoch 1500: train accuracy: 0.9951\n",
      "\t Epoch 2000: train accuracy: 0.9966\n",
      "\t Epoch 2500: train accuracy: 0.9969\n",
      "\t Epoch 3000: train accuracy: 0.9970\n",
      "\t Epoch 3500: train accuracy: 0.9970\n",
      "\t Epoch 4000: train accuracy: 0.9970\n",
      "\t Epoch 4500: train accuracy: 0.9970\n",
      "\t Epoch 5000: train accuracy: 0.9970\n",
      "\t Epoch 5500: train accuracy: 0.9971\n",
      "\t Epoch 6000: train accuracy: 0.9971\n",
      "\t Epoch 0: train accuracy: 0.4687\n",
      "\t Epoch 500: train accuracy: 0.9478\n",
      "\t Epoch 1000: train accuracy: 0.9478\n",
      "\t Epoch 1500: train accuracy: 0.9485\n",
      "\t Epoch 2000: train accuracy: 0.9491\n",
      "\t Epoch 2500: train accuracy: 0.9498\n",
      "\t Epoch 3000: train accuracy: 0.9501\n",
      "\t Epoch 3500: train accuracy: 0.9439\n",
      "\t Epoch 4000: train accuracy: 0.9432\n",
      "\t Epoch 4500: train accuracy: 0.9439\n",
      "\t Epoch 5000: train accuracy: 0.9439\n",
      "\t Epoch 5500: train accuracy: 0.9442\n",
      "\t Epoch 6000: train accuracy: 0.9442\n",
      "\t Model's accuracy (mid): 0.6953 - Model's accuracy (top): 0.9112\n",
      "\t Class 1 - Global explanation: \"v2x_freexp_altinf & v2xel_frefair & v2x_elecoff & v2xcl_rol & v2xdl_delib & v2x_egal & v2xeg_eqprotec & v2xeg_eqdr\" - Accuracy: 0.8107\n",
      "\t Elapsed time 2.9741101264953613\n",
      "\t Fidelity: \"0.8107\" - Complexity: \"8\"\n",
      "Split [10/10]\n",
      "\t Epoch 0: train accuracy: 0.5217\n",
      "\t Epoch 500: train accuracy: 0.9802\n",
      "\t Epoch 1000: train accuracy: 0.9904\n",
      "\t Epoch 1500: train accuracy: 0.9948\n",
      "\t Epoch 2000: train accuracy: 0.9959\n",
      "\t Epoch 2500: train accuracy: 0.9967\n",
      "\t Epoch 3000: train accuracy: 0.9968\n",
      "\t Epoch 3500: train accuracy: 0.9969\n",
      "\t Epoch 4000: train accuracy: 0.9969\n",
      "\t Epoch 4500: train accuracy: 0.9969\n",
      "\t Epoch 5000: train accuracy: 0.9969\n",
      "\t Epoch 5500: train accuracy: 0.9969\n",
      "\t Epoch 6000: train accuracy: 0.9969\n",
      "\t Epoch 0: train accuracy: 0.4683\n",
      "\t Epoch 500: train accuracy: 0.9475\n",
      "\t Epoch 1000: train accuracy: 0.9475\n",
      "\t Epoch 1500: train accuracy: 0.9481\n",
      "\t Epoch 2000: train accuracy: 0.9488\n",
      "\t Epoch 2500: train accuracy: 0.9491\n",
      "\t Epoch 3000: train accuracy: 0.9491\n",
      "\t Epoch 3500: train accuracy: 0.9485\n",
      "\t Epoch 4000: train accuracy: 0.9485\n",
      "\t Epoch 4500: train accuracy: 0.9485\n",
      "\t Epoch 5000: train accuracy: 0.9488\n",
      "\t Epoch 5500: train accuracy: 0.9485\n",
      "\t Epoch 6000: train accuracy: 0.9488\n",
      "\t Model's accuracy (mid): 0.7722 - Model's accuracy (top): 0.9231\n",
      "\t Class 1 - Global explanation: \"(v2x_mpi & v2x_freexp_altinf & v2x_frassoc_thick & v2xel_frefair & v2x_elecoff & v2xcl_rol & v2xeg_eqdr) | (v2x_freexp_altinf & v2x_frassoc_thick & v2xel_frefair & v2x_elecoff & v2xcl_rol & ~v2x_mpi & ~v2xeg_eqdr)\" - Accuracy: 0.8521\n",
      "\t Elapsed time 2.577124834060669\n",
      "\t Fidelity: \"0.8521\" - Complexity: \"14\"\n",
      "Consistency of explanations: 0.6250\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>model_accuracy_mid</th>\n",
       "      <th>model_accuracy_top</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_fidelity</th>\n",
       "      <th>explanation_complexity</th>\n",
       "      <th>explanation_consistency</th>\n",
       "      <th>elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pruning</td>\n",
       "      <td>0</td>\n",
       "      <td>v2x_freexp_altinf &amp; v2x_frassoc_thick &amp; v2xel_...</td>\n",
       "      <td>0.755162</td>\n",
       "      <td>0.926254</td>\n",
       "      <td>0.917404</td>\n",
       "      <td>0.917404</td>\n",
       "      <td>7</td>\n",
       "      <td>0.625</td>\n",
       "      <td>2.743629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pruning</td>\n",
       "      <td>1</td>\n",
       "      <td>v2x_freexp_altinf &amp; v2x_frassoc_thick &amp; v2xel_...</td>\n",
       "      <td>0.758112</td>\n",
       "      <td>0.943953</td>\n",
       "      <td>0.870206</td>\n",
       "      <td>0.870206</td>\n",
       "      <td>10</td>\n",
       "      <td>0.625</td>\n",
       "      <td>3.714072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pruning</td>\n",
       "      <td>2</td>\n",
       "      <td>(v2x_mpi &amp; v2x_freexp_altinf &amp; v2x_frassoc_thi...</td>\n",
       "      <td>0.749263</td>\n",
       "      <td>0.867257</td>\n",
       "      <td>0.817109</td>\n",
       "      <td>0.817109</td>\n",
       "      <td>12</td>\n",
       "      <td>0.625</td>\n",
       "      <td>2.507271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pruning</td>\n",
       "      <td>3</td>\n",
       "      <td>v2x_freexp_altinf &amp; v2x_frassoc_thick &amp; v2xel_...</td>\n",
       "      <td>0.743363</td>\n",
       "      <td>0.908555</td>\n",
       "      <td>0.831858</td>\n",
       "      <td>0.831858</td>\n",
       "      <td>8</td>\n",
       "      <td>0.625</td>\n",
       "      <td>2.915249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pruning</td>\n",
       "      <td>4</td>\n",
       "      <td>v2x_freexp_altinf &amp; v2x_frassoc_thick &amp; v2xel_...</td>\n",
       "      <td>0.746313</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.935103</td>\n",
       "      <td>0.935103</td>\n",
       "      <td>7</td>\n",
       "      <td>0.625</td>\n",
       "      <td>2.713786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pruning</td>\n",
       "      <td>5</td>\n",
       "      <td>v2x_freexp_altinf &amp; v2x_frassoc_thick &amp; v2xel_...</td>\n",
       "      <td>0.715976</td>\n",
       "      <td>0.914201</td>\n",
       "      <td>0.834320</td>\n",
       "      <td>0.834320</td>\n",
       "      <td>10</td>\n",
       "      <td>0.625</td>\n",
       "      <td>3.899576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pruning</td>\n",
       "      <td>6</td>\n",
       "      <td>(v2x_mpi &amp; v2x_freexp_altinf &amp; v2x_elecoff &amp; v...</td>\n",
       "      <td>0.727811</td>\n",
       "      <td>0.852071</td>\n",
       "      <td>0.798817</td>\n",
       "      <td>0.798817</td>\n",
       "      <td>10</td>\n",
       "      <td>0.625</td>\n",
       "      <td>2.416540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pruning</td>\n",
       "      <td>7</td>\n",
       "      <td>v2x_freexp_altinf &amp; v2x_frassoc_thick &amp; v2xel_...</td>\n",
       "      <td>0.733728</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.843195</td>\n",
       "      <td>0.843195</td>\n",
       "      <td>7</td>\n",
       "      <td>0.625</td>\n",
       "      <td>2.666849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pruning</td>\n",
       "      <td>8</td>\n",
       "      <td>v2x_freexp_altinf &amp; v2xel_frefair &amp; v2x_elecof...</td>\n",
       "      <td>0.695266</td>\n",
       "      <td>0.911243</td>\n",
       "      <td>0.810651</td>\n",
       "      <td>0.810651</td>\n",
       "      <td>8</td>\n",
       "      <td>0.625</td>\n",
       "      <td>2.974110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pruning</td>\n",
       "      <td>9</td>\n",
       "      <td>(v2x_mpi &amp; v2x_freexp_altinf &amp; v2x_frassoc_thi...</td>\n",
       "      <td>0.772189</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.852071</td>\n",
       "      <td>0.852071</td>\n",
       "      <td>14</td>\n",
       "      <td>0.625</td>\n",
       "      <td>2.577125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    method  split                                        explanation  \\\n",
       "0  pruning      0  v2x_freexp_altinf & v2x_frassoc_thick & v2xel_...   \n",
       "1  pruning      1  v2x_freexp_altinf & v2x_frassoc_thick & v2xel_...   \n",
       "2  pruning      2  (v2x_mpi & v2x_freexp_altinf & v2x_frassoc_thi...   \n",
       "3  pruning      3  v2x_freexp_altinf & v2x_frassoc_thick & v2xel_...   \n",
       "4  pruning      4  v2x_freexp_altinf & v2x_frassoc_thick & v2xel_...   \n",
       "5  pruning      5  v2x_freexp_altinf & v2x_frassoc_thick & v2xel_...   \n",
       "6  pruning      6  (v2x_mpi & v2x_freexp_altinf & v2x_elecoff & v...   \n",
       "7  pruning      7  v2x_freexp_altinf & v2x_frassoc_thick & v2xel_...   \n",
       "8  pruning      8  v2x_freexp_altinf & v2xel_frefair & v2x_elecof...   \n",
       "9  pruning      9  (v2x_mpi & v2x_freexp_altinf & v2x_frassoc_thi...   \n",
       "\n",
       "   model_accuracy_mid  model_accuracy_top  explanation_accuracy  \\\n",
       "0            0.755162            0.926254              0.917404   \n",
       "1            0.758112            0.943953              0.870206   \n",
       "2            0.749263            0.867257              0.817109   \n",
       "3            0.743363            0.908555              0.831858   \n",
       "4            0.746313            0.938053              0.935103   \n",
       "5            0.715976            0.914201              0.834320   \n",
       "6            0.727811            0.852071              0.798817   \n",
       "7            0.733728            0.923077              0.843195   \n",
       "8            0.695266            0.911243              0.810651   \n",
       "9            0.772189            0.923077              0.852071   \n",
       "\n",
       "   explanation_fidelity  explanation_complexity  explanation_consistency  \\\n",
       "0              0.917404                       7                    0.625   \n",
       "1              0.870206                      10                    0.625   \n",
       "2              0.817109                      12                    0.625   \n",
       "3              0.831858                       8                    0.625   \n",
       "4              0.935103                       7                    0.625   \n",
       "5              0.834320                      10                    0.625   \n",
       "6              0.798817                      10                    0.625   \n",
       "7              0.843195                       7                    0.625   \n",
       "8              0.810651                       8                    0.625   \n",
       "9              0.852071                      14                    0.625   \n",
       "\n",
       "   elapsed_time  \n",
       "0      2.743629  \n",
       "1      3.714072  \n",
       "2      2.507271  \n",
       "3      2.915249  \n",
       "4      2.713786  \n",
       "5      3.899576  \n",
       "6      2.416540  \n",
       "7      2.666849  \n",
       "8      2.974110  \n",
       "9      2.577125  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = 'pruning'\n",
    "need_pruning = True\n",
    "relu = False\n",
    "results_pruning = c_to_y(method, need_pruning, relu, verbose=True)\n",
    "results_pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-discrimination",
   "metadata": {},
   "source": [
    "## ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "empirical-essex",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split [1/10]\n",
      "\t Epoch 0: train accuracy: 0.5204\n",
      "\t Epoch 500: train accuracy: 0.9799\n",
      "\t Epoch 1000: train accuracy: 0.9900\n",
      "\t Epoch 1500: train accuracy: 0.9936\n",
      "\t Epoch 2000: train accuracy: 0.9955\n",
      "\t Epoch 2500: train accuracy: 0.9962\n",
      "\t Epoch 3000: train accuracy: 0.9966\n",
      "\t Epoch 3500: train accuracy: 0.9968\n",
      "\t Epoch 4000: train accuracy: 0.9968\n",
      "\t Epoch 4500: train accuracy: 0.9968\n",
      "\t Epoch 5000: train accuracy: 0.9968\n",
      "\t Epoch 5500: train accuracy: 0.9968\n",
      "\t Epoch 6000: train accuracy: 0.9968\n",
      "\t Epoch 0: train accuracy: 0.4685\n",
      "\t Epoch 500: train accuracy: 0.9471\n",
      "\t Epoch 1000: train accuracy: 0.9475\n",
      "\t Epoch 1500: train accuracy: 0.9481\n",
      "\t Epoch 2000: train accuracy: 0.9481\n",
      "\t Epoch 2500: train accuracy: 0.9481\n",
      "\t Epoch 3000: train accuracy: 0.9488\n",
      "\t Epoch 3500: train accuracy: 0.9494\n",
      "\t Epoch 4000: train accuracy: 0.9498\n",
      "\t Epoch 4500: train accuracy: 0.9491\n",
      "\t Epoch 5000: train accuracy: 0.9498\n",
      "\t Epoch 5500: train accuracy: 0.9498\n",
      "\t Epoch 6000: train accuracy: 0.9494\n",
      "\t Model's accuracy (mid): 0.7493 - Model's accuracy (top): 0.9351\n",
      "\t Class 1 - Global explanation: \"~v2x_mpi | (v2x_freexp_altinf & v2x_elecoff & v2xeg_eqaccess)\" - Accuracy: 0.5310\n",
      "\t Elapsed time 2.935150146484375\n",
      "\t Fidelity: \"0.5310\" - Complexity: \"4\"\n",
      "Split [2/10]\n",
      "\t Epoch 0: train accuracy: 0.5206\n",
      "\t Epoch 500: train accuracy: 0.9795\n",
      "\t Epoch 1000: train accuracy: 0.9897\n",
      "\t Epoch 1500: train accuracy: 0.9943\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.9966\n",
      "\t Epoch 3000: train accuracy: 0.9969\n",
      "\t Epoch 3500: train accuracy: 0.9970\n",
      "\t Epoch 4000: train accuracy: 0.9970\n",
      "\t Epoch 4500: train accuracy: 0.9970\n",
      "\t Epoch 5000: train accuracy: 0.9970\n",
      "\t Epoch 5500: train accuracy: 0.9970\n",
      "\t Epoch 6000: train accuracy: 0.9970\n",
      "\t Epoch 0: train accuracy: 0.4685\n",
      "\t Epoch 500: train accuracy: 0.9448\n",
      "\t Epoch 1000: train accuracy: 0.9458\n",
      "\t Epoch 1500: train accuracy: 0.9465\n",
      "\t Epoch 2000: train accuracy: 0.9468\n",
      "\t Epoch 2500: train accuracy: 0.9471\n",
      "\t Epoch 3000: train accuracy: 0.9471\n",
      "\t Epoch 3500: train accuracy: 0.9485\n",
      "\t Epoch 4000: train accuracy: 0.9485\n",
      "\t Epoch 4500: train accuracy: 0.9485\n",
      "\t Epoch 5000: train accuracy: 0.9485\n",
      "\t Epoch 5500: train accuracy: 0.9485\n",
      "\t Epoch 6000: train accuracy: 0.9481\n",
      "\t Model's accuracy (mid): 0.7493 - Model's accuracy (top): 0.9410\n",
      "\t Class 1 - Global explanation: \"~v2x_mpi | (v2x_api & v2x_frassoc_thick & v2xel_frefair & v2x_elecoff & v2xeg_eqdr)\" - Accuracy: 0.4926\n",
      "\t Elapsed time 3.210460901260376\n",
      "\t Fidelity: \"0.4926\" - Complexity: \"6\"\n",
      "Split [3/10]\n",
      "\t Epoch 0: train accuracy: 0.5203\n",
      "\t Epoch 500: train accuracy: 0.9803\n",
      "\t Epoch 1000: train accuracy: 0.9904\n",
      "\t Epoch 1500: train accuracy: 0.9946\n",
      "\t Epoch 2000: train accuracy: 0.9962\n",
      "\t Epoch 2500: train accuracy: 0.9967\n",
      "\t Epoch 3000: train accuracy: 0.9969\n",
      "\t Epoch 3500: train accuracy: 0.9970\n",
      "\t Epoch 4000: train accuracy: 0.9970\n",
      "\t Epoch 4500: train accuracy: 0.9970\n",
      "\t Epoch 5000: train accuracy: 0.9970\n",
      "\t Epoch 5500: train accuracy: 0.9971\n",
      "\t Epoch 6000: train accuracy: 0.9971\n",
      "\t Epoch 0: train accuracy: 0.4685\n",
      "\t Epoch 500: train accuracy: 0.9478\n",
      "\t Epoch 1000: train accuracy: 0.9485\n",
      "\t Epoch 1500: train accuracy: 0.9485\n",
      "\t Epoch 2000: train accuracy: 0.9488\n",
      "\t Epoch 2500: train accuracy: 0.9494\n",
      "\t Epoch 3000: train accuracy: 0.9498\n",
      "\t Epoch 3500: train accuracy: 0.9504\n",
      "\t Epoch 4000: train accuracy: 0.9514\n",
      "\t Epoch 4500: train accuracy: 0.9527\n",
      "\t Epoch 5000: train accuracy: 0.9527\n",
      "\t Epoch 5500: train accuracy: 0.9524\n",
      "\t Epoch 6000: train accuracy: 0.9527\n",
      "\t Model's accuracy (mid): 0.7463 - Model's accuracy (top): 0.9351\n",
      "\t Class 1 - Global explanation: \"~v2x_mpi | (v2xel_frefair & v2xcl_rol)\" - Accuracy: 0.5310\n",
      "\t Elapsed time 2.8524057865142822\n",
      "\t Fidelity: \"0.5310\" - Complexity: \"3\"\n",
      "Split [4/10]\n",
      "\t Epoch 0: train accuracy: 0.5203\n",
      "\t Epoch 500: train accuracy: 0.9799\n",
      "\t Epoch 1000: train accuracy: 0.9902\n",
      "\t Epoch 1500: train accuracy: 0.9940\n",
      "\t Epoch 2000: train accuracy: 0.9959\n",
      "\t Epoch 2500: train accuracy: 0.9965\n",
      "\t Epoch 3000: train accuracy: 0.9968\n",
      "\t Epoch 3500: train accuracy: 0.9969\n",
      "\t Epoch 4000: train accuracy: 0.9969\n",
      "\t Epoch 4500: train accuracy: 0.9969\n",
      "\t Epoch 5000: train accuracy: 0.9969\n",
      "\t Epoch 5500: train accuracy: 0.9969\n",
      "\t Epoch 6000: train accuracy: 0.9969\n",
      "\t Epoch 0: train accuracy: 0.4685\n",
      "\t Epoch 500: train accuracy: 0.9478\n",
      "\t Epoch 1000: train accuracy: 0.9478\n",
      "\t Epoch 1500: train accuracy: 0.9481\n",
      "\t Epoch 2000: train accuracy: 0.9494\n",
      "\t Epoch 2500: train accuracy: 0.9498\n",
      "\t Epoch 3000: train accuracy: 0.9498\n",
      "\t Epoch 3500: train accuracy: 0.9511\n",
      "\t Epoch 4000: train accuracy: 0.9511\n",
      "\t Epoch 4500: train accuracy: 0.9514\n",
      "\t Epoch 5000: train accuracy: 0.9514\n",
      "\t Epoch 5500: train accuracy: 0.9514\n",
      "\t Epoch 6000: train accuracy: 0.9514\n",
      "\t Model's accuracy (mid): 0.7522 - Model's accuracy (top): 0.9174\n",
      "\t Class 1 - Global explanation: \"v2x_mpi | ~v2x_mpi\" - Accuracy: 0.5310\n",
      "\t Elapsed time 2.7965707778930664\n",
      "\t Fidelity: \"0.5310\" - Complexity: \"2\"\n",
      "Split [5/10]\n",
      "\t Epoch 0: train accuracy: 0.5201\n",
      "\t Epoch 500: train accuracy: 0.9798\n",
      "\t Epoch 1000: train accuracy: 0.9902\n",
      "\t Epoch 1500: train accuracy: 0.9946\n",
      "\t Epoch 2000: train accuracy: 0.9961\n",
      "\t Epoch 2500: train accuracy: 0.9966\n",
      "\t Epoch 3000: train accuracy: 0.9970\n",
      "\t Epoch 3500: train accuracy: 0.9970\n",
      "\t Epoch 4000: train accuracy: 0.9970\n",
      "\t Epoch 4500: train accuracy: 0.9970\n",
      "\t Epoch 5000: train accuracy: 0.9970\n",
      "\t Epoch 5500: train accuracy: 0.9970\n",
      "\t Epoch 6000: train accuracy: 0.9970\n",
      "\t Epoch 0: train accuracy: 0.4685\n",
      "\t Epoch 500: train accuracy: 0.9465\n",
      "\t Epoch 1000: train accuracy: 0.9455\n",
      "\t Epoch 1500: train accuracy: 0.9462\n",
      "\t Epoch 2000: train accuracy: 0.9475\n",
      "\t Epoch 2500: train accuracy: 0.9478\n",
      "\t Epoch 3000: train accuracy: 0.9481\n",
      "\t Epoch 3500: train accuracy: 0.9498\n",
      "\t Epoch 4000: train accuracy: 0.9498\n",
      "\t Epoch 4500: train accuracy: 0.9498\n",
      "\t Epoch 5000: train accuracy: 0.9498\n",
      "\t Epoch 5500: train accuracy: 0.9498\n",
      "\t Epoch 6000: train accuracy: 0.9494\n",
      "\t Model's accuracy (mid): 0.7463 - Model's accuracy (top): 0.9381\n",
      "\t Class 1 - Global explanation: \"(v2x_frassoc_thick & ~v2x_mpi) | (v2x_api & v2x_frassoc_thick & v2xcl_rol & v2xeg_eqaccess)\" - Accuracy: 0.7847\n",
      "\t Elapsed time 4.071111440658569\n",
      "\t Fidelity: \"0.7847\" - Complexity: \"6\"\n",
      "Split [6/10]\n",
      "\t Epoch 0: train accuracy: 0.5209\n",
      "\t Epoch 500: train accuracy: 0.9805\n",
      "\t Epoch 1000: train accuracy: 0.9906\n",
      "\t Epoch 1500: train accuracy: 0.9941\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.9964\n",
      "\t Epoch 3000: train accuracy: 0.9967\n",
      "\t Epoch 3500: train accuracy: 0.9968\n",
      "\t Epoch 4000: train accuracy: 0.9968\n",
      "\t Epoch 4500: train accuracy: 0.9968\n",
      "\t Epoch 5000: train accuracy: 0.9968\n",
      "\t Epoch 5500: train accuracy: 0.9968\n",
      "\t Epoch 6000: train accuracy: 0.9968\n",
      "\t Epoch 0: train accuracy: 0.4687\n",
      "\t Epoch 500: train accuracy: 0.9472\n",
      "\t Epoch 1000: train accuracy: 0.9472\n",
      "\t Epoch 1500: train accuracy: 0.9481\n",
      "\t Epoch 2000: train accuracy: 0.9485\n",
      "\t Epoch 2500: train accuracy: 0.9498\n",
      "\t Epoch 3000: train accuracy: 0.9495\n",
      "\t Epoch 3500: train accuracy: 0.9504\n",
      "\t Epoch 4000: train accuracy: 0.9508\n",
      "\t Epoch 4500: train accuracy: 0.9508\n",
      "\t Epoch 5000: train accuracy: 0.9508\n",
      "\t Epoch 5500: train accuracy: 0.9508\n",
      "\t Epoch 6000: train accuracy: 0.9508\n",
      "\t Model's accuracy (mid): 0.7189 - Model's accuracy (top): 0.8994\n",
      "\t Class 1 - Global explanation: \"~v2x_mpi | (v2x_api & v2xel_frefair & v2xeg_eqprotec)\" - Accuracy: 0.5207\n",
      "\t Elapsed time 3.0987308025360107\n",
      "\t Fidelity: \"0.5207\" - Complexity: \"4\"\n",
      "Split [7/10]\n",
      "\t Epoch 0: train accuracy: 0.5206\n",
      "\t Epoch 500: train accuracy: 0.9802\n",
      "\t Epoch 1000: train accuracy: 0.9910\n",
      "\t Epoch 1500: train accuracy: 0.9945\n",
      "\t Epoch 2000: train accuracy: 0.9958\n",
      "\t Epoch 2500: train accuracy: 0.9965\n",
      "\t Epoch 3000: train accuracy: 0.9968\n",
      "\t Epoch 3500: train accuracy: 0.9969\n",
      "\t Epoch 4000: train accuracy: 0.9969\n",
      "\t Epoch 4500: train accuracy: 0.9969\n",
      "\t Epoch 5000: train accuracy: 0.9969\n",
      "\t Epoch 5500: train accuracy: 0.9969\n",
      "\t Epoch 6000: train accuracy: 0.9969\n",
      "\t Epoch 0: train accuracy: 0.4687\n",
      "\t Epoch 500: train accuracy: 0.9458\n",
      "\t Epoch 1000: train accuracy: 0.9465\n",
      "\t Epoch 1500: train accuracy: 0.9465\n",
      "\t Epoch 2000: train accuracy: 0.9475\n",
      "\t Epoch 2500: train accuracy: 0.9498\n",
      "\t Epoch 3000: train accuracy: 0.9498\n",
      "\t Epoch 3500: train accuracy: 0.9504\n",
      "\t Epoch 4000: train accuracy: 0.9504\n",
      "\t Epoch 4500: train accuracy: 0.9504\n",
      "\t Epoch 5000: train accuracy: 0.9508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 5500: train accuracy: 0.9508\n",
      "\t Epoch 6000: train accuracy: 0.9508\n",
      "\t Model's accuracy (mid): 0.7456 - Model's accuracy (top): 0.9201\n",
      "\t Class 1 - Global explanation: \"~v2x_mpi | (v2x_api & v2x_freexp_altinf & v2xel_frefair & v2x_elecoff & v2xcl_rol & v2xeg_eqdr)\" - Accuracy: 0.4970\n",
      "\t Elapsed time 3.2283756732940674\n",
      "\t Fidelity: \"0.4970\" - Complexity: \"7\"\n",
      "Split [8/10]\n",
      "\t Epoch 0: train accuracy: 0.5210\n",
      "\t Epoch 500: train accuracy: 0.9807\n",
      "\t Epoch 1000: train accuracy: 0.9902\n",
      "\t Epoch 1500: train accuracy: 0.9944\n",
      "\t Epoch 2000: train accuracy: 0.9960\n",
      "\t Epoch 2500: train accuracy: 0.9967\n",
      "\t Epoch 3000: train accuracy: 0.9970\n",
      "\t Epoch 3500: train accuracy: 0.9970\n",
      "\t Epoch 4000: train accuracy: 0.9971\n",
      "\t Epoch 4500: train accuracy: 0.9971\n",
      "\t Epoch 5000: train accuracy: 0.9971\n",
      "\t Epoch 5500: train accuracy: 0.9971\n",
      "\t Epoch 6000: train accuracy: 0.9970\n",
      "\t Epoch 0: train accuracy: 0.4687\n",
      "\t Epoch 500: train accuracy: 0.9455\n",
      "\t Epoch 1000: train accuracy: 0.9455\n",
      "\t Epoch 1500: train accuracy: 0.9455\n",
      "\t Epoch 2000: train accuracy: 0.9462\n",
      "\t Epoch 2500: train accuracy: 0.9472\n",
      "\t Epoch 3000: train accuracy: 0.9488\n",
      "\t Epoch 3500: train accuracy: 0.9491\n",
      "\t Epoch 4000: train accuracy: 0.9491\n",
      "\t Epoch 4500: train accuracy: 0.9491\n",
      "\t Epoch 5000: train accuracy: 0.9498\n",
      "\t Epoch 5500: train accuracy: 0.9495\n",
      "\t Epoch 6000: train accuracy: 0.9498\n",
      "\t Model's accuracy (mid): 0.7574 - Model's accuracy (top): 0.9320\n",
      "\t Class 1 - Global explanation: \"~v2x_mpi | (v2x_api & v2xel_frefair & v2x_elecoff & v2xeg_eqdr)\" - Accuracy: 0.4970\n",
      "\t Elapsed time 3.1815240383148193\n",
      "\t Fidelity: \"0.4970\" - Complexity: \"5\"\n",
      "Split [9/10]\n",
      "\t Epoch 0: train accuracy: 0.5199\n",
      "\t Epoch 500: train accuracy: 0.9803\n",
      "\t Epoch 1000: train accuracy: 0.9908\n",
      "\t Epoch 1500: train accuracy: 0.9944\n",
      "\t Epoch 2000: train accuracy: 0.9964\n",
      "\t Epoch 2500: train accuracy: 0.9967\n",
      "\t Epoch 3000: train accuracy: 0.9969\n",
      "\t Epoch 3500: train accuracy: 0.9970\n",
      "\t Epoch 4000: train accuracy: 0.9970\n",
      "\t Epoch 4500: train accuracy: 0.9970\n",
      "\t Epoch 5000: train accuracy: 0.9971\n",
      "\t Epoch 5500: train accuracy: 0.9971\n",
      "\t Epoch 6000: train accuracy: 0.9971\n",
      "\t Epoch 0: train accuracy: 0.4687\n",
      "\t Epoch 500: train accuracy: 0.9478\n",
      "\t Epoch 1000: train accuracy: 0.9478\n",
      "\t Epoch 1500: train accuracy: 0.9491\n",
      "\t Epoch 2000: train accuracy: 0.9495\n",
      "\t Epoch 2500: train accuracy: 0.9495\n",
      "\t Epoch 3000: train accuracy: 0.9504\n",
      "\t Epoch 3500: train accuracy: 0.9504\n",
      "\t Epoch 4000: train accuracy: 0.9504\n",
      "\t Epoch 4500: train accuracy: 0.9504\n",
      "\t Epoch 5000: train accuracy: 0.9504\n",
      "\t Epoch 5500: train accuracy: 0.9504\n",
      "\t Epoch 6000: train accuracy: 0.9511\n",
      "\t Model's accuracy (mid): 0.7219 - Model's accuracy (top): 0.9379\n",
      "\t Class 1 - Global explanation: \"~v2x_mpi | (v2xel_frefair & v2xcl_rol)\" - Accuracy: 0.5325\n",
      "\t Elapsed time 2.8304648399353027\n",
      "\t Fidelity: \"0.5325\" - Complexity: \"3\"\n",
      "Split [10/10]\n",
      "\t Epoch 0: train accuracy: 0.5209\n",
      "\t Epoch 500: train accuracy: 0.9797\n",
      "\t Epoch 1000: train accuracy: 0.9894\n",
      "\t Epoch 1500: train accuracy: 0.9942\n",
      "\t Epoch 2000: train accuracy: 0.9958\n",
      "\t Epoch 2500: train accuracy: 0.9964\n",
      "\t Epoch 3000: train accuracy: 0.9966\n",
      "\t Epoch 3500: train accuracy: 0.9969\n",
      "\t Epoch 4000: train accuracy: 0.9969\n",
      "\t Epoch 4500: train accuracy: 0.9969\n",
      "\t Epoch 5000: train accuracy: 0.9969\n",
      "\t Epoch 5500: train accuracy: 0.9969\n",
      "\t Epoch 6000: train accuracy: 0.9969\n",
      "\t Epoch 0: train accuracy: 0.4683\n",
      "\t Epoch 500: train accuracy: 0.9475\n",
      "\t Epoch 1000: train accuracy: 0.9481\n",
      "\t Epoch 1500: train accuracy: 0.9488\n",
      "\t Epoch 2000: train accuracy: 0.9488\n",
      "\t Epoch 2500: train accuracy: 0.9488\n",
      "\t Epoch 3000: train accuracy: 0.9488\n",
      "\t Epoch 3500: train accuracy: 0.9488\n",
      "\t Epoch 4000: train accuracy: 0.9488\n",
      "\t Epoch 4500: train accuracy: 0.9495\n",
      "\t Epoch 5000: train accuracy: 0.9491\n",
      "\t Epoch 5500: train accuracy: 0.9495\n",
      "\t Epoch 6000: train accuracy: 0.9495\n",
      "\t Model's accuracy (mid): 0.7515 - Model's accuracy (top): 0.9112\n",
      "\t Class 1 - Global explanation: \"v2x_mpi | ~v2x_mpi\" - Accuracy: 0.5296\n",
      "\t Elapsed time 2.757625102996826\n",
      "\t Fidelity: \"0.5296\" - Complexity: \"2\"\n",
      "Consistency of explanations: 0.3900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>model_accuracy_mid</th>\n",
       "      <th>model_accuracy_top</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_fidelity</th>\n",
       "      <th>explanation_complexity</th>\n",
       "      <th>explanation_consistency</th>\n",
       "      <th>elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weights</td>\n",
       "      <td>0</td>\n",
       "      <td>~v2x_mpi | (v2x_freexp_altinf &amp; v2x_elecoff &amp; ...</td>\n",
       "      <td>0.749263</td>\n",
       "      <td>0.935103</td>\n",
       "      <td>0.530973</td>\n",
       "      <td>0.530973</td>\n",
       "      <td>4</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2.935150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weights</td>\n",
       "      <td>1</td>\n",
       "      <td>~v2x_mpi | (v2x_api &amp; v2x_frassoc_thick &amp; v2xe...</td>\n",
       "      <td>0.749263</td>\n",
       "      <td>0.941003</td>\n",
       "      <td>0.492625</td>\n",
       "      <td>0.492625</td>\n",
       "      <td>6</td>\n",
       "      <td>0.39</td>\n",
       "      <td>3.210461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weights</td>\n",
       "      <td>2</td>\n",
       "      <td>~v2x_mpi | (v2xel_frefair &amp; v2xcl_rol)</td>\n",
       "      <td>0.746313</td>\n",
       "      <td>0.935103</td>\n",
       "      <td>0.530973</td>\n",
       "      <td>0.530973</td>\n",
       "      <td>3</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2.852406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weights</td>\n",
       "      <td>3</td>\n",
       "      <td>v2x_mpi | ~v2x_mpi</td>\n",
       "      <td>0.752212</td>\n",
       "      <td>0.917404</td>\n",
       "      <td>0.530973</td>\n",
       "      <td>0.530973</td>\n",
       "      <td>2</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2.796571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weights</td>\n",
       "      <td>4</td>\n",
       "      <td>(v2x_frassoc_thick &amp; ~v2x_mpi) | (v2x_api &amp; v2...</td>\n",
       "      <td>0.746313</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.784661</td>\n",
       "      <td>0.784661</td>\n",
       "      <td>6</td>\n",
       "      <td>0.39</td>\n",
       "      <td>4.071111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weights</td>\n",
       "      <td>5</td>\n",
       "      <td>~v2x_mpi | (v2x_api &amp; v2xel_frefair &amp; v2xeg_eq...</td>\n",
       "      <td>0.718935</td>\n",
       "      <td>0.899408</td>\n",
       "      <td>0.520710</td>\n",
       "      <td>0.520710</td>\n",
       "      <td>4</td>\n",
       "      <td>0.39</td>\n",
       "      <td>3.098731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weights</td>\n",
       "      <td>6</td>\n",
       "      <td>~v2x_mpi | (v2x_api &amp; v2x_freexp_altinf &amp; v2xe...</td>\n",
       "      <td>0.745562</td>\n",
       "      <td>0.920118</td>\n",
       "      <td>0.497041</td>\n",
       "      <td>0.497041</td>\n",
       "      <td>7</td>\n",
       "      <td>0.39</td>\n",
       "      <td>3.228376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weights</td>\n",
       "      <td>7</td>\n",
       "      <td>~v2x_mpi | (v2x_api &amp; v2xel_frefair &amp; v2x_elec...</td>\n",
       "      <td>0.757396</td>\n",
       "      <td>0.931953</td>\n",
       "      <td>0.497041</td>\n",
       "      <td>0.497041</td>\n",
       "      <td>5</td>\n",
       "      <td>0.39</td>\n",
       "      <td>3.181524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weights</td>\n",
       "      <td>8</td>\n",
       "      <td>~v2x_mpi | (v2xel_frefair &amp; v2xcl_rol)</td>\n",
       "      <td>0.721893</td>\n",
       "      <td>0.937870</td>\n",
       "      <td>0.532544</td>\n",
       "      <td>0.532544</td>\n",
       "      <td>3</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2.830465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>weights</td>\n",
       "      <td>9</td>\n",
       "      <td>v2x_mpi | ~v2x_mpi</td>\n",
       "      <td>0.751479</td>\n",
       "      <td>0.911243</td>\n",
       "      <td>0.529586</td>\n",
       "      <td>0.529586</td>\n",
       "      <td>2</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2.757625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    method  split                                        explanation  \\\n",
       "0  weights      0  ~v2x_mpi | (v2x_freexp_altinf & v2x_elecoff & ...   \n",
       "1  weights      1  ~v2x_mpi | (v2x_api & v2x_frassoc_thick & v2xe...   \n",
       "2  weights      2             ~v2x_mpi | (v2xel_frefair & v2xcl_rol)   \n",
       "3  weights      3                                 v2x_mpi | ~v2x_mpi   \n",
       "4  weights      4  (v2x_frassoc_thick & ~v2x_mpi) | (v2x_api & v2...   \n",
       "5  weights      5  ~v2x_mpi | (v2x_api & v2xel_frefair & v2xeg_eq...   \n",
       "6  weights      6  ~v2x_mpi | (v2x_api & v2x_freexp_altinf & v2xe...   \n",
       "7  weights      7  ~v2x_mpi | (v2x_api & v2xel_frefair & v2x_elec...   \n",
       "8  weights      8             ~v2x_mpi | (v2xel_frefair & v2xcl_rol)   \n",
       "9  weights      9                                 v2x_mpi | ~v2x_mpi   \n",
       "\n",
       "   model_accuracy_mid  model_accuracy_top  explanation_accuracy  \\\n",
       "0            0.749263            0.935103              0.530973   \n",
       "1            0.749263            0.941003              0.492625   \n",
       "2            0.746313            0.935103              0.530973   \n",
       "3            0.752212            0.917404              0.530973   \n",
       "4            0.746313            0.938053              0.784661   \n",
       "5            0.718935            0.899408              0.520710   \n",
       "6            0.745562            0.920118              0.497041   \n",
       "7            0.757396            0.931953              0.497041   \n",
       "8            0.721893            0.937870              0.532544   \n",
       "9            0.751479            0.911243              0.529586   \n",
       "\n",
       "   explanation_fidelity  explanation_complexity  explanation_consistency  \\\n",
       "0              0.530973                       4                     0.39   \n",
       "1              0.492625                       6                     0.39   \n",
       "2              0.530973                       3                     0.39   \n",
       "3              0.530973                       2                     0.39   \n",
       "4              0.784661                       6                     0.39   \n",
       "5              0.520710                       4                     0.39   \n",
       "6              0.497041                       7                     0.39   \n",
       "7              0.497041                       5                     0.39   \n",
       "8              0.532544                       3                     0.39   \n",
       "9              0.529586                       2                     0.39   \n",
       "\n",
       "   elapsed_time  \n",
       "0      2.935150  \n",
       "1      3.210461  \n",
       "2      2.852406  \n",
       "3      2.796571  \n",
       "4      4.071111  \n",
       "5      3.098731  \n",
       "6      3.228376  \n",
       "7      3.181524  \n",
       "8      2.830465  \n",
       "9      2.757625  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = 'weights'\n",
    "need_pruning = False\n",
    "relu = True\n",
    "results_weights = c_to_y(method, need_pruning, relu, True)\n",
    "results_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-crowd",
   "metadata": {},
   "source": [
    "## Psi network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "frozen-stockholm",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split [1/10]\n",
      "\t Epoch 0: train accuracy: 0.4649\n",
      "\t Epoch 500: train accuracy: 0.9104\n",
      "\t Epoch 1000: train accuracy: 0.9367\n",
      "\t Epoch 1500: train accuracy: 0.9503\n",
      "\t Epoch 2000: train accuracy: 0.9622\n",
      "\t Epoch 2500: train accuracy: 0.9742\n",
      "\t Epoch 3000: train accuracy: 0.9847\n",
      "\t Epoch 3500: train accuracy: 0.8533\n",
      "\t Epoch 4000: train accuracy: 0.8856\n",
      "\t Epoch 4500: train accuracy: 0.8930\n",
      "\t Epoch 5000: train accuracy: 0.8943\n",
      "\t Epoch 5500: train accuracy: 0.8964\n",
      "\t Epoch 6000: train accuracy: 0.8992\n",
      "\t Epoch 0: train accuracy: 0.4685\n",
      "\t Epoch 500: train accuracy: 0.7173\n",
      "\t Epoch 1000: train accuracy: 0.8546\n",
      "\t Epoch 1500: train accuracy: 0.8651\n",
      "\t Epoch 2000: train accuracy: 0.8766\n",
      "\t Epoch 2500: train accuracy: 0.8775\n",
      "\t Epoch 3000: train accuracy: 0.8805\n",
      "\t Epoch 3500: train accuracy: 0.8513\n",
      "\t Epoch 4000: train accuracy: 0.8480\n",
      "\t Epoch 4500: train accuracy: 0.8510\n",
      "\t Epoch 5000: train accuracy: 0.8595\n",
      "\t Epoch 5500: train accuracy: 0.8618\n",
      "\t Epoch 6000: train accuracy: 0.8638\n",
      "\t Model's accuracy (mid): 0.3451 - Model's accuracy (top): 0.8673\n",
      "\t Class 1 - Global explanation: \"(v2x_mpi)\" - Accuracy: 0.8142\n",
      "\t Elapsed time 0.008008480072021484\n",
      "\t Fidelity: \"0.8142\" - Complexity: \"1\"\n",
      "Split [2/10]\n",
      "\t Epoch 0: train accuracy: 0.4695\n",
      "\t Epoch 500: train accuracy: 0.9072\n",
      "\t Epoch 1000: train accuracy: 0.9349\n",
      "\t Epoch 1500: train accuracy: 0.9480\n",
      "\t Epoch 2000: train accuracy: 0.9592\n",
      "\t Epoch 2500: train accuracy: 0.9750\n",
      "\t Epoch 3000: train accuracy: 0.9841\n",
      "\t Epoch 3500: train accuracy: 0.8153\n",
      "\t Epoch 4000: train accuracy: 0.8607\n",
      "\t Epoch 4500: train accuracy: 0.8692\n",
      "\t Epoch 5000: train accuracy: 0.8751\n",
      "\t Epoch 5500: train accuracy: 0.8810\n",
      "\t Epoch 6000: train accuracy: 0.8829\n",
      "\t Epoch 0: train accuracy: 0.5315\n",
      "\t Epoch 500: train accuracy: 0.7754\n",
      "\t Epoch 1000: train accuracy: 0.8450\n",
      "\t Epoch 1500: train accuracy: 0.8572\n",
      "\t Epoch 2000: train accuracy: 0.8615\n",
      "\t Epoch 2500: train accuracy: 0.8697\n",
      "\t Epoch 3000: train accuracy: 0.8710\n",
      "\t Epoch 3500: train accuracy: 0.8194\n",
      "\t Epoch 4000: train accuracy: 0.8276\n",
      "\t Epoch 4500: train accuracy: 0.8244\n",
      "\t Epoch 5000: train accuracy: 0.8273\n",
      "\t Epoch 5500: train accuracy: 0.8296\n",
      "\t Epoch 6000: train accuracy: 0.8336\n",
      "\t Model's accuracy (mid): 0.3363 - Model's accuracy (top): 0.8496\n",
      "\t Class 1 - Global explanation: \"(v2x_freexp_altinf & v2xcl_rol)\" - Accuracy: 0.8289\n",
      "\t Elapsed time 0.030917644500732422\n",
      "\t Fidelity: \"0.8289\" - Complexity: \"2\"\n",
      "Split [3/10]\n",
      "\t Epoch 0: train accuracy: 0.5062\n",
      "\t Epoch 500: train accuracy: 0.9127\n",
      "\t Epoch 1000: train accuracy: 0.9378\n",
      "\t Epoch 1500: train accuracy: 0.9504\n",
      "\t Epoch 2000: train accuracy: 0.9652\n",
      "\t Epoch 2500: train accuracy: 0.9788\n",
      "\t Epoch 3000: train accuracy: 0.9865\n",
      "\t Epoch 3500: train accuracy: 0.8423\n",
      "\t Epoch 4000: train accuracy: 0.8808\n",
      "\t Epoch 4500: train accuracy: 0.8839\n",
      "\t Epoch 5000: train accuracy: 0.8922\n",
      "\t Epoch 5500: train accuracy: 0.8999\n",
      "\t Epoch 6000: train accuracy: 0.9007\n",
      "\t Epoch 0: train accuracy: 0.4685\n",
      "\t Epoch 500: train accuracy: 0.8362\n",
      "\t Epoch 1000: train accuracy: 0.8723\n",
      "\t Epoch 1500: train accuracy: 0.8802\n",
      "\t Epoch 2000: train accuracy: 0.8808\n",
      "\t Epoch 2500: train accuracy: 0.8795\n",
      "\t Epoch 3000: train accuracy: 0.8743\n",
      "\t Epoch 3500: train accuracy: 0.7991\n",
      "\t Epoch 4000: train accuracy: 0.8060\n",
      "\t Epoch 4500: train accuracy: 0.8102\n",
      "\t Epoch 5000: train accuracy: 0.8125\n",
      "\t Epoch 5500: train accuracy: 0.8178\n",
      "\t Epoch 6000: train accuracy: 0.8240\n",
      "\t Model's accuracy (mid): 0.3540 - Model's accuracy (top): 0.8348\n",
      "\t Class 1 - Global explanation: \"(v2xeg_eqaccess & (v2xdl_delib | ~v2x_suffr))\" - Accuracy: 0.8289\n",
      "\t Elapsed time 0.04787158966064453\n",
      "\t Fidelity: \"0.8289\" - Complexity: \"3\"\n",
      "Split [4/10]\n",
      "\t Epoch 0: train accuracy: 0.3644\n",
      "\t Epoch 500: train accuracy: 0.9121\n",
      "\t Epoch 1000: train accuracy: 0.9362\n",
      "\t Epoch 1500: train accuracy: 0.9495\n",
      "\t Epoch 2000: train accuracy: 0.9636\n",
      "\t Epoch 2500: train accuracy: 0.9739\n",
      "\t Epoch 3000: train accuracy: 0.9837\n",
      "\t Epoch 3500: train accuracy: 0.8111\n",
      "\t Epoch 4000: train accuracy: 0.8292\n",
      "\t Epoch 4500: train accuracy: 0.8642\n",
      "\t Epoch 5000: train accuracy: 0.8708\n",
      "\t Epoch 5500: train accuracy: 0.8749\n",
      "\t Epoch 6000: train accuracy: 0.8750\n",
      "\t Epoch 0: train accuracy: 0.5315\n",
      "\t Epoch 500: train accuracy: 0.8342\n",
      "\t Epoch 1000: train accuracy: 0.8631\n",
      "\t Epoch 1500: train accuracy: 0.8707\n",
      "\t Epoch 2000: train accuracy: 0.8762\n",
      "\t Epoch 2500: train accuracy: 0.8795\n",
      "\t Epoch 3000: train accuracy: 0.8841\n",
      "\t Epoch 3500: train accuracy: 0.7180\n",
      "\t Epoch 4000: train accuracy: 0.7124\n",
      "\t Epoch 4500: train accuracy: 0.7183\n",
      "\t Epoch 5000: train accuracy: 0.7410\n",
      "\t Epoch 5500: train accuracy: 0.7387\n",
      "\t Epoch 6000: train accuracy: 0.7702\n",
      "\t Model's accuracy (mid): 0.2655 - Model's accuracy (top): 0.7640\n",
      "\t Class 1 - Global explanation: \"(v2x_elecoff)\" - Accuracy: 0.6814\n",
      "\t Elapsed time 0.02892923355102539\n",
      "\t Fidelity: \"0.6814\" - Complexity: \"1\"\n",
      "Split [5/10]\n",
      "\t Epoch 0: train accuracy: 0.5734\n",
      "\t Epoch 500: train accuracy: 0.9120\n",
      "\t Epoch 1000: train accuracy: 0.9376\n",
      "\t Epoch 1500: train accuracy: 0.9500\n",
      "\t Epoch 2000: train accuracy: 0.9641\n",
      "\t Epoch 2500: train accuracy: 0.9770\n",
      "\t Epoch 3000: train accuracy: 0.9847\n",
      "\t Epoch 3500: train accuracy: 0.7999\n",
      "\t Epoch 4000: train accuracy: 0.8295\n",
      "\t Epoch 4500: train accuracy: 0.8427\n",
      "\t Epoch 5000: train accuracy: 0.8587\n",
      "\t Epoch 5500: train accuracy: 0.8615\n",
      "\t Epoch 6000: train accuracy: 0.8672\n",
      "\t Epoch 0: train accuracy: 0.5315\n",
      "\t Epoch 500: train accuracy: 0.8414\n",
      "\t Epoch 1000: train accuracy: 0.8601\n",
      "\t Epoch 1500: train accuracy: 0.8644\n",
      "\t Epoch 2000: train accuracy: 0.8664\n",
      "\t Epoch 2500: train accuracy: 0.8697\n",
      "\t Epoch 3000: train accuracy: 0.8785\n",
      "\t Epoch 3500: train accuracy: 0.6202\n",
      "\t Epoch 4000: train accuracy: 0.7981\n",
      "\t Epoch 4500: train accuracy: 0.8142\n",
      "\t Epoch 5000: train accuracy: 0.8230\n",
      "\t Epoch 5500: train accuracy: 0.8148\n",
      "\t Epoch 6000: train accuracy: 0.8135\n",
      "\t Model's accuracy (mid): 0.1681 - Model's accuracy (top): 0.8201\n",
      "\t Class 1 - Global explanation: \"(v2x_frassoc_thick & v2xeg_eqaccess)\" - Accuracy: 0.8761\n",
      "\t Elapsed time 0.033014535903930664\n",
      "\t Fidelity: \"0.8761\" - Complexity: \"2\"\n",
      "Split [6/10]\n",
      "\t Epoch 0: train accuracy: 0.4149\n",
      "\t Epoch 500: train accuracy: 0.9151\n",
      "\t Epoch 1000: train accuracy: 0.9371\n",
      "\t Epoch 1500: train accuracy: 0.9476\n",
      "\t Epoch 2000: train accuracy: 0.9619\n",
      "\t Epoch 2500: train accuracy: 0.9750\n",
      "\t Epoch 3000: train accuracy: 0.9843\n",
      "\t Epoch 3500: train accuracy: 0.8164\n",
      "\t Epoch 4000: train accuracy: 0.8335\n",
      "\t Epoch 4500: train accuracy: 0.8559\n",
      "\t Epoch 5000: train accuracy: 0.8668\n",
      "\t Epoch 5500: train accuracy: 0.8738\n",
      "\t Epoch 6000: train accuracy: 0.8736\n",
      "\t Epoch 0: train accuracy: 0.4687\n",
      "\t Epoch 500: train accuracy: 0.8326\n",
      "\t Epoch 1000: train accuracy: 0.8697\n",
      "\t Epoch 1500: train accuracy: 0.8792\n",
      "\t Epoch 2000: train accuracy: 0.8825\n",
      "\t Epoch 2500: train accuracy: 0.8858\n",
      "\t Epoch 3000: train accuracy: 0.8904\n",
      "\t Epoch 3500: train accuracy: 0.7345\n",
      "\t Epoch 4000: train accuracy: 0.7565\n",
      "\t Epoch 4500: train accuracy: 0.7683\n",
      "\t Epoch 5000: train accuracy: 0.7758\n",
      "\t Epoch 5500: train accuracy: 0.7801\n",
      "\t Epoch 6000: train accuracy: 0.7896\n",
      "\t Model's accuracy (mid): 0.3787 - Model's accuracy (top): 0.7870\n",
      "\t Class 1 - Global explanation: \"(v2x_frassoc_thick & v2xeg_eqaccess)\" - Accuracy: 0.7959\n",
      "\t Elapsed time 0.02792501449584961\n",
      "\t Fidelity: \"0.7959\" - Complexity: \"2\"\n",
      "Split [7/10]\n",
      "\t Epoch 0: train accuracy: 0.5186\n",
      "\t Epoch 500: train accuracy: 0.9088\n",
      "\t Epoch 1000: train accuracy: 0.9361\n",
      "\t Epoch 1500: train accuracy: 0.9501\n",
      "\t Epoch 2000: train accuracy: 0.9611\n",
      "\t Epoch 2500: train accuracy: 0.9769\n",
      "\t Epoch 3000: train accuracy: 0.9853\n",
      "\t Epoch 3500: train accuracy: 0.8163\n",
      "\t Epoch 4000: train accuracy: 0.8711\n",
      "\t Epoch 4500: train accuracy: 0.8824\n",
      "\t Epoch 5000: train accuracy: 0.9013\n",
      "\t Epoch 5500: train accuracy: 0.9029\n",
      "\t Epoch 6000: train accuracy: 0.9034\n",
      "\t Epoch 0: train accuracy: 0.5313\n",
      "\t Epoch 500: train accuracy: 0.8392\n",
      "\t Epoch 1000: train accuracy: 0.8654\n",
      "\t Epoch 1500: train accuracy: 0.8694\n",
      "\t Epoch 2000: train accuracy: 0.8730\n",
      "\t Epoch 2500: train accuracy: 0.8779\n",
      "\t Epoch 3000: train accuracy: 0.8871\n",
      "\t Epoch 3500: train accuracy: 0.7384\n",
      "\t Epoch 4000: train accuracy: 0.7535\n",
      "\t Epoch 4500: train accuracy: 0.7529\n",
      "\t Epoch 5000: train accuracy: 0.7466\n",
      "\t Epoch 5500: train accuracy: 0.7496\n",
      "\t Epoch 6000: train accuracy: 0.7473\n",
      "\t Model's accuracy (mid): 0.3462 - Model's accuracy (top): 0.7337\n",
      "\t Class 1 - Global explanation: \"(v2x_egal)\" - Accuracy: 0.7101\n",
      "\t Elapsed time 0.02593064308166504\n",
      "\t Fidelity: \"0.7101\" - Complexity: \"1\"\n",
      "Split [8/10]\n",
      "\t Epoch 0: train accuracy: 0.5142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 500: train accuracy: 0.9026\n",
      "\t Epoch 1000: train accuracy: 0.9372\n",
      "\t Epoch 1500: train accuracy: 0.9485\n",
      "\t Epoch 2000: train accuracy: 0.9651\n",
      "\t Epoch 2500: train accuracy: 0.9782\n",
      "\t Epoch 3000: train accuracy: 0.9863\n",
      "\t Epoch 3500: train accuracy: 0.8006\n",
      "\t Epoch 4000: train accuracy: 0.8554\n",
      "\t Epoch 4500: train accuracy: 0.8759\n",
      "\t Epoch 5000: train accuracy: 0.8800\n",
      "\t Epoch 5500: train accuracy: 0.8835\n",
      "\t Epoch 6000: train accuracy: 0.8845\n",
      "\t Epoch 0: train accuracy: 0.5313\n",
      "\t Epoch 500: train accuracy: 0.8461\n",
      "\t Epoch 1000: train accuracy: 0.8661\n",
      "\t Epoch 1500: train accuracy: 0.8677\n",
      "\t Epoch 2000: train accuracy: 0.8691\n",
      "\t Epoch 2500: train accuracy: 0.8710\n",
      "\t Epoch 3000: train accuracy: 0.8809\n",
      "\t Epoch 3500: train accuracy: 0.7460\n",
      "\t Epoch 4000: train accuracy: 0.7699\n",
      "\t Epoch 4500: train accuracy: 0.7781\n",
      "\t Epoch 5000: train accuracy: 0.7749\n",
      "\t Epoch 5500: train accuracy: 0.7870\n",
      "\t Epoch 6000: train accuracy: 0.7968\n",
      "\t Model's accuracy (mid): 0.3166 - Model's accuracy (top): 0.7811\n",
      "\t Class 1 - Global explanation: \"(v2xel_frefair)\" - Accuracy: 0.9201\n",
      "\t Elapsed time 0.02194499969482422\n",
      "\t Fidelity: \"0.9201\" - Complexity: \"1\"\n",
      "Split [9/10]\n",
      "\t Epoch 0: train accuracy: 0.5690\n",
      "\t Epoch 500: train accuracy: 0.9119\n",
      "\t Epoch 1000: train accuracy: 0.9372\n",
      "\t Epoch 1500: train accuracy: 0.9493\n",
      "\t Epoch 2000: train accuracy: 0.9618\n",
      "\t Epoch 2500: train accuracy: 0.9753\n",
      "\t Epoch 3000: train accuracy: 0.9836\n",
      "\t Epoch 3500: train accuracy: 0.7855\n",
      "\t Epoch 4000: train accuracy: 0.8039\n",
      "\t Epoch 4500: train accuracy: 0.8427\n",
      "\t Epoch 5000: train accuracy: 0.8544\n",
      "\t Epoch 5500: train accuracy: 0.8617\n",
      "\t Epoch 6000: train accuracy: 0.8674\n",
      "\t Epoch 0: train accuracy: 0.5313\n",
      "\t Epoch 500: train accuracy: 0.8014\n",
      "\t Epoch 1000: train accuracy: 0.8707\n",
      "\t Epoch 1500: train accuracy: 0.8756\n",
      "\t Epoch 2000: train accuracy: 0.8773\n",
      "\t Epoch 2500: train accuracy: 0.8750\n",
      "\t Epoch 3000: train accuracy: 0.8841\n",
      "\t Epoch 3500: train accuracy: 0.8014\n",
      "\t Epoch 4000: train accuracy: 0.8303\n",
      "\t Epoch 4500: train accuracy: 0.8513\n",
      "\t Epoch 5000: train accuracy: 0.8487\n",
      "\t Epoch 5500: train accuracy: 0.8503\n",
      "\t Epoch 6000: train accuracy: 0.8563\n",
      "\t Model's accuracy (mid): 0.3047 - Model's accuracy (top): 0.8491\n",
      "\t Class 1 - Global explanation: \"(v2x_freexp_altinf & v2x_cspart & (v2xel_frefair | ~v2x_suffr) & (v2xeg_eqaccess | ~v2x_suffr))\" - Accuracy: 0.8817\n",
      "\t Elapsed time 0.035935163497924805\n",
      "\t Fidelity: \"0.8817\" - Complexity: \"6\"\n",
      "Split [10/10]\n",
      "\t Epoch 0: train accuracy: 0.5914\n",
      "\t Epoch 500: train accuracy: 0.9018\n",
      "\t Epoch 1000: train accuracy: 0.9371\n",
      "\t Epoch 1500: train accuracy: 0.9494\n",
      "\t Epoch 2000: train accuracy: 0.9649\n",
      "\t Epoch 2500: train accuracy: 0.9785\n",
      "\t Epoch 3000: train accuracy: 0.9861\n",
      "\t Epoch 3500: train accuracy: 0.7995\n",
      "\t Epoch 4000: train accuracy: 0.8485\n",
      "\t Epoch 4500: train accuracy: 0.8572\n",
      "\t Epoch 5000: train accuracy: 0.8672\n",
      "\t Epoch 5500: train accuracy: 0.8754\n",
      "\t Epoch 6000: train accuracy: 0.8801\n",
      "\t Epoch 0: train accuracy: 0.4683\n",
      "\t Epoch 500: train accuracy: 0.8011\n",
      "\t Epoch 1000: train accuracy: 0.8540\n",
      "\t Epoch 1500: train accuracy: 0.8664\n",
      "\t Epoch 2000: train accuracy: 0.8664\n",
      "\t Epoch 2500: train accuracy: 0.8740\n",
      "\t Epoch 3000: train accuracy: 0.8796\n",
      "\t Epoch 3500: train accuracy: 0.6387\n",
      "\t Epoch 4000: train accuracy: 0.6387\n",
      "\t Epoch 4500: train accuracy: 0.6387\n",
      "\t Epoch 5000: train accuracy: 0.6387\n",
      "\t Epoch 5500: train accuracy: 0.6387\n",
      "\t Epoch 6000: train accuracy: 0.6387\n",
      "\t Model's accuracy (mid): 0.3314 - Model's accuracy (top): 0.6361\n",
      "\t Class 1 - Global explanation: \"(v2xeg_eqdr)\" - Accuracy: 0.6479\n",
      "\t Elapsed time 0.0070116519927978516\n",
      "\t Fidelity: \"0.6479\" - Complexity: \"1\"\n",
      "Consistency of explanations: 0.1583\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>model_accuracy_mid</th>\n",
       "      <th>model_accuracy_top</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_fidelity</th>\n",
       "      <th>explanation_complexity</th>\n",
       "      <th>explanation_consistency</th>\n",
       "      <th>elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>psi</td>\n",
       "      <td>0</td>\n",
       "      <td>(v2x_mpi)</td>\n",
       "      <td>0.345133</td>\n",
       "      <td>0.867257</td>\n",
       "      <td>0.814159</td>\n",
       "      <td>0.814159</td>\n",
       "      <td>1</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>0.008008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>psi</td>\n",
       "      <td>1</td>\n",
       "      <td>(v2x_freexp_altinf &amp; v2xcl_rol)</td>\n",
       "      <td>0.336283</td>\n",
       "      <td>0.849558</td>\n",
       "      <td>0.828909</td>\n",
       "      <td>0.828909</td>\n",
       "      <td>2</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>0.030918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>psi</td>\n",
       "      <td>2</td>\n",
       "      <td>(v2xeg_eqaccess &amp; (v2xdl_delib | ~v2x_suffr))</td>\n",
       "      <td>0.353982</td>\n",
       "      <td>0.834808</td>\n",
       "      <td>0.828909</td>\n",
       "      <td>0.828909</td>\n",
       "      <td>3</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>0.047872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>psi</td>\n",
       "      <td>3</td>\n",
       "      <td>(v2x_elecoff)</td>\n",
       "      <td>0.265487</td>\n",
       "      <td>0.764012</td>\n",
       "      <td>0.681416</td>\n",
       "      <td>0.681416</td>\n",
       "      <td>1</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>0.028929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>psi</td>\n",
       "      <td>4</td>\n",
       "      <td>(v2x_frassoc_thick &amp; v2xeg_eqaccess)</td>\n",
       "      <td>0.168142</td>\n",
       "      <td>0.820059</td>\n",
       "      <td>0.876106</td>\n",
       "      <td>0.876106</td>\n",
       "      <td>2</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>0.033015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>psi</td>\n",
       "      <td>5</td>\n",
       "      <td>(v2x_frassoc_thick &amp; v2xeg_eqaccess)</td>\n",
       "      <td>0.378698</td>\n",
       "      <td>0.786982</td>\n",
       "      <td>0.795858</td>\n",
       "      <td>0.795858</td>\n",
       "      <td>2</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>0.027925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>psi</td>\n",
       "      <td>6</td>\n",
       "      <td>(v2x_egal)</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.733728</td>\n",
       "      <td>0.710059</td>\n",
       "      <td>0.710059</td>\n",
       "      <td>1</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>0.025931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>psi</td>\n",
       "      <td>7</td>\n",
       "      <td>(v2xel_frefair)</td>\n",
       "      <td>0.316568</td>\n",
       "      <td>0.781065</td>\n",
       "      <td>0.920118</td>\n",
       "      <td>0.920118</td>\n",
       "      <td>1</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>0.021945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>psi</td>\n",
       "      <td>8</td>\n",
       "      <td>(v2x_freexp_altinf &amp; v2x_cspart &amp; (v2xel_frefa...</td>\n",
       "      <td>0.304734</td>\n",
       "      <td>0.849112</td>\n",
       "      <td>0.881657</td>\n",
       "      <td>0.881657</td>\n",
       "      <td>6</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>0.035935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>psi</td>\n",
       "      <td>9</td>\n",
       "      <td>(v2xeg_eqdr)</td>\n",
       "      <td>0.331361</td>\n",
       "      <td>0.636095</td>\n",
       "      <td>0.647929</td>\n",
       "      <td>0.647929</td>\n",
       "      <td>1</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>0.007012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  split                                        explanation  \\\n",
       "0    psi      0                                          (v2x_mpi)   \n",
       "1    psi      1                    (v2x_freexp_altinf & v2xcl_rol)   \n",
       "2    psi      2      (v2xeg_eqaccess & (v2xdl_delib | ~v2x_suffr))   \n",
       "3    psi      3                                      (v2x_elecoff)   \n",
       "4    psi      4               (v2x_frassoc_thick & v2xeg_eqaccess)   \n",
       "5    psi      5               (v2x_frassoc_thick & v2xeg_eqaccess)   \n",
       "6    psi      6                                         (v2x_egal)   \n",
       "7    psi      7                                    (v2xel_frefair)   \n",
       "8    psi      8  (v2x_freexp_altinf & v2x_cspart & (v2xel_frefa...   \n",
       "9    psi      9                                       (v2xeg_eqdr)   \n",
       "\n",
       "   model_accuracy_mid  model_accuracy_top  explanation_accuracy  \\\n",
       "0            0.345133            0.867257              0.814159   \n",
       "1            0.336283            0.849558              0.828909   \n",
       "2            0.353982            0.834808              0.828909   \n",
       "3            0.265487            0.764012              0.681416   \n",
       "4            0.168142            0.820059              0.876106   \n",
       "5            0.378698            0.786982              0.795858   \n",
       "6            0.346154            0.733728              0.710059   \n",
       "7            0.316568            0.781065              0.920118   \n",
       "8            0.304734            0.849112              0.881657   \n",
       "9            0.331361            0.636095              0.647929   \n",
       "\n",
       "   explanation_fidelity  explanation_complexity  explanation_consistency  \\\n",
       "0              0.814159                       1                 0.158333   \n",
       "1              0.828909                       2                 0.158333   \n",
       "2              0.828909                       3                 0.158333   \n",
       "3              0.681416                       1                 0.158333   \n",
       "4              0.876106                       2                 0.158333   \n",
       "5              0.795858                       2                 0.158333   \n",
       "6              0.710059                       1                 0.158333   \n",
       "7              0.920118                       1                 0.158333   \n",
       "8              0.881657                       6                 0.158333   \n",
       "9              0.647929                       1                 0.158333   \n",
       "\n",
       "   elapsed_time  \n",
       "0      0.008008  \n",
       "1      0.030918  \n",
       "2      0.047872  \n",
       "3      0.028929  \n",
       "4      0.033015  \n",
       "5      0.027925  \n",
       "6      0.025931  \n",
       "7      0.021945  \n",
       "8      0.035935  \n",
       "9      0.007012  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = 'psi'\n",
    "need_pruning = True\n",
    "relu = False\n",
    "results_psi = c_to_y(method, need_pruning, relu, verbose=True)\n",
    "results_psi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-addition",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "scheduled-quilt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split [1/10]\n",
      "Split [2/10]\n",
      "Split [3/10]\n",
      "Split [4/10]\n",
      "Split [5/10]\n",
      "Split [6/10]\n",
      "Split [7/10]\n",
      "Split [8/10]\n",
      "Split [9/10]\n",
      "Split [10/10]\n",
      "Consistency of explanations: 0.3686\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>model_accuracy_mid</th>\n",
       "      <th>model_accuracy_top</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_fidelity</th>\n",
       "      <th>explanation_complexity</th>\n",
       "      <th>explanation_consistency</th>\n",
       "      <th>elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tree</td>\n",
       "      <td>0</td>\n",
       "      <td>(v2xel_frefair &lt;= 0.33 &amp; v2xcl_rol &gt; 0.90 &amp; v2...</td>\n",
       "      <td>0.749263</td>\n",
       "      <td>0.935103</td>\n",
       "      <td>0.935103</td>\n",
       "      <td>0.935103</td>\n",
       "      <td>305</td>\n",
       "      <td>0.368571</td>\n",
       "      <td>0.000998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>(v2xel_frefair &lt;= 0.33 &amp; v2xdl_delib &gt; 0.58 &amp; ...</td>\n",
       "      <td>0.784661</td>\n",
       "      <td>0.932153</td>\n",
       "      <td>0.932153</td>\n",
       "      <td>0.932153</td>\n",
       "      <td>294</td>\n",
       "      <td>0.368571</td>\n",
       "      <td>0.000997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tree</td>\n",
       "      <td>2</td>\n",
       "      <td>(v2xel_frefair &lt;= 0.58 &amp; v2xcl_rol &gt; 0.88 &amp; v2...</td>\n",
       "      <td>0.746313</td>\n",
       "      <td>0.932153</td>\n",
       "      <td>0.932153</td>\n",
       "      <td>0.932153</td>\n",
       "      <td>236</td>\n",
       "      <td>0.368571</td>\n",
       "      <td>0.000998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tree</td>\n",
       "      <td>3</td>\n",
       "      <td>(v2xel_frefair &lt;= 0.88 &amp; v2xcl_rol &gt; 0.90 &amp; v2...</td>\n",
       "      <td>0.734513</td>\n",
       "      <td>0.914454</td>\n",
       "      <td>0.914454</td>\n",
       "      <td>0.914454</td>\n",
       "      <td>289</td>\n",
       "      <td>0.368571</td>\n",
       "      <td>0.000998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tree</td>\n",
       "      <td>4</td>\n",
       "      <td>(v2xel_frefair &lt;= 0.44 &amp; v2xcl_rol &gt; 0.90 &amp; v2...</td>\n",
       "      <td>0.722714</td>\n",
       "      <td>0.917404</td>\n",
       "      <td>0.917404</td>\n",
       "      <td>0.917404</td>\n",
       "      <td>289</td>\n",
       "      <td>0.368571</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tree</td>\n",
       "      <td>5</td>\n",
       "      <td>(v2xel_frefair &lt;= 0.46 &amp; v2xdl_delib &gt; 0.61 &amp; ...</td>\n",
       "      <td>0.745562</td>\n",
       "      <td>0.905325</td>\n",
       "      <td>0.905325</td>\n",
       "      <td>0.905325</td>\n",
       "      <td>319</td>\n",
       "      <td>0.368571</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tree</td>\n",
       "      <td>6</td>\n",
       "      <td>(v2xel_frefair &lt;= 0.47 &amp; v2xcl_rol &gt; 0.90 &amp; v2...</td>\n",
       "      <td>0.760355</td>\n",
       "      <td>0.899408</td>\n",
       "      <td>0.899408</td>\n",
       "      <td>0.899408</td>\n",
       "      <td>313</td>\n",
       "      <td>0.368571</td>\n",
       "      <td>0.000997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tree</td>\n",
       "      <td>7</td>\n",
       "      <td>(v2xel_frefair &lt;= 0.33 &amp; v2xcl_rol &gt; 0.88 &amp; v2...</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.926036</td>\n",
       "      <td>0.926036</td>\n",
       "      <td>0.926036</td>\n",
       "      <td>309</td>\n",
       "      <td>0.368571</td>\n",
       "      <td>0.000996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tree</td>\n",
       "      <td>8</td>\n",
       "      <td>(v2xel_frefair &lt;= 0.88 &amp; v2xcl_rol &gt; 0.90 &amp; v2...</td>\n",
       "      <td>0.754438</td>\n",
       "      <td>0.928994</td>\n",
       "      <td>0.928994</td>\n",
       "      <td>0.928994</td>\n",
       "      <td>273</td>\n",
       "      <td>0.368571</td>\n",
       "      <td>0.000997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tree</td>\n",
       "      <td>9</td>\n",
       "      <td>(v2xel_frefair &lt;= 0.58 &amp; v2xcl_rol &gt; 0.88 &amp; v2...</td>\n",
       "      <td>0.789941</td>\n",
       "      <td>0.920118</td>\n",
       "      <td>0.920118</td>\n",
       "      <td>0.920118</td>\n",
       "      <td>314</td>\n",
       "      <td>0.368571</td>\n",
       "      <td>0.001995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  split                                        explanation  \\\n",
       "0   tree      0  (v2xel_frefair <= 0.33 & v2xcl_rol > 0.90 & v2...   \n",
       "1   tree      1  (v2xel_frefair <= 0.33 & v2xdl_delib > 0.58 & ...   \n",
       "2   tree      2  (v2xel_frefair <= 0.58 & v2xcl_rol > 0.88 & v2...   \n",
       "3   tree      3  (v2xel_frefair <= 0.88 & v2xcl_rol > 0.90 & v2...   \n",
       "4   tree      4  (v2xel_frefair <= 0.44 & v2xcl_rol > 0.90 & v2...   \n",
       "5   tree      5  (v2xel_frefair <= 0.46 & v2xdl_delib > 0.61 & ...   \n",
       "6   tree      6  (v2xel_frefair <= 0.47 & v2xcl_rol > 0.90 & v2...   \n",
       "7   tree      7  (v2xel_frefair <= 0.33 & v2xcl_rol > 0.88 & v2...   \n",
       "8   tree      8  (v2xel_frefair <= 0.88 & v2xcl_rol > 0.90 & v2...   \n",
       "9   tree      9  (v2xel_frefair <= 0.58 & v2xcl_rol > 0.88 & v2...   \n",
       "\n",
       "   model_accuracy_mid  model_accuracy_top  explanation_accuracy  \\\n",
       "0            0.749263            0.935103              0.935103   \n",
       "1            0.784661            0.932153              0.932153   \n",
       "2            0.746313            0.932153              0.932153   \n",
       "3            0.734513            0.914454              0.914454   \n",
       "4            0.722714            0.917404              0.917404   \n",
       "5            0.745562            0.905325              0.905325   \n",
       "6            0.760355            0.899408              0.899408   \n",
       "7            0.769231            0.926036              0.926036   \n",
       "8            0.754438            0.928994              0.928994   \n",
       "9            0.789941            0.920118              0.920118   \n",
       "\n",
       "   explanation_fidelity  explanation_complexity  explanation_consistency  \\\n",
       "0              0.935103                     305                 0.368571   \n",
       "1              0.932153                     294                 0.368571   \n",
       "2              0.932153                     236                 0.368571   \n",
       "3              0.914454                     289                 0.368571   \n",
       "4              0.917404                     289                 0.368571   \n",
       "5              0.905325                     319                 0.368571   \n",
       "6              0.899408                     313                 0.368571   \n",
       "7              0.926036                     309                 0.368571   \n",
       "8              0.928994                     273                 0.368571   \n",
       "9              0.920118                     314                 0.368571   \n",
       "\n",
       "   elapsed_time  \n",
       "0      0.000998  \n",
       "1      0.000997  \n",
       "2      0.000998  \n",
       "3      0.000998  \n",
       "4      0.000000  \n",
       "5      0.000000  \n",
       "6      0.000997  \n",
       "7      0.000996  \n",
       "8      0.000997  \n",
       "9      0.001995  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = 'tree'\n",
    "need_pruning = False\n",
    "relu = False\n",
    "results_tree = c_to_y(method, need_pruning, relu, verbose=False)\n",
    "results_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-agent",
   "metadata": {},
   "source": [
    "## BRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "binding-salmon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split [1/10]\n",
      "\t Epoch 0: train accuracy: 0.5213\n",
      "\t Epoch 500: train accuracy: 0.9802\n",
      "\t Epoch 1000: train accuracy: 0.9908\n",
      "\t Epoch 1500: train accuracy: 0.9946\n",
      "\t Epoch 2000: train accuracy: 0.9962\n",
      "\t Epoch 2500: train accuracy: 0.9966\n",
      "\t Epoch 3000: train accuracy: 0.9968\n",
      "\t Epoch 3500: train accuracy: 0.9968\n",
      "\t Epoch 4000: train accuracy: 0.9968\n",
      "\t Epoch 4500: train accuracy: 0.9968\n",
      "\t Epoch 5000: train accuracy: 0.9968\n",
      "\t Epoch 5500: train accuracy: 0.9968\n",
      "\t Epoch 6000: train accuracy: 0.9968\n",
      "Labels (3046, 2)\n",
      "Discretized features\n",
      "Completed model 1/2!\n",
      "Completed model 2/2!\n",
      "Train_acc: 0.9, Val_acc: 0.0\n",
      "\t Model's accuracy (mid): 0.0000 - Model's accuracy (top): 92.0354\n",
      "\t Class 1 - Global explanation: \"v2x_mpi | (v2x_freexp_altinf & v2x_frassoc_thick & v2xel_frefair & v2x_elecoff & v2xcl_rol)\" - Accuracy: 0.9469\n",
      "\t Elapsed time 0.017922401428222656\n",
      "\t Fidelity: \"0.9469\" - Complexity: \"6\"\n",
      "Split [2/10]\n",
      "\t Epoch 0: train accuracy: 0.5215\n",
      "\t Epoch 500: train accuracy: 0.9804\n",
      "\t Epoch 1000: train accuracy: 0.9912\n",
      "\t Epoch 1500: train accuracy: 0.9949\n",
      "\t Epoch 2000: train accuracy: 0.9965\n",
      "\t Epoch 2500: train accuracy: 0.9969\n",
      "\t Epoch 3000: train accuracy: 0.9970\n",
      "\t Epoch 3500: train accuracy: 0.9970\n",
      "\t Epoch 4000: train accuracy: 0.9970\n",
      "\t Epoch 4500: train accuracy: 0.9970\n",
      "\t Epoch 5000: train accuracy: 0.9970\n",
      "\t Epoch 5500: train accuracy: 0.9970\n",
      "\t Epoch 6000: train accuracy: 0.9970\n",
      "Labels (3046, 2)\n",
      "Discretized features\n",
      "Completed model 1/2!\n",
      "Completed model 2/2!\n",
      "Train_acc: 0.9, Val_acc: 0.0\n",
      "\t Model's accuracy (mid): 0.0000 - Model's accuracy (top): 92.9204\n",
      "\t Class 1 - Global explanation: \"(v2x_mpi & v2x_freexp_altinf & v2xcl_rol) | (v2x_freexp_altinf & v2x_frassoc_thick & v2xel_frefair & v2x_elecoff & v2xcl_rol)\" - Accuracy: 0.9558\n",
      "\t Elapsed time 0.014959573745727539\n",
      "\t Fidelity: \"0.9558\" - Complexity: \"8\"\n",
      "Split [3/10]\n",
      "\t Epoch 0: train accuracy: 0.5211\n",
      "\t Epoch 500: train accuracy: 0.9803\n",
      "\t Epoch 1000: train accuracy: 0.9912\n",
      "\t Epoch 1500: train accuracy: 0.9951\n",
      "\t Epoch 2000: train accuracy: 0.9961\n",
      "\t Epoch 2500: train accuracy: 0.9967\n",
      "\t Epoch 3000: train accuracy: 0.9970\n",
      "\t Epoch 3500: train accuracy: 0.9970\n",
      "\t Epoch 4000: train accuracy: 0.9970\n",
      "\t Epoch 4500: train accuracy: 0.9970\n",
      "\t Epoch 5000: train accuracy: 0.9970\n",
      "\t Epoch 5500: train accuracy: 0.9971\n",
      "\t Epoch 6000: train accuracy: 0.9971\n",
      "Labels (3046, 2)\n",
      "Discretized features\n",
      "Completed model 1/2!\n",
      "Completed model 2/2!\n",
      "Train_acc: 0.9, Val_acc: 0.0\n",
      "\t Model's accuracy (mid): 0.0000 - Model's accuracy (top): 91.7404\n",
      "\t Class 1 - Global explanation: \"(v2x_mpi & v2x_freexp_altinf & v2x_frassoc_thick & v2x_elecoff & v2xcl_rol) | (v2x_freexp_altinf & v2x_frassoc_thick & v2xel_frefair & v2x_elecoff & v2xcl_rol)\" - Accuracy: 0.9381\n",
      "\t Elapsed time 0.018949508666992188\n",
      "\t Fidelity: \"0.9381\" - Complexity: \"10\"\n",
      "Split [4/10]\n",
      "\t Epoch 0: train accuracy: 0.5210\n",
      "\t Epoch 500: train accuracy: 0.9804\n",
      "\t Epoch 1000: train accuracy: 0.9910\n",
      "\t Epoch 1500: train accuracy: 0.9948\n",
      "\t Epoch 2000: train accuracy: 0.9964\n",
      "\t Epoch 2500: train accuracy: 0.9968\n",
      "\t Epoch 3000: train accuracy: 0.9968\n",
      "\t Epoch 3500: train accuracy: 0.9969\n",
      "\t Epoch 4000: train accuracy: 0.9969\n",
      "\t Epoch 4500: train accuracy: 0.9969\n",
      "\t Epoch 5000: train accuracy: 0.9969\n",
      "\t Epoch 5500: train accuracy: 0.9969\n",
      "\t Epoch 6000: train accuracy: 0.9969\n",
      "Labels (3046, 2)\n",
      "Discretized features\n",
      "Completed model 1/2!\n",
      "Completed model 2/2!\n",
      "Train_acc: 0.9, Val_acc: 0.0\n",
      "\t Model's accuracy (mid): 0.0000 - Model's accuracy (top): 90.8555\n",
      "\t Class 1 - Global explanation: \"(v2x_mpi & v2x_freexp_altinf & v2x_frassoc_thick & v2x_elecoff & v2xcl_rol) | (v2x_freexp_altinf & v2x_frassoc_thick & v2xel_frefair & v2x_elecoff & v2xcl_rol)\" - Accuracy: 0.9499\n",
      "\t Elapsed time 0.018918991088867188\n",
      "\t Fidelity: \"0.9499\" - Complexity: \"10\"\n",
      "Split [5/10]\n",
      "\t Epoch 0: train accuracy: 0.5208\n",
      "\t Epoch 500: train accuracy: 0.9809\n",
      "\t Epoch 1000: train accuracy: 0.9912\n",
      "\t Epoch 1500: train accuracy: 0.9950\n",
      "\t Epoch 2000: train accuracy: 0.9963\n",
      "\t Epoch 2500: train accuracy: 0.9968\n",
      "\t Epoch 3000: train accuracy: 0.9970\n",
      "\t Epoch 3500: train accuracy: 0.9970\n",
      "\t Epoch 4000: train accuracy: 0.9970\n",
      "\t Epoch 4500: train accuracy: 0.9970\n",
      "\t Epoch 5000: train accuracy: 0.9970\n",
      "\t Epoch 5500: train accuracy: 0.9970\n",
      "\t Epoch 6000: train accuracy: 0.9970\n",
      "Labels (3046, 2)\n",
      "Discretized features\n",
      "Completed model 1/2!\n",
      "Completed model 2/2!\n",
      "Train_acc: 0.9, Val_acc: 0.0\n",
      "\t Model's accuracy (mid): 0.0000 - Model's accuracy (top): 93.2153\n",
      "\t Class 1 - Global explanation: \"v2x_mpi | (v2x_freexp_altinf & v2x_frassoc_thick & v2xel_frefair & v2x_elecoff & v2xcl_rol)\" - Accuracy: 0.9617\n",
      "\t Elapsed time 0.016953706741333008\n",
      "\t Fidelity: \"0.9617\" - Complexity: \"6\"\n",
      "Split [6/10]\n",
      "\t Epoch 0: train accuracy: 0.5217\n",
      "\t Epoch 500: train accuracy: 0.9812\n",
      "\t Epoch 1000: train accuracy: 0.9915\n",
      "\t Epoch 1500: train accuracy: 0.9952\n",
      "\t Epoch 2000: train accuracy: 0.9962\n",
      "\t Epoch 2500: train accuracy: 0.9967\n",
      "\t Epoch 3000: train accuracy: 0.9968\n",
      "\t Epoch 3500: train accuracy: 0.9968\n",
      "\t Epoch 4000: train accuracy: 0.9968\n",
      "\t Epoch 4500: train accuracy: 0.9968\n",
      "\t Epoch 5000: train accuracy: 0.9968\n",
      "\t Epoch 5500: train accuracy: 0.9968\n",
      "\t Epoch 6000: train accuracy: 0.9968\n",
      "Labels (3047, 2)\n",
      "Discretized features\n",
      "Completed model 1/2!\n",
      "Completed model 2/2!\n",
      "Train_acc: 0.9, Val_acc: 0.0\n",
      "\t Model's accuracy (mid): 0.0000 - Model's accuracy (top): 90.8284\n",
      "\t Class 1 - Global explanation: \"(v2x_mpi & v2x_freexp_altinf & v2x_frassoc_thick & v2xcl_rol) | (v2x_freexp_altinf & v2x_frassoc_thick & v2xel_frefair & v2x_elecoff & v2xcl_rol)\" - Accuracy: 0.9349\n",
      "\t Elapsed time 0.014959573745727539\n",
      "\t Fidelity: \"0.9349\" - Complexity: \"9\"\n",
      "Split [7/10]\n",
      "\t Epoch 0: train accuracy: 0.5214\n",
      "\t Epoch 500: train accuracy: 0.9798\n",
      "\t Epoch 1000: train accuracy: 0.9912\n",
      "\t Epoch 1500: train accuracy: 0.9948\n",
      "\t Epoch 2000: train accuracy: 0.9961\n",
      "\t Epoch 2500: train accuracy: 0.9966\n",
      "\t Epoch 3000: train accuracy: 0.9968\n",
      "\t Epoch 3500: train accuracy: 0.9969\n",
      "\t Epoch 4000: train accuracy: 0.9969\n",
      "\t Epoch 4500: train accuracy: 0.9969\n",
      "\t Epoch 5000: train accuracy: 0.9969\n",
      "\t Epoch 5500: train accuracy: 0.9969\n",
      "\t Epoch 6000: train accuracy: 0.9969\n",
      "Labels (3047, 2)\n",
      "Discretized features\n",
      "Completed model 1/2!\n",
      "Completed model 2/2!\n",
      "Train_acc: 0.9, Val_acc: 0.0\n",
      "\t Model's accuracy (mid): 0.0000 - Model's accuracy (top): 91.7160\n",
      "\t Class 1 - Global explanation: \"(v2x_mpi & v2x_freexp_altinf & v2xcl_rol) | (v2x_freexp_altinf & v2x_frassoc_thick & v2xel_frefair & v2x_elecoff & v2xcl_rol)\" - Accuracy: 0.9438\n",
      "\t Elapsed time 0.013962268829345703\n",
      "\t Fidelity: \"0.9438\" - Complexity: \"8\"\n",
      "Split [8/10]\n",
      "\t Epoch 0: train accuracy: 0.5217\n",
      "\t Epoch 500: train accuracy: 0.9808\n",
      "\t Epoch 1000: train accuracy: 0.9917\n",
      "\t Epoch 1500: train accuracy: 0.9953\n",
      "\t Epoch 2000: train accuracy: 0.9965\n",
      "\t Epoch 2500: train accuracy: 0.9969\n",
      "\t Epoch 3000: train accuracy: 0.9970\n",
      "\t Epoch 3500: train accuracy: 0.9970\n",
      "\t Epoch 4000: train accuracy: 0.9970\n",
      "\t Epoch 4500: train accuracy: 0.9971\n",
      "\t Epoch 5000: train accuracy: 0.9971\n",
      "\t Epoch 5500: train accuracy: 0.9971\n",
      "\t Epoch 6000: train accuracy: 0.9971\n",
      "Labels (3047, 2)\n",
      "Discretized features\n",
      "Completed model 1/2!\n",
      "Completed model 2/2!\n",
      "Train_acc: 0.9, Val_acc: 0.0\n",
      "\t Model's accuracy (mid): 0.0000 - Model's accuracy (top): 92.3077\n",
      "\t Class 1 - Global explanation: \"(v2x_mpi & v2x_freexp_altinf) | (v2x_freexp_altinf & v2x_frassoc_thick & v2xel_frefair & v2x_elecoff & v2xcl_rol & v2x_cspart)\" - Accuracy: 0.9586\n",
      "\t Elapsed time 0.03291201591491699\n",
      "\t Fidelity: \"0.9586\" - Complexity: \"8\"\n",
      "Split [9/10]\n",
      "\t Epoch 0: train accuracy: 0.5207\n",
      "\t Epoch 500: train accuracy: 0.9803\n",
      "\t Epoch 1000: train accuracy: 0.9911\n",
      "\t Epoch 1500: train accuracy: 0.9951\n",
      "\t Epoch 2000: train accuracy: 0.9966\n",
      "\t Epoch 2500: train accuracy: 0.9969\n",
      "\t Epoch 3000: train accuracy: 0.9970\n",
      "\t Epoch 3500: train accuracy: 0.9970\n",
      "\t Epoch 4000: train accuracy: 0.9970\n",
      "\t Epoch 4500: train accuracy: 0.9970\n",
      "\t Epoch 5000: train accuracy: 0.9970\n",
      "\t Epoch 5500: train accuracy: 0.9971\n",
      "\t Epoch 6000: train accuracy: 0.9971\n",
      "Labels (3047, 2)\n",
      "Discretized features\n",
      "Completed model 1/2!\n",
      "Completed model 2/2!\n",
      "Train_acc: 0.9, Val_acc: 0.0\n",
      "\t Model's accuracy (mid): 0.0000 - Model's accuracy (top): 91.4201\n",
      "\t Class 1 - Global explanation: \"(v2x_mpi & v2x_freexp_altinf & v2x_frassoc_thick & v2xcl_rol) | (v2x_freexp_altinf & v2x_frassoc_thick & v2xel_frefair & v2x_elecoff & v2xcl_rol)\" - Accuracy: 0.9408\n",
      "\t Elapsed time 0.01495981216430664\n",
      "\t Fidelity: \"0.9408\" - Complexity: \"9\"\n",
      "Split [10/10]\n",
      "\t Epoch 0: train accuracy: 0.5217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 500: train accuracy: 0.9802\n",
      "\t Epoch 1000: train accuracy: 0.9904\n",
      "\t Epoch 1500: train accuracy: 0.9948\n",
      "\t Epoch 2000: train accuracy: 0.9959\n",
      "\t Epoch 2500: train accuracy: 0.9967\n",
      "\t Epoch 3000: train accuracy: 0.9968\n",
      "\t Epoch 3500: train accuracy: 0.9969\n",
      "\t Epoch 4000: train accuracy: 0.9969\n",
      "\t Epoch 4500: train accuracy: 0.9969\n",
      "\t Epoch 5000: train accuracy: 0.9969\n",
      "\t Epoch 5500: train accuracy: 0.9969\n",
      "\t Epoch 6000: train accuracy: 0.9969\n",
      "Labels (3047, 2)\n",
      "Discretized features\n",
      "Completed model 1/2!\n",
      "Completed model 2/2!\n",
      "Train_acc: 0.9, Val_acc: 0.0\n",
      "\t Model's accuracy (mid): 0.0000 - Model's accuracy (top): 92.3077\n",
      "\t Class 1 - Global explanation: \"v2x_mpi & v2x_freexp_altinf & v2xcl_rol\" - Accuracy: 0.8136\n",
      "\t Elapsed time 0.10372233390808105\n",
      "\t Fidelity: \"0.8136\" - Complexity: \"3\"\n",
      "Consistency of explanations: 0.8286\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>model_accuracy_mid</th>\n",
       "      <th>model_accuracy_top</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_fidelity</th>\n",
       "      <th>explanation_complexity</th>\n",
       "      <th>explanation_consistency</th>\n",
       "      <th>elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>brl</td>\n",
       "      <td>0</td>\n",
       "      <td>v2x_mpi | (v2x_freexp_altinf &amp; v2x_frassoc_thi...</td>\n",
       "      <td>0</td>\n",
       "      <td>92.035398</td>\n",
       "      <td>0.946903</td>\n",
       "      <td>0.946903</td>\n",
       "      <td>6</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.017922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brl</td>\n",
       "      <td>1</td>\n",
       "      <td>(v2x_mpi &amp; v2x_freexp_altinf &amp; v2xcl_rol) | (v...</td>\n",
       "      <td>0</td>\n",
       "      <td>92.920354</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>8</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.014960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brl</td>\n",
       "      <td>2</td>\n",
       "      <td>(v2x_mpi &amp; v2x_freexp_altinf &amp; v2x_frassoc_thi...</td>\n",
       "      <td>0</td>\n",
       "      <td>91.740413</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>10</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.018950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>brl</td>\n",
       "      <td>3</td>\n",
       "      <td>(v2x_mpi &amp; v2x_freexp_altinf &amp; v2x_frassoc_thi...</td>\n",
       "      <td>0</td>\n",
       "      <td>90.855457</td>\n",
       "      <td>0.949853</td>\n",
       "      <td>0.949853</td>\n",
       "      <td>10</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.018919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brl</td>\n",
       "      <td>4</td>\n",
       "      <td>v2x_mpi | (v2x_freexp_altinf &amp; v2x_frassoc_thi...</td>\n",
       "      <td>0</td>\n",
       "      <td>93.215339</td>\n",
       "      <td>0.961652</td>\n",
       "      <td>0.961652</td>\n",
       "      <td>6</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.016954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>brl</td>\n",
       "      <td>5</td>\n",
       "      <td>(v2x_mpi &amp; v2x_freexp_altinf &amp; v2x_frassoc_thi...</td>\n",
       "      <td>0</td>\n",
       "      <td>90.828402</td>\n",
       "      <td>0.934911</td>\n",
       "      <td>0.934911</td>\n",
       "      <td>9</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.014960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>brl</td>\n",
       "      <td>6</td>\n",
       "      <td>(v2x_mpi &amp; v2x_freexp_altinf &amp; v2xcl_rol) | (v...</td>\n",
       "      <td>0</td>\n",
       "      <td>91.715976</td>\n",
       "      <td>0.943787</td>\n",
       "      <td>0.943787</td>\n",
       "      <td>8</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.013962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>brl</td>\n",
       "      <td>7</td>\n",
       "      <td>(v2x_mpi &amp; v2x_freexp_altinf) | (v2x_freexp_al...</td>\n",
       "      <td>0</td>\n",
       "      <td>92.307692</td>\n",
       "      <td>0.958580</td>\n",
       "      <td>0.958580</td>\n",
       "      <td>8</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.032912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>brl</td>\n",
       "      <td>8</td>\n",
       "      <td>(v2x_mpi &amp; v2x_freexp_altinf &amp; v2x_frassoc_thi...</td>\n",
       "      <td>0</td>\n",
       "      <td>91.420118</td>\n",
       "      <td>0.940828</td>\n",
       "      <td>0.940828</td>\n",
       "      <td>9</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.014960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>brl</td>\n",
       "      <td>9</td>\n",
       "      <td>v2x_mpi &amp; v2x_freexp_altinf &amp; v2xcl_rol</td>\n",
       "      <td>0</td>\n",
       "      <td>92.307692</td>\n",
       "      <td>0.813609</td>\n",
       "      <td>0.813609</td>\n",
       "      <td>3</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.103722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  split                                        explanation  \\\n",
       "0    brl      0  v2x_mpi | (v2x_freexp_altinf & v2x_frassoc_thi...   \n",
       "1    brl      1  (v2x_mpi & v2x_freexp_altinf & v2xcl_rol) | (v...   \n",
       "2    brl      2  (v2x_mpi & v2x_freexp_altinf & v2x_frassoc_thi...   \n",
       "3    brl      3  (v2x_mpi & v2x_freexp_altinf & v2x_frassoc_thi...   \n",
       "4    brl      4  v2x_mpi | (v2x_freexp_altinf & v2x_frassoc_thi...   \n",
       "5    brl      5  (v2x_mpi & v2x_freexp_altinf & v2x_frassoc_thi...   \n",
       "6    brl      6  (v2x_mpi & v2x_freexp_altinf & v2xcl_rol) | (v...   \n",
       "7    brl      7  (v2x_mpi & v2x_freexp_altinf) | (v2x_freexp_al...   \n",
       "8    brl      8  (v2x_mpi & v2x_freexp_altinf & v2x_frassoc_thi...   \n",
       "9    brl      9            v2x_mpi & v2x_freexp_altinf & v2xcl_rol   \n",
       "\n",
       "   model_accuracy_mid  model_accuracy_top  explanation_accuracy  \\\n",
       "0                   0           92.035398              0.946903   \n",
       "1                   0           92.920354              0.955752   \n",
       "2                   0           91.740413              0.938053   \n",
       "3                   0           90.855457              0.949853   \n",
       "4                   0           93.215339              0.961652   \n",
       "5                   0           90.828402              0.934911   \n",
       "6                   0           91.715976              0.943787   \n",
       "7                   0           92.307692              0.958580   \n",
       "8                   0           91.420118              0.940828   \n",
       "9                   0           92.307692              0.813609   \n",
       "\n",
       "   explanation_fidelity  explanation_complexity  explanation_consistency  \\\n",
       "0              0.946903                       6                 0.828571   \n",
       "1              0.955752                       8                 0.828571   \n",
       "2              0.938053                      10                 0.828571   \n",
       "3              0.949853                      10                 0.828571   \n",
       "4              0.961652                       6                 0.828571   \n",
       "5              0.934911                       9                 0.828571   \n",
       "6              0.943787                       8                 0.828571   \n",
       "7              0.958580                       8                 0.828571   \n",
       "8              0.940828                       9                 0.828571   \n",
       "9              0.813609                       3                 0.828571   \n",
       "\n",
       "   elapsed_time  \n",
       "0      0.017922  \n",
       "1      0.014960  \n",
       "2      0.018950  \n",
       "3      0.018919  \n",
       "4      0.016954  \n",
       "5      0.014960  \n",
       "6      0.013962  \n",
       "7      0.032912  \n",
       "8      0.014960  \n",
       "9      0.103722  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = 'brl'\n",
    "need_pruning = False\n",
    "relu = False\n",
    "results_brl = c_to_y(method, need_pruning, relu, verbose=True)\n",
    "results_brl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-liberia",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "competent-measure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_accuracy_top_mean</th>\n",
       "      <th>explanation_accuracy_mean</th>\n",
       "      <th>explanation_fidelity_mean</th>\n",
       "      <th>explanation_complexity_mean</th>\n",
       "      <th>elapsed_time_mean</th>\n",
       "      <th>explanation_consistency_mean</th>\n",
       "      <th>model_accuracy_top_sem</th>\n",
       "      <th>explanation_accuracy_sem</th>\n",
       "      <th>explanation_fidelity_sem</th>\n",
       "      <th>explanation_complexity_sem</th>\n",
       "      <th>elapsed_time_sem</th>\n",
       "      <th>explanation_consistency_sem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pruning</th>\n",
       "      <td>0.910774</td>\n",
       "      <td>0.851073</td>\n",
       "      <td>0.851073</td>\n",
       "      <td>9.3</td>\n",
       "      <td>2.912821</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.009276</td>\n",
       "      <td>0.014165</td>\n",
       "      <td>0.014165</td>\n",
       "      <td>0.746101</td>\n",
       "      <td>0.158873</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weights</th>\n",
       "      <td>0.926726</td>\n",
       "      <td>0.544713</td>\n",
       "      <td>0.544713</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.096242</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>0.027152</td>\n",
       "      <td>0.027152</td>\n",
       "      <td>0.553775</td>\n",
       "      <td>0.122414</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psi</th>\n",
       "      <td>0.792268</td>\n",
       "      <td>0.798512</td>\n",
       "      <td>0.798512</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.026749</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>0.021982</td>\n",
       "      <td>0.028681</td>\n",
       "      <td>0.028681</td>\n",
       "      <td>0.494413</td>\n",
       "      <td>0.003884</td>\n",
       "      <td>9.251859e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>0.921115</td>\n",
       "      <td>0.921115</td>\n",
       "      <td>0.921115</td>\n",
       "      <td>294.1</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.368571</td>\n",
       "      <td>0.003808</td>\n",
       "      <td>0.003808</td>\n",
       "      <td>0.003808</td>\n",
       "      <td>7.878875</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>1.850372e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRL</th>\n",
       "      <td>91.934684</td>\n",
       "      <td>0.934393</td>\n",
       "      <td>0.934393</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.026822</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.250310</td>\n",
       "      <td>0.013708</td>\n",
       "      <td>0.013708</td>\n",
       "      <td>0.683943</td>\n",
       "      <td>0.008717</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model_accuracy_top_mean  explanation_accuracy_mean  \\\n",
       "pruning                 0.910774                   0.851073   \n",
       "weights                 0.926726                   0.544713   \n",
       "psi                     0.792268                   0.798512   \n",
       "tree                    0.921115                   0.921115   \n",
       "BRL                    91.934684                   0.934393   \n",
       "\n",
       "         explanation_fidelity_mean  explanation_complexity_mean  \\\n",
       "pruning                   0.851073                          9.3   \n",
       "weights                   0.544713                          4.2   \n",
       "psi                       0.798512                          2.0   \n",
       "tree                      0.921115                        294.1   \n",
       "BRL                       0.934393                          7.7   \n",
       "\n",
       "         elapsed_time_mean  explanation_consistency_mean  \\\n",
       "pruning           2.912821                      0.625000   \n",
       "weights           3.096242                      0.390000   \n",
       "psi               0.026749                      0.158333   \n",
       "tree              0.000897                      0.368571   \n",
       "BRL               0.026822                      0.828571   \n",
       "\n",
       "         model_accuracy_top_sem  explanation_accuracy_sem  \\\n",
       "pruning                0.009276                  0.014165   \n",
       "weights                0.004398                  0.027152   \n",
       "psi                    0.021982                  0.028681   \n",
       "tree                   0.003808                  0.003808   \n",
       "BRL                    0.250310                  0.013708   \n",
       "\n",
       "         explanation_fidelity_sem  explanation_complexity_sem  \\\n",
       "pruning                  0.014165                    0.746101   \n",
       "weights                  0.027152                    0.553775   \n",
       "psi                      0.028681                    0.494413   \n",
       "tree                     0.003808                    7.878875   \n",
       "BRL                      0.013708                    0.683943   \n",
       "\n",
       "         elapsed_time_sem  explanation_consistency_sem  \n",
       "pruning          0.158873                 0.000000e+00  \n",
       "weights          0.122414                 0.000000e+00  \n",
       "psi              0.003884                 9.251859e-18  \n",
       "tree             0.000179                 1.850372e-17  \n",
       "BRL              0.008717                 0.000000e+00  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['model_accuracy_top', 'explanation_accuracy', 'explanation_fidelity', \n",
    "        'explanation_complexity', 'elapsed_time', 'explanation_consistency']\n",
    "mean_cols = [f'{c}_mean' for c in cols]\n",
    "sem_cols = [f'{c}_sem' for c in cols]\n",
    "\n",
    "# pruning\n",
    "df_mean = results_pruning[cols].mean()\n",
    "df_sem = results_pruning[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_pruning = pd.concat([df_mean, df_sem])\n",
    "summary_pruning.name = 'pruning'\n",
    "\n",
    "# # lime\n",
    "# df_mean = results_lime[cols].mean()\n",
    "# df_sem = results_lime[cols].sem()\n",
    "# df_mean.columns = mean_cols\n",
    "# df_sem.columns = sem_cols\n",
    "# summary_lime = pd.concat([df_mean, df_sem])\n",
    "# summary_lime.name = 'lime'\n",
    "\n",
    "# weights\n",
    "df_mean = results_weights[cols].mean()\n",
    "df_sem = results_weights[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_weights = pd.concat([df_mean, df_sem])\n",
    "summary_weights.name = 'weights'\n",
    "\n",
    "# psi\n",
    "df_mean = results_psi[cols].mean()\n",
    "df_sem = results_psi[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_psi = pd.concat([df_mean, df_sem])\n",
    "summary_psi.name = 'psi'\n",
    "\n",
    "# tree\n",
    "df_mean = results_tree[cols].mean()\n",
    "df_sem = results_tree[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_tree = pd.concat([df_mean, df_sem])\n",
    "summary_tree.name = 'tree'\n",
    "\n",
    "# BRL\n",
    "df_mean = results_brl[cols].mean()\n",
    "df_sem = results_brl[cols].sem()\n",
    "df_mean.columns = mean_cols\n",
    "df_sem.columns = sem_cols\n",
    "summary_brl = pd.concat([df_mean, df_sem])\n",
    "summary_brl.name = 'BRL'\n",
    "\n",
    "summary = pd.concat([summary_pruning,\n",
    "                     summary_weights, \n",
    "                     summary_psi, \n",
    "                     summary_tree,\n",
    "                     summary_brl], axis=1).T\n",
    "summary.columns = mean_cols + sem_cols\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "stylish-gothic",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_csv(os.path.join(results_dir, 'summary.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}