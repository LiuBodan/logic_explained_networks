{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1776, 90])\n",
      "torch.Size([1776])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, KBinsDiscretizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sympy import simplify_logic\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import deep_logic as dl\n",
    "from deep_logic.utils.base import validate_network, set_seed, tree_to_formula\n",
    "from deep_logic.utils.layer import prune_logic_layers\n",
    "from deep_logic import logic\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "#%%\n",
    "\n",
    "data = pd.read_csv('data/mimic-ii/full_cohort_data.csv')\n",
    "# data.drop('hgb_first')\n",
    "fs = [\n",
    "    'aline_flg',\n",
    "    'gender_num',\n",
    "    # 'hosp_exp_flg',\n",
    "    # 'icu_exp_flg',\n",
    "    # 'day_28_flg',\n",
    "    # 'censor_flg',\n",
    "    'sepsis_flg', 'chf_flg', 'afib_flg',\n",
    "    'renal_flg', 'liver_flg', 'copd_flg', 'cad_flg', 'stroke_flg',\n",
    "    'mal_flg', 'resp_flg',\n",
    "]\n",
    "features = fs\n",
    "data1 = data[fs].values\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "data1 = imp_mean.fit_transform(data1)\n",
    "\n",
    "f2 = fs.copy()\n",
    "f2.append('day_icu_intime')\n",
    "f2.append('service_unit')\n",
    "f2.append('day_28_flg')\n",
    "f2.append('hospital_los_day')\n",
    "f2.append('icu_exp_flg')\n",
    "f2.append('hosp_exp_flg')\n",
    "f2.append('censor_flg')\n",
    "f2.append('mort_day_censored')\n",
    "f2 = data.columns.difference(f2)\n",
    "data2 = data[f2].values\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "data2 = imp_mean.fit_transform(data2)\n",
    "scaler = MinMaxScaler((0, 1))\n",
    "data2 = scaler.fit_transform(data2)\n",
    "features = features + list(f2)\n",
    "est = KBinsDiscretizer(n_bins=3, encode='onehot-dense', strategy='uniform')\n",
    "data2d = est.fit_transform(data2)\n",
    "f2d = []\n",
    "for feature in f2:\n",
    "    #f2d.append(feature + '_VLOW')\n",
    "    f2d.append(feature + '_LOW')\n",
    "    f2d.append(feature + '_NORMAL')\n",
    "    f2d.append(feature + '_HIGH')\n",
    "    #f2d.append(feature + '_VHIGH')\n",
    "features = fs + f2d\n",
    "\n",
    "datax = np.hstack((data1, data2d))\n",
    "datay = data['day_28_flg'].values\n",
    "\n",
    "x = torch.FloatTensor(datax)\n",
    "y = torch.FloatTensor(datay)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = 'results_ll/mimic'\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# concepts = [f'c{i:03}' for i in range(x.shape[1])]\n",
    "concepts =  features\n",
    "n_rep = 10\n",
    "tot_epochs = 5001\n",
    "prune_epochs = 2001\n",
    "seed = 42\n",
    "\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(x_train, y_train, seed, device, l1=0.001, lr=0.001, verbose=False):\n",
    "    set_seed(seed)\n",
    "    x_train = x_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    layers = [\n",
    "        dl.nn.XLogic(x_train.size(1), activation='identity', first=True),\n",
    "        torch.nn.Linear(x_train.size(1), 50),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(50, 30),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(30, 1),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        dl.nn.XLogic(1, activation='sigmoid', top=True),\n",
    "    ]\n",
    "    model = torch.nn.Sequential(*layers).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    loss_form = torch.nn.BCELoss()\n",
    "    model.train()\n",
    "    need_pruning = True\n",
    "    for epoch in range(tot_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_train).squeeze()\n",
    "        loss = loss_form(y_pred, y_train)\n",
    "\n",
    "        for module in model.children():\n",
    "            if isinstance(module, dl.nn.XLogic):\n",
    "                loss += l1 * torch.norm(module.weight, 1)\n",
    "                loss += l1 * torch.norm(module.bias, 1)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch > prune_epochs and need_pruning:\n",
    "            dl.utils.layer.prune_logic_layers(model.to(device), fan_in=5, device=device)\n",
    "            need_pruning = False\n",
    "\n",
    "        # compute accuracy\n",
    "        if epoch % 100 == 0 and verbose:\n",
    "            y_pred_d = y_pred > 0.5\n",
    "            accuracy = y_pred_d.eq(y_train).sum().item() / y_train.size(0)\n",
    "            print(f'Epoch {epoch}: train accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_to_y(method, verbose=False):\n",
    "    methods = []\n",
    "    splits = []\n",
    "    explanations = []\n",
    "    model_accuracies = []\n",
    "    explanation_accuracies = []\n",
    "    explanation_fidelities = []\n",
    "    explanation_complexities = []\n",
    "    elapsed_times = []\n",
    "    for split, (trainval_index, test_index) in enumerate(skf.split(x.cpu().detach().numpy(), y.cpu().detach().numpy())):\n",
    "        print(f'Split [{split+1}/{n_splits}]')\n",
    "        x_trainval, x_test = torch.FloatTensor(x[trainval_index]), torch.FloatTensor(x[test_index])\n",
    "        y_trainval, y_test = torch.FloatTensor(y[trainval_index]), torch.FloatTensor(y[test_index])\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x_trainval, y_trainval, test_size=0.3, random_state=42)\n",
    "    \n",
    "        explanation, explanation_inv = '', ''\n",
    "        explanation_accuracy, explanation_accuracy_inv = 0, 0\n",
    "        \n",
    "        if method == 'tree':\n",
    "            classifier = DecisionTreeClassifier(random_state=seed)\n",
    "            classifier.fit(x_train.detach().numpy(), y_train.detach().numpy())\n",
    "            y_preds = classifier.predict(x_test.detach().numpy())\n",
    "            model_accuracy = accuracy_score(y_test.detach().numpy(), y_preds)\n",
    "            explanation_accuracy = model_accuracy\n",
    "\n",
    "            target_class = 1\n",
    "            start = time.time()\n",
    "            explanation = tree_to_formula(classifier, concepts, target_class)\n",
    "            elapsed_time = time.time() - start\n",
    "            explanation_fidelity = 1.\n",
    "            explanation_complexity = dl.logic.complexity(explanation)\n",
    "\n",
    "            target_class_inv = 0\n",
    "            start = time.time()\n",
    "            explanation_inv = tree_to_formula(classifier, concepts, target_class_inv)\n",
    "            elapsed_time = time.time() - start\n",
    "        \n",
    "        else:\n",
    "            model = train_nn(x_trainval, y_trainval, seed, device, verbose=verbose)#=False)\n",
    "            y_preds = model(x_test.to(device)).cpu().detach().numpy() > 0.5\n",
    "            model_accuracy = accuracy_score(y_test.cpu().detach().numpy(), y_preds)\n",
    "\n",
    "            # positive class\n",
    "            start = time.time()\n",
    "            class_explanation, class_explanations = dl.logic.explain_class(model.cpu(), \n",
    "                                                                           x_trainval.cpu(), \n",
    "                                                                           y_trainval.cpu(), \n",
    "                                                                           binary=True, target_class=0,\n",
    "                                                                           topk_explanations=4)\n",
    "            elapsed_time = time.time() - start\n",
    "            \n",
    "            if class_explanation:\n",
    "                explanation = logic.base.replace_names(class_explanation, concepts)\n",
    "                explanation_accuracy, y_formula = logic.base.test_explanation(class_explanation, \n",
    "                                                                              target_class=0, \n",
    "                                                                              x=x_test, y=y_test,\n",
    "                                                                              metric=accuracy_score)\n",
    "                explanation_fidelity = dl.logic.fidelity(y_formula, 1-y_preds)\n",
    "                explanation_complexity = dl.logic.complexity(class_explanation)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'\\t Model\\'s accuracy: {model_accuracy:.4f}')\n",
    "            print(f'\\t Class 1 - Global explanation: \"{explanation}\" - Accuracy: {explanation_accuracy:.4f}')\n",
    "            print(f'\\t Fidelity: \"{explanation_fidelity:.4f}\" - Complexity: \"{explanation_complexity}\"')\n",
    "            print(f'\\t Elapsed time {elapsed_time}')\n",
    "\n",
    "        methods.append(method)\n",
    "        splits.append(seed)\n",
    "        explanations.append(explanation)\n",
    "        model_accuracies.append(model_accuracy)\n",
    "        explanation_accuracies.append(explanation_accuracy)\n",
    "        explanation_fidelities.append(explanation_fidelity)\n",
    "        explanation_complexities.append(explanation_complexity)\n",
    "        elapsed_times.append(elapsed_time)\n",
    "    \n",
    "    explanation_consistency = dl.logic.formula_consistency(explanations)\n",
    "    print(f'Consistency of explanations: {explanation_consistency:.4f}')\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'method': methods,\n",
    "        'split': splits,\n",
    "        'explanation': explanations,\n",
    "        'model_accuracy': model_accuracies,\n",
    "        'explanation_accuracy': explanation_accuracies,\n",
    "        'explanation_fidelity': explanation_fidelities,\n",
    "        'explanation_complexity': explanation_complexities,\n",
    "        'explanation_consistency': explanation_consistency,\n",
    "        'elapsed_time': elapsed_times,\n",
    "    })\n",
    "    results.to_csv(os.path.join(results_dir, f'results_{method}.csv'))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split [1/10]\n",
      "Epoch 0: train accuracy: 0.1589\n",
      "Epoch 100: train accuracy: 0.8411\n",
      "Epoch 200: train accuracy: 0.8411\n",
      "Epoch 300: train accuracy: 0.8411\n",
      "Epoch 400: train accuracy: 0.8467\n",
      "Epoch 500: train accuracy: 0.8561\n",
      "Epoch 600: train accuracy: 0.8586\n",
      "Epoch 700: train accuracy: 0.8648\n",
      "Epoch 800: train accuracy: 0.8730\n",
      "Epoch 900: train accuracy: 0.8748\n",
      "Epoch 1000: train accuracy: 0.8780\n",
      "Epoch 1100: train accuracy: 0.8767\n",
      "Epoch 1200: train accuracy: 0.8748\n",
      "Epoch 1300: train accuracy: 0.8742\n",
      "Epoch 1400: train accuracy: 0.8736\n",
      "Epoch 1500: train accuracy: 0.8748\n",
      "Epoch 1600: train accuracy: 0.8730\n",
      "Epoch 1700: train accuracy: 0.8761\n",
      "Epoch 1800: train accuracy: 0.8736\n",
      "Epoch 1900: train accuracy: 0.8748\n",
      "Epoch 2000: train accuracy: 0.8817\n",
      "Epoch 2100: train accuracy: 0.8911\n",
      "Epoch 2200: train accuracy: 0.8936\n",
      "Epoch 2300: train accuracy: 0.8974\n",
      "Epoch 2400: train accuracy: 0.8974\n",
      "Epoch 2500: train accuracy: 0.8967\n",
      "Epoch 2600: train accuracy: 0.8974\n",
      "Epoch 2700: train accuracy: 0.8974\n",
      "Epoch 2800: train accuracy: 0.8974\n",
      "Epoch 2900: train accuracy: 0.8980\n",
      "Epoch 3000: train accuracy: 0.8992\n",
      "Epoch 3100: train accuracy: 0.8992\n",
      "Epoch 3200: train accuracy: 0.8992\n",
      "Epoch 3300: train accuracy: 0.8999\n",
      "Epoch 3400: train accuracy: 0.8992\n",
      "Epoch 3500: train accuracy: 0.8999\n",
      "Epoch 3600: train accuracy: 0.9018\n",
      "Epoch 3700: train accuracy: 0.9018\n",
      "Epoch 3800: train accuracy: 0.8986\n",
      "Epoch 3900: train accuracy: 0.9005\n",
      "Epoch 4000: train accuracy: 0.8999\n",
      "Epoch 4100: train accuracy: 0.9005\n",
      "Epoch 4200: train accuracy: 0.9018\n",
      "Epoch 4300: train accuracy: 0.9018\n",
      "Epoch 4400: train accuracy: 0.9043\n",
      "Epoch 4500: train accuracy: 0.9049\n",
      "Epoch 4600: train accuracy: 0.9055\n",
      "Epoch 4700: train accuracy: 0.9061\n",
      "Epoch 4800: train accuracy: 0.9061\n",
      "Epoch 4900: train accuracy: 0.9061\n",
      "Epoch 5000: train accuracy: 0.9061\n",
      "\t Model's accuracy: 0.8652\n",
      "\t Class 1 - Global explanation: \"(bun_first_LOW & hr_1st_NORMAL & ~chloride_first_HIGH & ~hr_1st_LOW) | (bun_first_LOW & ~chloride_first_HIGH & ~hr_1st_NORMAL & ~platelet_first_NORMAL)\" - Accuracy: 0.8090\n",
      "\t Fidelity: \"0.8989\" - Complexity: \"8\"\n",
      "\t Elapsed time 2.818157911300659\n",
      "Split [2/10]\n",
      "Epoch 0: train accuracy: 0.1589\n",
      "Epoch 100: train accuracy: 0.8411\n",
      "Epoch 200: train accuracy: 0.8411\n",
      "Epoch 300: train accuracy: 0.8411\n",
      "Epoch 400: train accuracy: 0.8436\n",
      "Epoch 500: train accuracy: 0.8573\n",
      "Epoch 600: train accuracy: 0.8642\n",
      "Epoch 700: train accuracy: 0.8730\n",
      "Epoch 800: train accuracy: 0.8767\n",
      "Epoch 900: train accuracy: 0.8798\n",
      "Epoch 1000: train accuracy: 0.8805\n",
      "Epoch 1100: train accuracy: 0.8874\n",
      "Epoch 1200: train accuracy: 0.8892\n",
      "Epoch 1300: train accuracy: 0.8899\n",
      "Epoch 1400: train accuracy: 0.8886\n",
      "Epoch 1500: train accuracy: 0.8942\n",
      "Epoch 1600: train accuracy: 0.8999\n",
      "Epoch 1700: train accuracy: 0.9036\n",
      "Epoch 1800: train accuracy: 0.9074\n",
      "Epoch 1900: train accuracy: 0.9130\n",
      "Epoch 2000: train accuracy: 0.9155\n",
      "Epoch 2100: train accuracy: 0.9199\n",
      "Epoch 2200: train accuracy: 0.9249\n",
      "Epoch 2300: train accuracy: 0.9312\n",
      "Epoch 2400: train accuracy: 0.9330\n",
      "Epoch 2500: train accuracy: 0.9362\n",
      "Epoch 2600: train accuracy: 0.9368\n",
      "Epoch 2700: train accuracy: 0.9380\n",
      "Epoch 2800: train accuracy: 0.9362\n",
      "Epoch 2900: train accuracy: 0.9374\n",
      "Epoch 3000: train accuracy: 0.9412\n",
      "Epoch 3100: train accuracy: 0.9387\n",
      "Epoch 3200: train accuracy: 0.9418\n",
      "Epoch 3300: train accuracy: 0.9443\n",
      "Epoch 3400: train accuracy: 0.9443\n",
      "Epoch 3500: train accuracy: 0.9437\n",
      "Epoch 3600: train accuracy: 0.9449\n",
      "Epoch 3700: train accuracy: 0.9462\n",
      "Epoch 3800: train accuracy: 0.9443\n",
      "Epoch 3900: train accuracy: 0.9462\n",
      "Epoch 4000: train accuracy: 0.9481\n",
      "Epoch 4100: train accuracy: 0.9481\n",
      "Epoch 4200: train accuracy: 0.9481\n",
      "Epoch 4300: train accuracy: 0.9487\n",
      "Epoch 4400: train accuracy: 0.9487\n",
      "Epoch 4500: train accuracy: 0.9499\n",
      "Epoch 4600: train accuracy: 0.9493\n",
      "Epoch 4700: train accuracy: 0.9506\n",
      "Epoch 4800: train accuracy: 0.9506\n",
      "Epoch 4900: train accuracy: 0.9481\n",
      "Epoch 5000: train accuracy: 0.9531\n",
      "\t Model's accuracy: 0.8315\n",
      "\t Class 1 - Global explanation: \"(bun_first_LOW & hr_1st_NORMAL & ~chloride_first_HIGH & ~hr_1st_LOW) | (bun_first_LOW & ~chloride_first_HIGH & ~hr_1st_NORMAL & ~platelet_first_NORMAL)\" - Accuracy: 0.8202\n",
      "\t Fidelity: \"0.8315\" - Complexity: \"8\"\n",
      "\t Elapsed time 2.7182207107543945\n",
      "Split [3/10]\n",
      "Epoch 0: train accuracy: 0.1589\n",
      "Epoch 100: train accuracy: 0.8411\n",
      "Epoch 200: train accuracy: 0.8411\n",
      "Epoch 300: train accuracy: 0.8411\n",
      "Epoch 400: train accuracy: 0.8454\n",
      "Epoch 500: train accuracy: 0.8567\n",
      "Epoch 600: train accuracy: 0.8648\n",
      "Epoch 700: train accuracy: 0.8686\n",
      "Epoch 800: train accuracy: 0.8705\n",
      "Epoch 900: train accuracy: 0.8742\n",
      "Epoch 1000: train accuracy: 0.8742\n",
      "Epoch 1100: train accuracy: 0.8786\n",
      "Epoch 1200: train accuracy: 0.8792\n",
      "Epoch 1300: train accuracy: 0.8824\n",
      "Epoch 1400: train accuracy: 0.8842\n",
      "Epoch 1500: train accuracy: 0.8842\n",
      "Epoch 1600: train accuracy: 0.8867\n",
      "Epoch 1700: train accuracy: 0.8892\n",
      "Epoch 1800: train accuracy: 0.8911\n",
      "Epoch 1900: train accuracy: 0.8905\n",
      "Epoch 2000: train accuracy: 0.8917\n",
      "Epoch 2100: train accuracy: 0.8936\n",
      "Epoch 2200: train accuracy: 0.8949\n",
      "Epoch 2300: train accuracy: 0.8961\n",
      "Epoch 2400: train accuracy: 0.8980\n",
      "Epoch 2500: train accuracy: 0.8980\n",
      "Epoch 2600: train accuracy: 0.8999\n",
      "Epoch 2700: train accuracy: 0.8999\n",
      "Epoch 2800: train accuracy: 0.8999\n",
      "Epoch 2900: train accuracy: 0.8961\n",
      "Epoch 3000: train accuracy: 0.8974\n",
      "Epoch 3100: train accuracy: 0.8999\n",
      "Epoch 3200: train accuracy: 0.9030\n",
      "Epoch 3300: train accuracy: 0.9143\n",
      "Epoch 3400: train accuracy: 0.9143\n",
      "Epoch 3500: train accuracy: 0.9168\n",
      "Epoch 3600: train accuracy: 0.9186\n",
      "Epoch 3700: train accuracy: 0.9205\n",
      "Epoch 3800: train accuracy: 0.9199\n",
      "Epoch 3900: train accuracy: 0.9218\n",
      "Epoch 4000: train accuracy: 0.9230\n",
      "Epoch 4100: train accuracy: 0.9230\n",
      "Epoch 4200: train accuracy: 0.9249\n",
      "Epoch 4300: train accuracy: 0.9255\n",
      "Epoch 4400: train accuracy: 0.9268\n",
      "Epoch 4500: train accuracy: 0.9268\n",
      "Epoch 4600: train accuracy: 0.9268\n",
      "Epoch 4700: train accuracy: 0.9287\n",
      "Epoch 4800: train accuracy: 0.9293\n",
      "Epoch 4900: train accuracy: 0.9299\n",
      "Epoch 5000: train accuracy: 0.9299\n",
      "\t Model's accuracy: 0.8427\n",
      "\t Class 1 - Global explanation: \"(bun_first_LOW & hr_1st_NORMAL & ~chloride_first_HIGH & ~hr_1st_LOW) | (bun_first_LOW & ~chloride_first_HIGH & ~hr_1st_NORMAL & ~platelet_first_NORMAL)\" - Accuracy: 0.7528\n",
      "\t Fidelity: \"0.8427\" - Complexity: \"8\"\n",
      "\t Elapsed time 2.979811429977417\n",
      "Split [4/10]\n",
      "Epoch 0: train accuracy: 0.1596\n",
      "Epoch 100: train accuracy: 0.8404\n",
      "Epoch 200: train accuracy: 0.8404\n",
      "Epoch 300: train accuracy: 0.8404\n",
      "Epoch 400: train accuracy: 0.8454\n",
      "Epoch 500: train accuracy: 0.8536\n",
      "Epoch 600: train accuracy: 0.8655\n",
      "Epoch 700: train accuracy: 0.8717\n",
      "Epoch 800: train accuracy: 0.8773\n",
      "Epoch 900: train accuracy: 0.8798\n",
      "Epoch 1000: train accuracy: 0.8805\n",
      "Epoch 1100: train accuracy: 0.8805\n",
      "Epoch 1200: train accuracy: 0.8805\n",
      "Epoch 1300: train accuracy: 0.8830\n",
      "Epoch 1400: train accuracy: 0.8849\n",
      "Epoch 1500: train accuracy: 0.8855\n",
      "Epoch 1600: train accuracy: 0.8874\n",
      "Epoch 1700: train accuracy: 0.8867\n",
      "Epoch 1800: train accuracy: 0.8855\n",
      "Epoch 1900: train accuracy: 0.8880\n",
      "Epoch 2000: train accuracy: 0.8886\n",
      "Epoch 2100: train accuracy: 0.8905\n",
      "Epoch 2200: train accuracy: 0.8905\n",
      "Epoch 2300: train accuracy: 0.8917\n",
      "Epoch 2400: train accuracy: 0.8917\n",
      "Epoch 2500: train accuracy: 0.8917\n",
      "Epoch 2600: train accuracy: 0.8936\n",
      "Epoch 2700: train accuracy: 0.8974\n",
      "Epoch 2800: train accuracy: 0.8967\n",
      "Epoch 2900: train accuracy: 0.8961\n",
      "Epoch 3000: train accuracy: 0.8967\n",
      "Epoch 3100: train accuracy: 0.8974\n",
      "Epoch 3200: train accuracy: 0.8942\n",
      "Epoch 3300: train accuracy: 0.8961\n",
      "Epoch 3400: train accuracy: 0.8949\n",
      "Epoch 3500: train accuracy: 0.8980\n",
      "Epoch 3600: train accuracy: 0.9005\n",
      "Epoch 3700: train accuracy: 0.9086\n",
      "Epoch 3800: train accuracy: 0.9105\n",
      "Epoch 3900: train accuracy: 0.9111\n",
      "Epoch 4000: train accuracy: 0.9149\n",
      "Epoch 4100: train accuracy: 0.9168\n",
      "Epoch 4200: train accuracy: 0.9193\n",
      "Epoch 4300: train accuracy: 0.9149\n",
      "Epoch 4400: train accuracy: 0.9193\n",
      "Epoch 4500: train accuracy: 0.9230\n",
      "Epoch 4600: train accuracy: 0.9193\n",
      "Epoch 4700: train accuracy: 0.9218\n",
      "Epoch 4800: train accuracy: 0.9218\n",
      "Epoch 4900: train accuracy: 0.9237\n",
      "Epoch 5000: train accuracy: 0.9199\n",
      "\t Model's accuracy: 0.8652\n",
      "\t Class 1 - Global explanation: \"(bun_first_LOW & hr_1st_NORMAL & ~chloride_first_HIGH & ~hr_1st_LOW) | (bun_first_LOW & ~chloride_first_HIGH & ~hr_1st_NORMAL & ~platelet_first_NORMAL)\" - Accuracy: 0.8090\n",
      "\t Fidelity: \"0.8315\" - Complexity: \"8\"\n",
      "\t Elapsed time 2.7425363063812256\n",
      "Split [5/10]\n",
      "Epoch 0: train accuracy: 0.1596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: train accuracy: 0.8404\n",
      "Epoch 200: train accuracy: 0.8404\n",
      "Epoch 300: train accuracy: 0.8404\n",
      "Epoch 400: train accuracy: 0.8461\n",
      "Epoch 500: train accuracy: 0.8611\n",
      "Epoch 600: train accuracy: 0.8686\n",
      "Epoch 700: train accuracy: 0.8748\n",
      "Epoch 800: train accuracy: 0.8817\n",
      "Epoch 900: train accuracy: 0.8798\n",
      "Epoch 1000: train accuracy: 0.8811\n",
      "Epoch 1100: train accuracy: 0.8842\n",
      "Epoch 1200: train accuracy: 0.8849\n",
      "Epoch 1300: train accuracy: 0.8842\n",
      "Epoch 1400: train accuracy: 0.8849\n",
      "Epoch 1500: train accuracy: 0.8867\n",
      "Epoch 1600: train accuracy: 0.8867\n",
      "Epoch 1700: train accuracy: 0.8867\n",
      "Epoch 1800: train accuracy: 0.8905\n",
      "Epoch 1900: train accuracy: 0.8911\n",
      "Epoch 2000: train accuracy: 0.8930\n",
      "Epoch 2100: train accuracy: 0.8949\n",
      "Epoch 2200: train accuracy: 0.8961\n",
      "Epoch 2300: train accuracy: 0.8986\n",
      "Epoch 2400: train accuracy: 0.9043\n",
      "Epoch 2500: train accuracy: 0.9086\n",
      "Epoch 2600: train accuracy: 0.9155\n",
      "Epoch 2700: train accuracy: 0.9199\n",
      "Epoch 2800: train accuracy: 0.9205\n",
      "Epoch 2900: train accuracy: 0.9224\n",
      "Epoch 3000: train accuracy: 0.9262\n",
      "Epoch 3100: train accuracy: 0.9262\n",
      "Epoch 3200: train accuracy: 0.9268\n",
      "Epoch 3300: train accuracy: 0.9268\n",
      "Epoch 3400: train accuracy: 0.9287\n",
      "Epoch 3500: train accuracy: 0.9312\n",
      "Epoch 3600: train accuracy: 0.9337\n",
      "Epoch 3700: train accuracy: 0.9324\n",
      "Epoch 3800: train accuracy: 0.9374\n",
      "Epoch 3900: train accuracy: 0.9380\n",
      "Epoch 4000: train accuracy: 0.9406\n",
      "Epoch 4100: train accuracy: 0.9393\n",
      "Epoch 4200: train accuracy: 0.9431\n",
      "Epoch 4300: train accuracy: 0.9431\n",
      "Epoch 4400: train accuracy: 0.9437\n",
      "Epoch 4500: train accuracy: 0.9443\n",
      "Epoch 4600: train accuracy: 0.9456\n",
      "Epoch 4700: train accuracy: 0.9474\n",
      "Epoch 4800: train accuracy: 0.9481\n",
      "Epoch 4900: train accuracy: 0.9499\n",
      "Epoch 5000: train accuracy: 0.9493\n",
      "\t Model's accuracy: 0.8258\n",
      "\t Class 1 - Global explanation: \"(bun_first_LOW & hr_1st_NORMAL & ~chloride_first_HIGH & ~hr_1st_LOW) | (bun_first_LOW & ~chloride_first_HIGH & ~hr_1st_NORMAL & ~platelet_first_NORMAL)\" - Accuracy: 0.8090\n",
      "\t Fidelity: \"0.8146\" - Complexity: \"8\"\n",
      "\t Elapsed time 2.9268453121185303\n",
      "Split [6/10]\n",
      "Epoch 0: train accuracy: 0.1596\n",
      "Epoch 100: train accuracy: 0.8404\n",
      "Epoch 200: train accuracy: 0.8404\n",
      "Epoch 300: train accuracy: 0.8404\n",
      "Epoch 400: train accuracy: 0.8442\n",
      "Epoch 500: train accuracy: 0.8586\n",
      "Epoch 600: train accuracy: 0.8673\n",
      "Epoch 700: train accuracy: 0.8748\n",
      "Epoch 800: train accuracy: 0.8767\n",
      "Epoch 900: train accuracy: 0.8767\n",
      "Epoch 1000: train accuracy: 0.8786\n",
      "Epoch 1100: train accuracy: 0.8773\n",
      "Epoch 1200: train accuracy: 0.8786\n",
      "Epoch 1300: train accuracy: 0.8798\n",
      "Epoch 1400: train accuracy: 0.8805\n",
      "Epoch 1500: train accuracy: 0.8830\n",
      "Epoch 1600: train accuracy: 0.8849\n",
      "Epoch 1700: train accuracy: 0.8899\n",
      "Epoch 1800: train accuracy: 0.8905\n",
      "Epoch 1900: train accuracy: 0.8917\n",
      "Epoch 2000: train accuracy: 0.8936\n",
      "Epoch 2100: train accuracy: 0.8955\n",
      "Epoch 2200: train accuracy: 0.8967\n",
      "Epoch 2300: train accuracy: 0.8992\n",
      "Epoch 2400: train accuracy: 0.8980\n",
      "Epoch 2500: train accuracy: 0.9011\n",
      "Epoch 2600: train accuracy: 0.9068\n",
      "Epoch 2700: train accuracy: 0.9074\n",
      "Epoch 2800: train accuracy: 0.9099\n",
      "Epoch 2900: train accuracy: 0.9118\n",
      "Epoch 3000: train accuracy: 0.9149\n",
      "Epoch 3100: train accuracy: 0.9149\n",
      "Epoch 3200: train accuracy: 0.9161\n",
      "Epoch 3300: train accuracy: 0.9186\n",
      "Epoch 3400: train accuracy: 0.9193\n",
      "Epoch 3500: train accuracy: 0.9205\n",
      "Epoch 3600: train accuracy: 0.9205\n",
      "Epoch 3700: train accuracy: 0.9218\n",
      "Epoch 3800: train accuracy: 0.9237\n",
      "Epoch 3900: train accuracy: 0.9237\n",
      "Epoch 4000: train accuracy: 0.9255\n",
      "Epoch 4100: train accuracy: 0.9249\n",
      "Epoch 4200: train accuracy: 0.9262\n",
      "Epoch 4300: train accuracy: 0.9243\n",
      "Epoch 4400: train accuracy: 0.9268\n",
      "Epoch 4500: train accuracy: 0.9255\n",
      "Epoch 4600: train accuracy: 0.9262\n",
      "Epoch 4700: train accuracy: 0.9136\n",
      "Epoch 4800: train accuracy: 0.9274\n",
      "Epoch 4900: train accuracy: 0.9293\n",
      "Epoch 5000: train accuracy: 0.9299\n",
      "\t Model's accuracy: 0.8596\n",
      "\t Class 1 - Global explanation: \"(bun_first_LOW & hr_1st_NORMAL & ~chloride_first_HIGH & ~hr_1st_LOW) | (bun_first_LOW & ~chloride_first_HIGH & ~hr_1st_NORMAL & ~platelet_first_NORMAL)\" - Accuracy: 0.7753\n",
      "\t Fidelity: \"0.7697\" - Complexity: \"8\"\n",
      "\t Elapsed time 2.972019910812378\n",
      "Split [7/10]\n",
      "Epoch 0: train accuracy: 0.1595\n",
      "Epoch 100: train accuracy: 0.8405\n",
      "Epoch 200: train accuracy: 0.8405\n",
      "Epoch 300: train accuracy: 0.8405\n",
      "Epoch 400: train accuracy: 0.8449\n",
      "Epoch 500: train accuracy: 0.8612\n",
      "Epoch 600: train accuracy: 0.8668\n",
      "Epoch 700: train accuracy: 0.8680\n",
      "Epoch 800: train accuracy: 0.8680\n",
      "Epoch 900: train accuracy: 0.8674\n",
      "Epoch 1000: train accuracy: 0.8655\n",
      "Epoch 1100: train accuracy: 0.8662\n",
      "Epoch 1200: train accuracy: 0.8674\n",
      "Epoch 1300: train accuracy: 0.8680\n",
      "Epoch 1400: train accuracy: 0.8718\n",
      "Epoch 1500: train accuracy: 0.8724\n",
      "Epoch 1600: train accuracy: 0.8762\n",
      "Epoch 1700: train accuracy: 0.8793\n",
      "Epoch 1800: train accuracy: 0.8799\n",
      "Epoch 1900: train accuracy: 0.8812\n",
      "Epoch 2000: train accuracy: 0.8824\n",
      "Epoch 2100: train accuracy: 0.8862\n",
      "Epoch 2200: train accuracy: 0.8874\n",
      "Epoch 2300: train accuracy: 0.8881\n",
      "Epoch 2400: train accuracy: 0.8937\n",
      "Epoch 2500: train accuracy: 0.8943\n",
      "Epoch 2600: train accuracy: 0.8968\n",
      "Epoch 2700: train accuracy: 0.9024\n",
      "Epoch 2800: train accuracy: 0.9043\n",
      "Epoch 2900: train accuracy: 0.9081\n",
      "Epoch 3000: train accuracy: 0.9124\n",
      "Epoch 3100: train accuracy: 0.9174\n",
      "Epoch 3200: train accuracy: 0.9206\n",
      "Epoch 3300: train accuracy: 0.9212\n",
      "Epoch 3400: train accuracy: 0.9243\n",
      "Epoch 3500: train accuracy: 0.9250\n",
      "Epoch 3600: train accuracy: 0.9262\n",
      "Epoch 3700: train accuracy: 0.9250\n",
      "Epoch 3800: train accuracy: 0.9262\n",
      "Epoch 3900: train accuracy: 0.9243\n",
      "Epoch 4000: train accuracy: 0.9243\n",
      "Epoch 4100: train accuracy: 0.9243\n",
      "Epoch 4200: train accuracy: 0.9243\n",
      "Epoch 4300: train accuracy: 0.9212\n",
      "Epoch 4400: train accuracy: 0.9187\n",
      "Epoch 4500: train accuracy: 0.9162\n",
      "Epoch 4600: train accuracy: 0.9318\n",
      "Epoch 4700: train accuracy: 0.9312\n",
      "Epoch 4800: train accuracy: 0.9350\n",
      "Epoch 4900: train accuracy: 0.9331\n",
      "Epoch 5000: train accuracy: 0.9375\n",
      "\t Model's accuracy: 0.8192\n",
      "\t Class 1 - Global explanation: \"(bun_first_LOW & hr_1st_NORMAL & ~chloride_first_HIGH & ~hr_1st_LOW) | (bun_first_LOW & ~chloride_first_HIGH & ~hr_1st_NORMAL & ~platelet_first_NORMAL)\" - Accuracy: 0.7853\n",
      "\t Fidelity: \"0.7966\" - Complexity: \"8\"\n",
      "\t Elapsed time 2.58506178855896\n",
      "Split [8/10]\n",
      "Epoch 0: train accuracy: 0.1595\n",
      "Epoch 100: train accuracy: 0.8405\n",
      "Epoch 200: train accuracy: 0.8405\n",
      "Epoch 300: train accuracy: 0.8405\n",
      "Epoch 400: train accuracy: 0.8443\n",
      "Epoch 500: train accuracy: 0.8562\n",
      "Epoch 600: train accuracy: 0.8624\n",
      "Epoch 700: train accuracy: 0.8662\n",
      "Epoch 800: train accuracy: 0.8687\n",
      "Epoch 900: train accuracy: 0.8712\n",
      "Epoch 1000: train accuracy: 0.8712\n",
      "Epoch 1100: train accuracy: 0.8737\n",
      "Epoch 1200: train accuracy: 0.8762\n",
      "Epoch 1300: train accuracy: 0.8768\n",
      "Epoch 1400: train accuracy: 0.8774\n",
      "Epoch 1500: train accuracy: 0.8793\n",
      "Epoch 1600: train accuracy: 0.8806\n",
      "Epoch 1700: train accuracy: 0.8824\n",
      "Epoch 1800: train accuracy: 0.8849\n",
      "Epoch 1900: train accuracy: 0.8856\n",
      "Epoch 2000: train accuracy: 0.8881\n",
      "Epoch 2100: train accuracy: 0.8887\n",
      "Epoch 2200: train accuracy: 0.8893\n",
      "Epoch 2300: train accuracy: 0.8949\n",
      "Epoch 2400: train accuracy: 0.8987\n",
      "Epoch 2500: train accuracy: 0.9031\n",
      "Epoch 2600: train accuracy: 0.9056\n",
      "Epoch 2700: train accuracy: 0.9074\n",
      "Epoch 2800: train accuracy: 0.9081\n",
      "Epoch 2900: train accuracy: 0.9106\n",
      "Epoch 3000: train accuracy: 0.9131\n",
      "Epoch 3100: train accuracy: 0.9187\n",
      "Epoch 3200: train accuracy: 0.9206\n",
      "Epoch 3300: train accuracy: 0.9193\n",
      "Epoch 3400: train accuracy: 0.9231\n",
      "Epoch 3500: train accuracy: 0.9243\n",
      "Epoch 3600: train accuracy: 0.9250\n",
      "Epoch 3700: train accuracy: 0.9262\n",
      "Epoch 3800: train accuracy: 0.9275\n",
      "Epoch 3900: train accuracy: 0.9287\n",
      "Epoch 4000: train accuracy: 0.9306\n",
      "Epoch 4100: train accuracy: 0.9337\n",
      "Epoch 4200: train accuracy: 0.9362\n",
      "Epoch 4300: train accuracy: 0.9350\n",
      "Epoch 4400: train accuracy: 0.9362\n",
      "Epoch 4500: train accuracy: 0.9356\n",
      "Epoch 4600: train accuracy: 0.9368\n",
      "Epoch 4700: train accuracy: 0.9375\n",
      "Epoch 4800: train accuracy: 0.9393\n",
      "Epoch 4900: train accuracy: 0.9400\n",
      "Epoch 5000: train accuracy: 0.9406\n",
      "\t Model's accuracy: 0.8475\n",
      "\t Class 1 - Global explanation: \"(bun_first_LOW & hr_1st_NORMAL & ~chloride_first_HIGH & ~hr_1st_LOW) | (bun_first_LOW & ~chloride_first_HIGH & ~hr_1st_NORMAL & ~platelet_first_NORMAL)\" - Accuracy: 0.8136\n",
      "\t Fidelity: \"0.7740\" - Complexity: \"8\"\n",
      "\t Elapsed time 3.0868289470672607\n",
      "Split [9/10]\n",
      "Epoch 0: train accuracy: 0.1595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: train accuracy: 0.8405\n",
      "Epoch 200: train accuracy: 0.8405\n",
      "Epoch 300: train accuracy: 0.8405\n",
      "Epoch 400: train accuracy: 0.8443\n",
      "Epoch 500: train accuracy: 0.8562\n",
      "Epoch 600: train accuracy: 0.8618\n",
      "Epoch 700: train accuracy: 0.8730\n",
      "Epoch 800: train accuracy: 0.8762\n",
      "Epoch 900: train accuracy: 0.8774\n",
      "Epoch 1000: train accuracy: 0.8787\n",
      "Epoch 1100: train accuracy: 0.8831\n",
      "Epoch 1200: train accuracy: 0.8856\n",
      "Epoch 1300: train accuracy: 0.8868\n",
      "Epoch 1400: train accuracy: 0.8893\n",
      "Epoch 1500: train accuracy: 0.8887\n",
      "Epoch 1600: train accuracy: 0.8924\n",
      "Epoch 1700: train accuracy: 0.8906\n",
      "Epoch 1800: train accuracy: 0.8924\n",
      "Epoch 1900: train accuracy: 0.8943\n",
      "Epoch 2000: train accuracy: 0.8949\n",
      "Epoch 2100: train accuracy: 0.8962\n",
      "Epoch 2200: train accuracy: 0.8974\n",
      "Epoch 2300: train accuracy: 0.8993\n",
      "Epoch 2400: train accuracy: 0.9006\n",
      "Epoch 2500: train accuracy: 0.8999\n",
      "Epoch 2600: train accuracy: 0.9012\n",
      "Epoch 2700: train accuracy: 0.9018\n",
      "Epoch 2800: train accuracy: 0.9043\n",
      "Epoch 2900: train accuracy: 0.9024\n",
      "Epoch 3000: train accuracy: 0.9037\n",
      "Epoch 3100: train accuracy: 0.9062\n",
      "Epoch 3200: train accuracy: 0.9081\n",
      "Epoch 3300: train accuracy: 0.9074\n",
      "Epoch 3400: train accuracy: 0.9074\n",
      "Epoch 3500: train accuracy: 0.9087\n",
      "Epoch 3600: train accuracy: 0.9081\n",
      "Epoch 3700: train accuracy: 0.9112\n",
      "Epoch 3800: train accuracy: 0.9081\n",
      "Epoch 3900: train accuracy: 0.9124\n",
      "Epoch 4000: train accuracy: 0.9068\n",
      "Epoch 4100: train accuracy: 0.9062\n",
      "Epoch 4200: train accuracy: 0.9049\n",
      "Epoch 4300: train accuracy: 0.9018\n",
      "Epoch 4400: train accuracy: 0.8943\n",
      "Epoch 4500: train accuracy: 0.8949\n",
      "Epoch 4600: train accuracy: 0.8918\n",
      "Epoch 4700: train accuracy: 0.8956\n",
      "Epoch 4800: train accuracy: 0.8981\n",
      "Epoch 4900: train accuracy: 0.8987\n",
      "Epoch 5000: train accuracy: 0.8981\n",
      "\t Model's accuracy: 0.8362\n",
      "\t Class 1 - Global explanation: \"(bun_first_LOW & hr_1st_NORMAL & ~chloride_first_HIGH & ~hr_1st_LOW) | (bun_first_LOW & ~chloride_first_HIGH & ~hr_1st_NORMAL & ~platelet_first_NORMAL)\" - Accuracy: 0.7740\n",
      "\t Fidelity: \"0.8701\" - Complexity: \"8\"\n",
      "\t Elapsed time 2.752565383911133\n",
      "Split [10/10]\n",
      "Epoch 0: train accuracy: 0.1595\n",
      "Epoch 100: train accuracy: 0.8405\n",
      "Epoch 200: train accuracy: 0.8405\n",
      "Epoch 300: train accuracy: 0.8405\n",
      "Epoch 400: train accuracy: 0.8430\n",
      "Epoch 500: train accuracy: 0.8587\n",
      "Epoch 600: train accuracy: 0.8655\n",
      "Epoch 700: train accuracy: 0.8755\n",
      "Epoch 800: train accuracy: 0.8799\n",
      "Epoch 900: train accuracy: 0.8799\n",
      "Epoch 1000: train accuracy: 0.8837\n",
      "Epoch 1100: train accuracy: 0.8849\n",
      "Epoch 1200: train accuracy: 0.8887\n",
      "Epoch 1300: train accuracy: 0.8887\n",
      "Epoch 1400: train accuracy: 0.8881\n",
      "Epoch 1500: train accuracy: 0.8899\n",
      "Epoch 1600: train accuracy: 0.8899\n",
      "Epoch 1700: train accuracy: 0.8918\n",
      "Epoch 1800: train accuracy: 0.8974\n",
      "Epoch 1900: train accuracy: 0.8981\n",
      "Epoch 2000: train accuracy: 0.9006\n",
      "Epoch 2100: train accuracy: 0.9043\n",
      "Epoch 2200: train accuracy: 0.9049\n",
      "Epoch 2300: train accuracy: 0.9087\n",
      "Epoch 2400: train accuracy: 0.9137\n",
      "Epoch 2500: train accuracy: 0.9156\n",
      "Epoch 2600: train accuracy: 0.9143\n",
      "Epoch 2700: train accuracy: 0.9187\n",
      "Epoch 2800: train accuracy: 0.9199\n",
      "Epoch 2900: train accuracy: 0.9231\n",
      "Epoch 3000: train accuracy: 0.9250\n",
      "Epoch 3100: train accuracy: 0.9262\n",
      "Epoch 3200: train accuracy: 0.9268\n",
      "Epoch 3300: train accuracy: 0.9287\n",
      "Epoch 3400: train accuracy: 0.9281\n",
      "Epoch 3500: train accuracy: 0.9287\n",
      "Epoch 3600: train accuracy: 0.9312\n",
      "Epoch 3700: train accuracy: 0.9331\n",
      "Epoch 3800: train accuracy: 0.9337\n",
      "Epoch 3900: train accuracy: 0.9356\n",
      "Epoch 4000: train accuracy: 0.9362\n",
      "Epoch 4100: train accuracy: 0.9375\n",
      "Epoch 4200: train accuracy: 0.9387\n",
      "Epoch 4300: train accuracy: 0.9393\n",
      "Epoch 4400: train accuracy: 0.9406\n",
      "Epoch 4500: train accuracy: 0.9425\n",
      "Epoch 4600: train accuracy: 0.9437\n",
      "Epoch 4700: train accuracy: 0.9450\n",
      "Epoch 4800: train accuracy: 0.9462\n",
      "Epoch 4900: train accuracy: 0.9481\n",
      "Epoch 5000: train accuracy: 0.9481\n",
      "\t Model's accuracy: 0.8079\n",
      "\t Class 1 - Global explanation: \"(bun_first_LOW & hr_1st_NORMAL & ~chloride_first_HIGH & ~hr_1st_LOW) | (bun_first_LOW & ~chloride_first_HIGH & ~hr_1st_NORMAL & ~platelet_first_NORMAL)\" - Accuracy: 0.8023\n",
      "\t Fidelity: \"0.8249\" - Complexity: \"8\"\n",
      "\t Elapsed time 2.7306406497955322\n",
      "Consistency of explanations: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_fidelity</th>\n",
       "      <th>explanation_complexity</th>\n",
       "      <th>explanation_consistency</th>\n",
       "      <th>elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logic_layer</td>\n",
       "      <td>42</td>\n",
       "      <td>(bun_first_LOW &amp; hr_1st_NORMAL &amp; ~chloride_fir...</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.898876</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.818158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logic_layer</td>\n",
       "      <td>42</td>\n",
       "      <td>(bun_first_LOW &amp; hr_1st_NORMAL &amp; ~chloride_fir...</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.718221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logic_layer</td>\n",
       "      <td>42</td>\n",
       "      <td>(bun_first_LOW &amp; hr_1st_NORMAL &amp; ~chloride_fir...</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.979811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logic_layer</td>\n",
       "      <td>42</td>\n",
       "      <td>(bun_first_LOW &amp; hr_1st_NORMAL &amp; ~chloride_fir...</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.742536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>logic_layer</td>\n",
       "      <td>42</td>\n",
       "      <td>(bun_first_LOW &amp; hr_1st_NORMAL &amp; ~chloride_fir...</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.926845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>logic_layer</td>\n",
       "      <td>42</td>\n",
       "      <td>(bun_first_LOW &amp; hr_1st_NORMAL &amp; ~chloride_fir...</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.972020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>logic_layer</td>\n",
       "      <td>42</td>\n",
       "      <td>(bun_first_LOW &amp; hr_1st_NORMAL &amp; ~chloride_fir...</td>\n",
       "      <td>0.819209</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.585062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>logic_layer</td>\n",
       "      <td>42</td>\n",
       "      <td>(bun_first_LOW &amp; hr_1st_NORMAL &amp; ~chloride_fir...</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.774011</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.086829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>logic_layer</td>\n",
       "      <td>42</td>\n",
       "      <td>(bun_first_LOW &amp; hr_1st_NORMAL &amp; ~chloride_fir...</td>\n",
       "      <td>0.836158</td>\n",
       "      <td>0.774011</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.752565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>logic_layer</td>\n",
       "      <td>42</td>\n",
       "      <td>(bun_first_LOW &amp; hr_1st_NORMAL &amp; ~chloride_fir...</td>\n",
       "      <td>0.807910</td>\n",
       "      <td>0.802260</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.730641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        method  split                                        explanation  \\\n",
       "0  logic_layer     42  (bun_first_LOW & hr_1st_NORMAL & ~chloride_fir...   \n",
       "1  logic_layer     42  (bun_first_LOW & hr_1st_NORMAL & ~chloride_fir...   \n",
       "2  logic_layer     42  (bun_first_LOW & hr_1st_NORMAL & ~chloride_fir...   \n",
       "3  logic_layer     42  (bun_first_LOW & hr_1st_NORMAL & ~chloride_fir...   \n",
       "4  logic_layer     42  (bun_first_LOW & hr_1st_NORMAL & ~chloride_fir...   \n",
       "5  logic_layer     42  (bun_first_LOW & hr_1st_NORMAL & ~chloride_fir...   \n",
       "6  logic_layer     42  (bun_first_LOW & hr_1st_NORMAL & ~chloride_fir...   \n",
       "7  logic_layer     42  (bun_first_LOW & hr_1st_NORMAL & ~chloride_fir...   \n",
       "8  logic_layer     42  (bun_first_LOW & hr_1st_NORMAL & ~chloride_fir...   \n",
       "9  logic_layer     42  (bun_first_LOW & hr_1st_NORMAL & ~chloride_fir...   \n",
       "\n",
       "   model_accuracy  explanation_accuracy  explanation_fidelity  \\\n",
       "0        0.865169              0.808989              0.898876   \n",
       "1        0.831461              0.820225              0.831461   \n",
       "2        0.842697              0.752809              0.842697   \n",
       "3        0.865169              0.808989              0.831461   \n",
       "4        0.825843              0.808989              0.814607   \n",
       "5        0.859551              0.775281              0.769663   \n",
       "6        0.819209              0.785311              0.796610   \n",
       "7        0.847458              0.813559              0.774011   \n",
       "8        0.836158              0.774011              0.870056   \n",
       "9        0.807910              0.802260              0.824859   \n",
       "\n",
       "   explanation_complexity  explanation_consistency  elapsed_time  \n",
       "0                       8                      1.0      2.818158  \n",
       "1                       8                      1.0      2.718221  \n",
       "2                       8                      1.0      2.979811  \n",
       "3                       8                      1.0      2.742536  \n",
       "4                       8                      1.0      2.926845  \n",
       "5                       8                      1.0      2.972020  \n",
       "6                       8                      1.0      2.585062  \n",
       "7                       8                      1.0      3.086829  \n",
       "8                       8                      1.0      2.752565  \n",
       "9                       8                      1.0      2.730641  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_pruning = c_to_y(method='logic_layer', verbose=True)\n",
    "results_pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split [1/10]\n",
      "Split [2/10]\n",
      "Split [3/10]\n",
      "Split [4/10]\n",
      "Split [5/10]\n",
      "Split [6/10]\n",
      "Split [7/10]\n",
      "Split [8/10]\n",
      "Split [9/10]\n",
      "Split [10/10]\n",
      "Consistency of explanations: 0.7510\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>split</th>\n",
       "      <th>explanation</th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>explanation_accuracy</th>\n",
       "      <th>explanation_fidelity</th>\n",
       "      <th>explanation_complexity</th>\n",
       "      <th>explanation_consistency</th>\n",
       "      <th>elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tree</td>\n",
       "      <td>42</td>\n",
       "      <td>(age_HIGH &lt;= 0.50 &amp; resp_flg &lt;= 0.50 &amp; stroke_...</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>1.0</td>\n",
       "      <td>838</td>\n",
       "      <td>0.750955</td>\n",
       "      <td>0.002992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tree</td>\n",
       "      <td>42</td>\n",
       "      <td>(stroke_flg &lt;= 0.50 &amp; age_HIGH &lt;= 0.50 &amp; copd_...</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>1.0</td>\n",
       "      <td>994</td>\n",
       "      <td>0.750955</td>\n",
       "      <td>0.002952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tree</td>\n",
       "      <td>42</td>\n",
       "      <td>(stroke_flg &lt;= 0.50 &amp; age_HIGH &lt;= 0.50 &amp; resp_...</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>1.0</td>\n",
       "      <td>993</td>\n",
       "      <td>0.750955</td>\n",
       "      <td>0.002970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tree</td>\n",
       "      <td>42</td>\n",
       "      <td>(age_HIGH &lt;= 0.50 &amp; stroke_flg &lt;= 0.50 &amp; sapsi...</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1002</td>\n",
       "      <td>0.750955</td>\n",
       "      <td>0.001994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tree</td>\n",
       "      <td>42</td>\n",
       "      <td>(age_HIGH &lt;= 0.50 &amp; sapsi_first_HIGH &lt;= 0.50 &amp;...</td>\n",
       "      <td>0.735955</td>\n",
       "      <td>0.735955</td>\n",
       "      <td>1.0</td>\n",
       "      <td>927</td>\n",
       "      <td>0.750955</td>\n",
       "      <td>0.002992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tree</td>\n",
       "      <td>42</td>\n",
       "      <td>(stroke_flg &lt;= 0.50 &amp; age_HIGH &lt;= 0.50 &amp; mal_f...</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>1.0</td>\n",
       "      <td>903</td>\n",
       "      <td>0.750955</td>\n",
       "      <td>0.003990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tree</td>\n",
       "      <td>42</td>\n",
       "      <td>(stroke_flg &lt;= 0.50 &amp; age_HIGH &lt;= 0.50 &amp; mal_f...</td>\n",
       "      <td>0.774011</td>\n",
       "      <td>0.774011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>864</td>\n",
       "      <td>0.750955</td>\n",
       "      <td>0.003989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tree</td>\n",
       "      <td>42</td>\n",
       "      <td>(stroke_flg &lt;= 0.50 &amp; age_HIGH &lt;= 0.50 &amp; copd_...</td>\n",
       "      <td>0.790960</td>\n",
       "      <td>0.790960</td>\n",
       "      <td>1.0</td>\n",
       "      <td>987</td>\n",
       "      <td>0.750955</td>\n",
       "      <td>0.002917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tree</td>\n",
       "      <td>42</td>\n",
       "      <td>(age_HIGH &lt;= 0.50 &amp; stroke_flg &lt;= 0.50 &amp; resp_...</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>1.0</td>\n",
       "      <td>811</td>\n",
       "      <td>0.750955</td>\n",
       "      <td>0.001996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tree</td>\n",
       "      <td>42</td>\n",
       "      <td>(age_HIGH &lt;= 0.50 &amp; age_NORMAL &lt;= 0.50 &amp; chlor...</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>1.0</td>\n",
       "      <td>898</td>\n",
       "      <td>0.750955</td>\n",
       "      <td>0.001995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  split                                        explanation  \\\n",
       "0   tree     42  (age_HIGH <= 0.50 & resp_flg <= 0.50 & stroke_...   \n",
       "1   tree     42  (stroke_flg <= 0.50 & age_HIGH <= 0.50 & copd_...   \n",
       "2   tree     42  (stroke_flg <= 0.50 & age_HIGH <= 0.50 & resp_...   \n",
       "3   tree     42  (age_HIGH <= 0.50 & stroke_flg <= 0.50 & sapsi...   \n",
       "4   tree     42  (age_HIGH <= 0.50 & sapsi_first_HIGH <= 0.50 &...   \n",
       "5   tree     42  (stroke_flg <= 0.50 & age_HIGH <= 0.50 & mal_f...   \n",
       "6   tree     42  (stroke_flg <= 0.50 & age_HIGH <= 0.50 & mal_f...   \n",
       "7   tree     42  (stroke_flg <= 0.50 & age_HIGH <= 0.50 & copd_...   \n",
       "8   tree     42  (age_HIGH <= 0.50 & stroke_flg <= 0.50 & resp_...   \n",
       "9   tree     42  (age_HIGH <= 0.50 & age_NORMAL <= 0.50 & chlor...   \n",
       "\n",
       "   model_accuracy  explanation_accuracy  explanation_fidelity  \\\n",
       "0        0.752809              0.752809                   1.0   \n",
       "1        0.775281              0.775281                   1.0   \n",
       "2        0.808989              0.808989                   1.0   \n",
       "3        0.758427              0.758427                   1.0   \n",
       "4        0.735955              0.735955                   1.0   \n",
       "5        0.792135              0.792135                   1.0   \n",
       "6        0.774011              0.774011                   1.0   \n",
       "7        0.790960              0.790960                   1.0   \n",
       "8        0.779661              0.779661                   1.0   \n",
       "9        0.785311              0.785311                   1.0   \n",
       "\n",
       "   explanation_complexity  explanation_consistency  elapsed_time  \n",
       "0                     838                 0.750955      0.002992  \n",
       "1                     994                 0.750955      0.002952  \n",
       "2                     993                 0.750955      0.002970  \n",
       "3                    1002                 0.750955      0.001994  \n",
       "4                     927                 0.750955      0.002992  \n",
       "5                     903                 0.750955      0.003990  \n",
       "6                     864                 0.750955      0.003989  \n",
       "7                     987                 0.750955      0.002917  \n",
       "8                     811                 0.750955      0.001996  \n",
       "9                     898                 0.750955      0.001995  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_pruning = c_to_y(method='tree', verbose=False)\n",
    "results_pruning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
