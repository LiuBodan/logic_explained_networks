{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "import sys\n",
    "\n",
    "import sklearn\n",
    "from sklearn.datasets import load_digits\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from deep_logic.utils.relunn import get_reduced_model, prune_features\n",
    "from deep_logic import fol\n",
    "import deep_logic as dl\n",
    "from data import ConceptToTaskDataset\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = ConceptToTaskDataset(\"../data/CUB_200_2011\")\n",
    "\n",
    "X = dataset.attributes\n",
    "y = np.asarray(dataset.targets)\n",
    "\n",
    "concept_names = dataset.attribute_names.tolist()\n",
    "concept_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (11788, 312)\n",
      "Classes: [0. 1.]\n",
      "X max: 1.0 X min 0.0\n"
     ]
    }
   ],
   "source": [
    "y = sklearn.preprocessing.OneHotEncoder(sparse=False).fit_transform(y.reshape(-1, 1))\n",
    "X = sklearn.preprocessing.MinMaxScaler((0, 1)).fit_transform(X)\n",
    "print(f'X shape: {X.shape}\\nClasses: {np.unique(y)}')\n",
    "print(f'X max: {X.max()} X min {X.min()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (10609, 312)\n",
      "Y shape: (10609, 200)\n",
      "X_test shape: (1179, 312)\n",
      "Y_test shape: (1179, 200)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.1)\n",
    "print(f'X shape: {X.shape}\\nY shape: {y.shape}')\n",
    "print(f'X_test shape: {X_test.shape}\\nY_test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "torch.Size([10609, 312])\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.tensor(X, dtype=torch.float)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_train = torch.zeros((y.shape[0], y.shape[1]), dtype=torch.float)\n",
    "y_train = torch.tensor(y, dtype=torch.float)\n",
    "x_test = x_train\n",
    "n_classes = y_train.size(1)\n",
    "print(n_classes)\n",
    "print(y_train)\n",
    "y_train.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-c9613d89b4f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mloss_form\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# CrossEntropyLoss()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(0)\n",
    "device = torch.device(\"cuda\")\n",
    "x_train = x_train.to(device)\n",
    "y_train = y_train.argmax(dim=1).to(torch.long).to(device)[:, 0]\n",
    "n_classes = 1\n",
    "loss_form = torch.nn.BCELoss() # CrossEntropyLoss()\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 train accuracy: 4.00 loss: 5.2969\n",
      "Epoch: 20 train accuracy: 15.80 loss: 5.1510\n",
      "Epoch: 30 train accuracy: 23.56 loss: 5.0729\n",
      "Epoch: 40 train accuracy: 34.47 loss: 4.9709\n",
      "Epoch: 50 train accuracy: 39.97 loss: 4.9101\n",
      "Epoch: 60 train accuracy: 45.51 loss: 4.8551\n",
      "Epoch: 70 train accuracy: 48.36 loss: 4.8271\n",
      "Epoch: 80 train accuracy: 49.82 loss: 4.8123\n",
      "Epoch: 90 train accuracy: 51.13 loss: 4.7995\n",
      "Epoch: 100 train accuracy: 51.30 loss: 4.7978\n",
      "Epoch: 110 train accuracy: 52.18 loss: 4.7891\n",
      "Epoch: 120 train accuracy: 52.85 loss: 4.7824\n",
      "Epoch: 130 train accuracy: 53.24 loss: 4.7782\n",
      "Epoch: 140 train accuracy: 53.74 loss: 4.7732\n",
      "Epoch: 150 train accuracy: 54.02 loss: 4.7705\n",
      "Epoch: 160 train accuracy: 54.14 loss: 4.7695\n",
      "Epoch: 170 train accuracy: 54.43 loss: 4.7667\n",
      "Epoch: 180 train accuracy: 54.99 loss: 4.7610\n",
      "Epoch: 190 train accuracy: 55.42 loss: 4.7566\n",
      "Epoch: 200 train accuracy: 55.52 loss: 4.7554\n",
      "Epoch: 210 train accuracy: 55.75 loss: 4.7534\n",
      "Epoch: 220 train accuracy: 55.90 loss: 4.7518\n",
      "Epoch: 230 train accuracy: 55.87 loss: 4.7522\n",
      "Epoch: 240 train accuracy: 56.09 loss: 4.7498\n",
      "Epoch: 250 train accuracy: 55.80 loss: 4.7529\n",
      "Epoch: 260 train accuracy: 56.07 loss: 4.7501\n",
      "Epoch: 270 train accuracy: 56.30 loss: 4.7479\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-5cf35df1ffad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0my_pred_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0my_train_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;31m# torch.argmax(y_train, dim=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch + 1} train accuracy: {accuracy:.2f} loss: {loss:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "dimensions = [10, 50, 20]\n",
    "layers = [\n",
    "    torch.nn.Linear(x_train.size(1), dimensions[0] * n_classes),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    dl.nn.XLinear(dimensions[0], dimensions[1], n_classes),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    dl.nn.XLinear(dimensions[1], dimensions[2], n_classes),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    dl.nn.XLinear(dimensions[2], 1, n_classes),\n",
    "    torch.nn.Softmax(),\n",
    "]\n",
    "model = torch.nn.Sequential(*layers)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "model.train()\n",
    "need_pruning = True\n",
    "for epoch in range(3000):\n",
    "    # forward pass\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(x_train)\n",
    "    # Compute Loss\n",
    "    loss = loss_form(y_pred, y_train)\n",
    "\n",
    "    for module in model.children():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            loss += 1e-8 * torch.norm(module.weight, 1)\n",
    "            break\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch > 1500 and need_pruning:\n",
    "        prune_features(model, n_classes, device=device)\n",
    "        need_pruning = False\n",
    "\n",
    "    # compute accuracy\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        y_pred_d = torch.argmax(y_pred, dim=1)\n",
    "        y_train_d = y_train # torch.argmax(y_train, dim=1)\n",
    "        accuracy = y_pred_d.eq(y_train_d).sum().item() / y_train.size(0) * 100.\n",
    "        print(f'Epoch: {epoch + 1} train accuracy: {accuracy:.2f} loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Local explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "outputs = []\n",
    "for i, (xin, yin) in enumerate(zip(x_train, y_train)):\n",
    "    model_reduced = get_reduced_model(model, xin)\n",
    "    for module in model_reduced.children():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            wa = module.weight.detach().numpy()\n",
    "            ba = module.bias.detach().numpy()\n",
    "            break\n",
    "    output = model_reduced(xin)\n",
    "\n",
    "    pred_class = torch.argmax(output)\n",
    "    true_class = torch.argmax(y_train[i])\n",
    "\n",
    "    # generate local explanation only if the prediction is correct\n",
    "    if pred_class.eq(true_class):\n",
    "        local_explanation = fol.relunn.explain_local(model, x_train, y_train, xin)\n",
    "        print(f'Input {(i + 1)}')\n",
    "        print(f'\\tx={xin.detach().numpy()}')\n",
    "        print(f'\\ty={output.detach().numpy()}, y_label={yin}')\n",
    "        print(f'\\tw={wa}')\n",
    "        print(f'\\tb={ba}')\n",
    "        print(f'\\tExplanation: {local_explanation}')\n",
    "        print()\n",
    "        xin = xin.reshape(8, 8)\n",
    "        plt.figure(1, figsize=(3, 3))\n",
    "        plt.imshow(xin, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        plt.show()\n",
    "#         wa = wa.reshape(8, 8)\n",
    "#         plt.figure(1, figsize=(3, 3))\n",
    "#         plt.imshow(wa * xin.numpy(), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "#         plt.show()\n",
    "\n",
    "    outputs.append(output)\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %% md\n",
    "\n",
    "# Combine local explanations\n",
    "\n",
    "# %%\n",
    "counters = []\n",
    "from sklearn.metrics import f1_score\n",
    "y_train_d = torch.argmax(y_train, dim=1)\n",
    "for target_class in range(n_classes):\n",
    "    global_explanation, predictions, counter = fol.combine_local_explanations(model, x_train, y_train,\n",
    "                                                                              topk_explanations=10,\n",
    "                                                                              target_class=target_class,\n",
    "                                                                              concept_names=concept_names)\n",
    "\n",
    "    y2 = torch.argmax(y_train, dim=1) == target_class\n",
    "    accuracy = sum(predictions == y2.detach().numpy().squeeze()) / len(predictions)\n",
    "    f1 = f1_score(y_train[:, target_class], predictions)\n",
    "    print(f'Class {target_class} - Global explanation: \"{global_explanation}\" - Accuracy: {accuracy:.4f} - F1: {f1:.4f}')\n",
    "    counters.append(counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i, counter in enumerate(counters):\n",
    "    for j, values in enumerate(counter.items()):\n",
    "        print(i, j, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "y_pred = model(torch.Tensor(X_test)).argmax(dim=1).detach().numpy()\n",
    "y_test = np.argmax(y_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"Accuracy: {accuracy:.2f}.\\nF1: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88.\n",
      "F1: 0.89\n",
      "Accuracy: 0.27.\n",
      "F1: 0.27\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_model = DecisionTreeClassifier(max_depth=30)\n",
    "X_bool = X > 0.5\n",
    "tree_model.fit(X, y_train_d.cpu().numpy())\n",
    "X_test_bool = X_test > 0.5\n",
    "\n",
    "y_pred = tree_model.predict(X)\n",
    "accuracy = accuracy_score(y_train.cpu().numpy(), y_pred)\n",
    "f1 = f1_score(y_train.cpu().numpy(), y_pred, average='macro')\n",
    "print(f\"Accuracy: {accuracy:.2f}.\\nF1: {f1:.2f}\")\n",
    "\n",
    "y_pred = tree_model.predict(X_test)\n",
    "accuracy = accuracy_score(np.argmax(y_test, axis=1), y_pred)\n",
    "f1 = f1_score(np.argmax(y_test, axis=1), y_pred, average='macro')\n",
    "print(f\"Accuracy: {accuracy:.2f}.\\nF1: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sklearn.tree.plot_tree(tree_model)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
